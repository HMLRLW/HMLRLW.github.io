<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[BitMap算法]]></title>
    <url>%2F2019%2F10%2F17%2Fbitmap-suan-fa%2F</url>
    <content type="text"><![CDATA[这是前海亿车的一道笔试题，虽然我没做出来，但是我又学到了一种新的算法，加油！ 参考链接https://www.cnblogs.com/senlinyang/p/7885685.html 问题描述在40亿的unsigned int 类型的数据中，找出我们指定的数据。 问题分析一个数字int类型占4个字节，一个字节占8个bit，我们总共需要占用40 * 10000 * 10000 * 4 * 8个比特的内存 内存中1G是 = 1 * 1024 * 1024 * 1024 * 8 bit，计算一下我们需要14.90G的内存存放数据。一般情况下我们的内存是吃不消的，所以常规的排序算法等都不可用。 BitMap算法引入我们都知道1Byte = 8 bit; 1 int = 4 Byte = 4 * 8 bit; 假如我们一位数字代表一个数 即： 1就是1；2就是10；3就是100，存在则该位数为1，不存在则为0，这样我们一个int类型可以表示32个数字，这样我们只需要40 * 10000 * 10000 * 4 * 8 / （4 * 8）bit位置数字表示就可以，也就是（40 * 10000 * 10000）/（1024 * 1024 * 8）M表示，也就是476.84M表示，大大缩小了我们的内存空间 那么问题来了，我们该如何表示这些数据呢分析经过上面的分析，我们知道： 1：0-31 2：32-63 3：64-95 所以我们只用一维数组表示即可，至于中间的位数为1表示存在，0表示不存在 假设数据n,那么可以表示为[n/32]行，n%32列的数据为1 实现首先引入位运算 左移 右移 无符号左 无符号右移 n &gt;&gt; 1表示 n / 2 n &gt;&gt; 1表示 n / 2 n &gt;&gt; 1表示 n / 2 n &gt;&gt; 1表示 n / 2 n &gt;&gt; 2表示 n / 4 n &gt;&gt; 2表示 n / 4 n &gt;&gt; 2表示 n / 4 n &gt;&gt; 2表示 n / 4 n &gt;&gt; 3表示 n / 8 n &gt;&gt; 3表示 n / 8 n &gt;&gt; 3表示 n / 8 n &gt;&gt; 3表示 n / 8 0x1F表示32 n &amp; 0x1F = n 1 &lt;&lt; n 表示找到第n位数字 所以 n / 32 可以用 n &gt;&gt; 4表示 n %32 可以用 (value &amp; 0x1F) 根据上面关于表示问题的分析，我们需要把[n/32[n%32] 位置的数字置为1，我们可以这样做[n/32] |= 1 &lt;&lt; (n &amp; 0x1F)其中1 &lt;&lt; (n &amp; 0x1F)表示找到该列，[n/32] |= 1 &lt;&lt; (n &amp; 0x1F)把该行该列数据置为1； 代码实现package interview.day1015; import java.sql.Time; import java.util.ArrayList; import java.util.List; import java.util.Random; /** * 位图算法 * 分析：每位数都可以用一个bit位置表示,比如1 可以用1表示 2 可以用 10表示 * 由于int占四个字节 每个字节占8个bit位置 所以1可以表示 32个位置 * 加入我们有n个数字，我们就可以使用 n/32个数字表示 * 现在假设我们有n = 1 0000 0000 个数字使用int类型表示，那么每个数字表示为 * a[i >> 4][1 &lt;&lt; ] * * @author liwei * @date 2019/10/16 22:19 */ public class BitMap { private final static int N = 100000000; private static int[] a = new int[N / 32 + 1]; public void add(int value) { // value / 32 int row = value >> 5; // value % 32 // 将对应位置的元素置为1 找出对应的位置的元素value &amp; 0x1F 1左移对应的位数就找到对应的位置 a[row] |= 1 &lt;&lt; (value &amp; 0x1F); } /** * 是否存在 * * @param n * @return */ public boolean exit(int n) { // n / 32 int row = n >> 5; return (a[row] &amp; (1 &lt;&lt; (n &amp; 0x1F))) == 1; } public static void display(int n) { for (int i = 0; i &lt; n; i++) { // 保存每个数的二进制代表的数据 List&lt;Integer> list = new ArrayList&lt;>(); // 代表某一行的起始位 int temp = a[i]; for (int j = 0; j &lt; 32; j++) { list.add(temp &amp; 1); //依次往下走 temp >>= 1; } System.out.println(list); } } public int count(int n) { int count = 1; for (int i = 0; i &lt; N; i++) { if (exit(n)) { count++; } } return count; } /** * 排序 * */ public void sort() { for (int i = 0; i &lt; N; i++) { if (exit(i)) { System.out.print(i + "\t"); } } } public static void main(String[] args) { BitMap bitMap = new BitMap(); for (int i = 0; i &lt; N; i++) { bitMap.add(new Random().nextInt(N)); } // boolean exit = bitMap.exit(1234); // System.out.println(exit); // display(5); // int i = new Random().nextInt(N); // int count = bitMap.count(i); // System.out.println("统计" + i + "的数量：" + count); long start = System.currentTimeMillis(); bitMap.sort(); long end = System.currentTimeMillis(); System.out.println(end - start); } } Finally 虽然我现在很菜，但是只要我持续学习，持续整理，持续输出。从有一天菜鸟也会编程（变成）大神 就算是从下水道干起，我也要做最好的下水道，扛把子]]></content>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链表实现十进制加法]]></title>
    <url>%2F2019%2F10%2F16%2Flian-biao-shi-xian-shi-jin-zhi-jia-fa%2F</url>
    <content type="text"><![CDATA[只有走出去，才会学到更多东西 题目这是昨天笔试深圳前海亿车公司的算法题。 题目如下： 给一组单链表表示的十进制数字，实现数字的加法 1 —&gt; 2 —&gt;7 —&gt;4 ​ 8—&gt;3 实现他们的加法，注意链表顺序，不能使用其他数据结构 我的思路类似桶排序算法（其实不能这么说，应该是把数字拆分为个十百千万，但是我们这里不用放到桶里面），然后依次获取尾部节点的数据（获取尾部节点的同时删除尾部节点），相加，然后放在我们新建链表的头部，后面每次添加的节点都会放到链表的头部。但是问题是加法存在进位，如何表示进位的数据？我当时想的是新建一个节点，保存该进位的数据。这样就带来一个问题，再后续的java中如何处理这个节点？我想的是用变量存储该链表的长度，每次循环链表的长度应该是顺序增加的。当时我觉着这样应该可以解决。 后来回来又想了以下，我的思路还是有问题： 链表表示数据怎么表示，需要头节点存放数据吗？当我写到这里的时候，思路就已经短断掉了。 网上思路思路分析 将链表反转， 然后实现从个十百千万位的加法，有进位就使用变量保存起来，然后相加的时候加上去，再对相加后的数据取余，余数就是我们当前位置的数据，整数就是我们进位的数据，也就是下一个节点要想加的数据 当有链表为空的时候，就可以推出循环，将长链表的数据加上去 思路演示1 —&gt; 2 —&gt;7 —&gt;4 ​ 8—&gt;3 反转 4 —&gt; 7 —&gt;2 —&gt;1 3—&gt;8 相加 7 —&gt; 5 —&gt;3 —&gt;1 代码实现package interview.day1015; /** * 单链表反转，然后相加 * * @author liwei * @date 2019/10/15 18:13 */ public class YiHaiTest { public static void main(String[] args) { Node node1 = new Node(1); Node node2 = new Node(3); Node node3 = new Node(5); Node node4 = new Node(6); node1.next = node2; node2.next = node3; node3.next = node4; Node node5 = new Node(3); Node node6 = new Node(5); Node node7 = new Node(5); Node node8 = new Node(5); node5.next = node6; node6.next = node7; node7.next = node8; Node reverseNode1 = reverseNode(node1); Node reverseNode2 = reverseNode(node5); Node add = add(reverseNode1, reverseNode2); Node node = reverseNode(add); System.out.println(node); } /** * 链表反转. * * @param node */ public static Node reverseNode(Node node) { Node pre = null; Node temp = null; while (node != null) { //保存当前节点的下一个节点 temp = node.next; //当前节点的下一个节点为当前节点的前置节点 node.next = pre; //更新前置节点 pre = node; //重新赋值当前节点 node = temp; } return pre; } public static Node add(Node node1, Node node2) { //保存头节点 Node head = new Node(); // 替代尾节点前进 Node temp = head; //保存进位的值 int sum = 0; while (node1 != null || node2 != null || sum != 0) { if (node1 != null) { sum += node2.value; node1 = node1.next; } if (node2 != null) { sum += node2.value; node2 = node2.next; } temp.next = new Node(sum % 10); sum = sum / 10; temp = temp.next; } return head.next; } } class Node { public int value; public Node next; public Node() { } public Node(int value) { this.value = value; } @Override public String toString() { return "Node{" + "value=" + value + ", next=" + next + '}'; } } 结果展示// Node{value=7, next=Node{value=1, next=Node{value=1, next=Node{value=0, next=null}}}} finally 虽然我现在很菜，但是只要我持续学习，持续整理，持续输出。从有一天菜鸟也会编程（变成）大神 就算是从下水道干起，我也要做最好的下水道，扛把子]]></content>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA['java注意事项']]></title>
    <url>%2F2019%2F10%2F14%2Fjava-zhu-yi-shi-xiang%2F</url>
    <content type="text"><![CDATA[复习的时候看到这篇文章，很有意思，值得注意，差不多80%都遇到过，记录下来，引以为戒 摘自https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Java%E7%96%91%E9%9A%BE%E7%82%B9.md 基础1.1. 正确使用 equals 方法Object的equals方法容易抛空指针异常，应使用常量或确定有值的对象来调用 equals。 举个例子： // 不能使用一个值为null的引用类型变量来调用非静态方法，否则会抛出异常 String str = null; if (str.equals(&quot;SnailClimb&quot;)) { ... } else { .. }运行上面的程序会抛出空指针异常，但是我们把第二行的条件判断语句改为下面这样的话，就不会抛出空指针异常，else 语句块得到执行。： &quot;SnailClimb&quot;.equals(str);// false 不过更推荐使用 java.util.Objects#equals(JDK7 引入的工具类)。 Objects.equals(null,&quot;SnailClimb&quot;);// false我们看一下java.util.Objects#equals的源码就知道原因了。 public static boolean equals(Object a, Object b) { // 可以避免空指针异常。如果a==null的话此时a.equals(b)就不会得到执行，避免出现空指针异常。 return (a == b) || (a != null &amp;&amp; a.equals(b)); }注意： Reference:Java中equals方法造成空指针异常的原因及解决方案 每种原始类型都有默认值一样，如int默认值为 0，boolean 的默认值为 false，null 是任何引用类型的默认值，不严格的说是所有 Object 类型的默认值。 可以使用 == 或者 != 操作来比较null值，但是不能使用其他算法或者逻辑操作。在Java中null == null将返回true。 不能使用一个值为null的引用类型变量来调用非静态方法，否则会抛出异常 1.2. 整型包装类值的比较所有整型包装类对象值的比较必须使用equals方法。 先看下面这个例子： Integer x = 3; Integer y = 3; System.out.println(x == y);// true Integer a = new Integer(3); Integer b = new Integer(3); System.out.println(a == b);//false System.out.println(a.equals(b));//true当使用自动装箱方式创建一个Integer对象时，当数值在-128 ~127时，会将创建的 Integer 对象缓存起来，当下次再出现该数值时，直接从缓存中取出对应的Integer对象。所以上述代码中，x和y引用的是相同的Integer对象。 注意：如果你的IDE(IDEA/Eclipse)上安装了阿里巴巴的p3c插件，这个插件如果检测到你用 ==的话会报错提示，推荐安装一个这个插件，很不错。 1.3. BigDecimal1.3.1. BigDecimal 的用处《阿里巴巴Java开发手册》中提到：浮点数之间的等值判断，基本数据类型不能用==来比较，包装数据类型不能用 equals 来判断。 具体原理和浮点数的编码方式有关，这里就不多提了，我们下面直接上实例： float a = 1.0f - 0.9f; float b = 0.9f - 0.8f; System.out.println(a);// 0.100000024 System.out.println(b);// 0.099999964 System.out.println(a == b);// false具有基本数学知识的我们很清楚的知道输出并不是我们想要的结果（精度丢失），我们如何解决这个问题呢？一种很常用的方法是：使用使用 BigDecimal 来定义浮点数的值，再进行浮点数的运算操作。 BigDecimal a = new BigDecimal(&quot;1.0&quot;); BigDecimal b = new BigDecimal(&quot;0.9&quot;); BigDecimal c = new BigDecimal(&quot;0.8&quot;); BigDecimal x = a.subtract(b);// 0.1 BigDecimal y = b.subtract(c);// 0.1 System.out.println(x.equals(y));// true 1.3.2. BigDecimal 的大小比较a.compareTo(b) : 返回 -1 表示小于，0 表示 等于， 1表示 大于。 BigDecimal a = new BigDecimal(&quot;1.0&quot;); BigDecimal b = new BigDecimal(&quot;0.9&quot;); System.out.println(a.compareTo(b));// 11.3.3. BigDecimal 保留几位小数通过 setScale方法设置保留几位小数以及保留规则。保留规则有挺多种，不需要记，IDEA会提示。 BigDecimal m = new BigDecimal(&quot;1.255433&quot;); BigDecimal n = m.setScale(3,BigDecimal.ROUND_HALF_DOWN); System.out.println(n);// 1.2551.3.4. BigDecimal 的使用注意事项注意：我们在使用BigDecimal时，为了防止精度丢失，推荐使用它的 BigDecimal(String) 构造方法来创建对象。《阿里巴巴Java开发手册》对这部分内容也有提到如下图所示。 1.3.5. 总结BigDecimal 主要用来操作（大）浮点数，BigInteger 主要用来操作大整数（超过 long 类型）。 BigDecimal 的实现利用到了 BigInteger, 所不同的是 BigDecimal 加入了小数位的概念 1.4. 基本数据类型与包装数据类型的使用标准Reference:《阿里巴巴Java开发手册》 【强制】所有的 POJO 类属性必须使用包装数据类型。 【强制】RPC 方法的返回值和参数必须使用包装数据类型。 【推荐】所有的局部变量使用基本数据类型。 比如我们如果自定义了一个Student类,其中有一个属性是成绩score,如果用Integer而不用int定义,一次考试,学生可能没考,值是null,也可能考了,但考了0分,值是0,这两个表达的状态明显不一样. 说明 :POJO 类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何 NPE 问题，或者入库检查，都由使用者来保证。 正例 : 数据库的查询结果可能是 null，因为自动拆箱，用基本数据类型接收有 NPE 风险。 反例 : 比如显示成交总额涨跌情况，即正负 x%，x 为基本数据类型，调用的 RPC 服务，调用不成功时，返回的是默认值，页面显示为 0%，这是不合理的，应该显示成中划线。所以包装数据类型的 null 值，能够表示额外的信息，如:远程调用失败，异常退出。 2. 集合2.1. Arrays.asList()使用指南最近使用Arrays.asList()遇到了一些坑，然后在网上看到这篇文章：Java Array to List Examples 感觉挺不错的，但是还不是特别全面。所以，自己对于这块小知识点进行了简单的总结。 2.1.1. 简介Arrays.asList()在平时开发中还是比较常见的，我们可以使用它将一个数组转换为一个List集合。 String[] myArray = { &quot;Apple&quot;, &quot;Banana&quot;, &quot;Orange&quot; }； List&lt;String&gt; myList = Arrays.asList(myArray); //上面两个语句等价于下面一条语句 List&lt;String&gt; myList = Arrays.asList(&quot;Apple&quot;,&quot;Banana&quot;, &quot;Orange&quot;);JDK 源码对于这个方法的说明： /** *返回由指定数组支持的固定大小的列表。此方法作为基于数组和基于集合的API之间的桥梁，与 Collection.toArray()结合使用。返回的List是可序列化并实现RandomAccess接口。 */ public static &lt;T&gt; List&lt;T&gt; asList(T... a) { return new ArrayList&lt;&gt;(a); }2.1.2. 《阿里巴巴Java 开发手册》对其的描述Arrays.asList()将数组转换为集合后,底层其实还是数组，《阿里巴巴Java 开发手册》对于这个方法有如下描述： 2.1.3. 使用时的注意事项总结传递的数组必须是对象数组，而不是基本类型。 Arrays.asList()是泛型方法，传入的对象必须是对象数组。 int[] myArray = { 1, 2, 3 }; List myList = Arrays.asList(myArray); System.out.println(myList.size());//1 System.out.println(myList.get(0));//数组地址值 System.out.println(myList.get(1));//报错：ArrayIndexOutOfBoundsException int [] array=(int[]) myList.get(0); System.out.println(array[0]);//1当传入一个原生数据类型数组时，Arrays.asList() 的真正得到的参数就不是数组中的元素，而是数组对象本身！此时List 的唯一元素就是这个数组，这也就解释了上面的代码。 我们使用包装类型数组就可以解决这个问题。 Integer[] myArray = { 1, 2, 3 };使用集合的修改方法:add()、remove()、clear()会抛出异常。 List myList = Arrays.asList(1, 2, 3); myList.add(4);//运行时报错：UnsupportedOperationException myList.remove(1);//运行时报错：UnsupportedOperationException myList.clear();//运行时报错：UnsupportedOperationExceptionArrays.asList() 方法返回的并不是 java.util.ArrayList ，而是 java.util.Arrays 的一个内部类,这个内部类并没有实现集合的修改方法或者说并没有重写这些方法。 List myList = Arrays.asList(1, 2, 3); System.out.println(myList.getClass());//class java.util.Arrays$ArrayList下图是java.util.Arrays$ArrayList的简易源码，我们可以看到这个类重写的方法有哪些。 private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable { ... @Override public E get(int index) { ... } @Override public E set(int index, E element) { ... } @Override public int indexOf(Object o) { ... } @Override public boolean contains(Object o) { ... } @Override public void forEach(Consumer&lt;? super E&gt; action) { ... } @Override public void replaceAll(UnaryOperator&lt;E&gt; operator) { ... } @Override public void sort(Comparator&lt;? super E&gt; c) { ... } }我们再看一下java.util.AbstractList的remove()方法，这样我们就明白为啥会抛出UnsupportedOperationException。 public E remove(int index) { throw new UnsupportedOperationException(); }2.1.4. 如何正确的将数组转换为ArrayList?stackoverflow：https://dwz.cn/vcBkTiTW 1. 自己动手实现（教育目的） //JDK1.5+ static &lt;T&gt; List&lt;T&gt; arrayToList(final T[] array) { final List&lt;T&gt; l = new ArrayList&lt;T&gt;(array.length); for (final T s : array) { l.add(s); } return (l); } Integer [] myArray = { 1, 2, 3 }; System.out.println(arrayToList(myArray).getClass());//class java.util.ArrayList2. 最简便的方法(推荐) List list = new ArrayList&lt;&gt;(Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;))3. 使用 Java8 的Stream(推荐) Integer [] myArray = { 1, 2, 3 }; List myList = Arrays.stream(myArray).collect(Collectors.toList()); //基本类型也可以实现转换（依赖boxed的装箱操作） int [] myArray2 = { 1, 2, 3 }; List myList = Arrays.stream(myArray2).boxed().collect(Collectors.toList());4. 使用 Guava(推荐) 对于不可变集合，你可以使用ImmutableList类及其of()与copyOf()工厂方法：（参数不能为空） List&lt;String&gt; il = ImmutableList.of(&quot;string&quot;, &quot;elements&quot;); // from varargs List&lt;String&gt; il = ImmutableList.copyOf(aStringArray); // from array对于可变集合，你可以使用Lists类及其newArrayList()工厂方法： List&lt;String&gt; l1 = Lists.newArrayList(anotherListOrCollection); // from collection List&lt;String&gt; l2 = Lists.newArrayList(aStringArray); // from array List&lt;String&gt; l3 = Lists.newArrayList(&quot;or&quot;, &quot;string&quot;, &quot;elements&quot;); // from varargs5. 使用 Apache Commons Collections List&lt;String&gt; list = new ArrayList&lt;String&gt;(); CollectionUtils.addAll(list, str);2.2. Collection.toArray()方法使用的坑&amp;如何反转数组该方法是一个泛型方法：&lt;T&gt; T[] toArray(T[] a); 如果toArray方法中没有传递任何参数的话返回的是Object类型数组。 String [] s= new String[]{ &quot;dog&quot;, &quot;lazy&quot;, &quot;a&quot;, &quot;over&quot;, &quot;jumps&quot;, &quot;fox&quot;, &quot;brown&quot;, &quot;quick&quot;, &quot;A&quot; }; List&lt;String&gt; list = Arrays.asList(s); Collections.reverse(list); s=list.toArray(new String[0]);//没有指定类型的话会报错由于JVM优化，new String[0]作为Collection.toArray()方法的参数现在使用更好，new String[0]就是起一个模板的作用，指定了返回数组的类型，0是为了节省空间，因为它只是为了说明返回的类型。详见：https://shipilev.net/blog/2016/arrays-wisdom-ancients/ 2.3. 不要在 foreach 循环里进行元素的 remove/add 操作如果要进行remove操作，可以调用迭代器的 remove方法而不是集合类的 remove 方法。因为如果列表在任何时间从结构上修改创建迭代器之后，以任何方式除非通过迭代器自身remove/add方法，迭代器都将抛出一个ConcurrentModificationException,这就是单线程状态下产生的 fail-fast 机制。 fail-fast 机制 ：多个线程对 fail-fast 集合进行修改的时，可能会抛出ConcurrentModificationException，单线程下也会出现这种情况，上面已经提到过。 java.util包下面的所有的集合类都是fail-fast的，而java.util.concurrent包下面的所有的类都是fail-safe的。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql语句练习]]></title>
    <url>%2F2019%2F10%2F13%2Fsql-yu-ju-lian-xi%2F</url>
    <content type="text"><![CDATA[昨天参加了两场笔试，发现在及在SQL语句上缺少训练，写的很糟糕，现在突击训练以下，相关思考在代码里面 题目链接https://note.youdao.com/ynoteshare1/index.html?id=45d4298f42397bd52ccf6fc716e27ee9&amp;type=note#/ # 学生表 create table Student(SId varchar(10),Sname varchar(10),Sage datetime,Ssex varchar(10)); insert into Student values('01' , '赵雷' , '1990-01-01' , '男'); insert into Student values('02' , '钱电' , '1990-12-21' , '男'); insert into Student values('03' , '孙风' , '1990-05-20' , '男'); insert into Student values('04' , '李云' , '1990-08-06' , '男'); insert into Student values('05' , '周梅' , '1991-12-01' , '女'); insert into Student values('06' , '吴兰' , '1992-03-01' , '女'); insert into Student values('07' , '郑竹' , '1989-07-01' , '女'); insert into Student values('09' , '张三' , '2017-12-20' , '女'); insert into Student values('10' , '李四' , '2017-12-25' , '女'); insert into Student values('11' , '李四' , '2017-12-30' , '女'); insert into Student values('12' , '赵六' , '2017-01-01' , '女'); insert into Student values('13' , '孙七' , '2018-01-01' , '女'); # 课程表 create table Course(CId varchar(10),Cname nvarchar(10),TId varchar(10)) insert into Course values('01' , '语文' , '02'); insert into Course values('02' , '数学' , '01'); insert into Course values('03' , '英语' , '03'); # 教师表 create table Teacher(TId varchar(10),Tname varchar(10)); insert into Teacher values('01' , '张三'); insert into Teacher values('02' , '李四'); insert into Teacher values('03' , '王五'); # 学生课程成绩表 create table SC(SId varchar(10),CId varchar(10),score decimal(18,1)); insert into SC values('01' , '01' , 80); insert into SC values('01' , '02' , 90); insert into SC values('01' , '03' , 99); insert into SC values('02' , '01' , 70); insert into SC values('02' , '02' , 60); insert into SC values('02' , '03' , 80); insert into SC values('03' , '01' , 80); insert into SC values('03' , '02' , 80); insert into SC values('03' , '03' , 80); insert into SC values('04' , '01' , 50); insert into SC values('04' , '02' , 30); insert into SC values('04' , '03' , 20); insert into SC values('05' , '01' , 76); insert into SC values('05' , '02' , 87); insert into SC values('06' , '01' , 31); insert into SC values('06' , '03' , 34); insert into SC values('07' , '02' , 89); insert into SC values('07' , '03' , 98); # 查询" 01 "课程比" 02 "课程成绩高的学生的信息及课程分数 select sc.SId, sc.score from SC sc where sc.CId = '01'; select sc.SId, sc.score from SC sc where sc.CId = '02'; SELECT sc1.SId AS sid, sc1.score AS score FROM ( SELECT SId, score FROM SC sc WHERE sc.CId = '01' ) AS sc1, ( SELECT SId, score FROM SC sc WHERE sc.CId = '02' ) AS sc2 WHERE sc1.score > sc2.score AND sc1.SId = sc2.SId; SELECT s.*, temp.score AS score FROM Student s, ( SELECT sc1.SId AS sid, sc1.score AS score FROM ( SELECT SId, score FROM SC sc WHERE sc.CId = '01' ) AS sc1, ( SELECT SId, score FROM SC sc WHERE sc.CId = '02' ) AS sc2 WHERE sc1.score > sc2.score AND sc1.SId = sc2.SId ) AS temp WHERE s.SId = temp.sid # 1.1 查询同时存在" 01 "课程和" 02 "课程的情况 SELECT t1.SId AS sid, t2.CId AS cid FROM ( SELECT SId, CId FROM SC sc WHERE sc.CId = '01' ) AS t1, ( SELECT SId, CId FROM SC sc WHERE sc.CId = '02' ) AS t2 WHERE t1.SId = t2.SId; SELECT s.*, c.*, temp.score from Student s, Course c, (SELECT t1.SId AS sid, t1.CId AS cid, t1.score as score FROM ( SELECT SId, CId, score FROM SC sc WHERE sc.CId = '01' ) AS t1, ( SELECT SId, CId, score FROM SC sc WHERE sc.CId = '02' ) AS t2 WHERE t1.SId = t2.SId) as temp where s.SId = temp.sid and c.CId = temp.cid # 1.2 查询存在" 01 "课程但可能不存在" 02 "课程的情况(不存在时显示为 null ) select * from (select SId, CId, score from SC sc where sc.CId = '01') as t1 left join (SELECT SId, CId, score FROM SC sc WHERE sc.CId = '02' ) as t2 on t1.SId = t2.SId # 1.3 查询不存在" 01 "课程但存在" 02 "课程的情况 select * from (select SId, CId, score from SC sc where sc.CId != '01') as t1, (select SId, CId from SC sc where sc.CId = '02') as t2 where t1.SId = t2.SId select * from SC sc where sc.SId not in(select SId from SC where CId = '01') and CId = '02' # 查询平均成绩大于等于 60 分的同学的学生编号和学生姓名和平均成绩 # 方案一： select SId, AVG(score) from SC sc where SId = '01' select s.SId, s.Sname, (SELECT AVG(score) from SC sc where sc.SId = s.SId) as avgscore from Student s select * from (select SId, Sname, (SELECT AVG(score) from SC sc where sc.SId = s.SId) as avgscore from Student s) as temp where temp.avgscore >= 60 # 方案二： select sc.SId ,AVG(sc.score)as avgscore from SC sc GROUP BY sc.SId HAVING AVG(sc.score)>=60 select s.SId, s.Sname, t1.avgscore FROM Student s INNER join ( select sc.SId as SId ,AVG(sc.score)as avgscore from SC sc GROUP BY sc.SId HAVING AVG(sc.score)>=60 ) as t1 on s.SId = t1.SId # 查询在 SC 表存在成绩的学生信息 select distinct SId from SC sc where sc.score is not null select * from Student s where s.SId in (select distinct SId from SC sc where sc.score is not null) select * from Student s where EXISTS (select * from SC sc where s.SId = sc.SId) # 查询所有同学的学生编号、学生姓名、选课总数、所有课程的总成绩(没成绩的显示为 null ) 4.1 查有成绩的学生信息 select sc.SId as sid, count(sc.CId) as count , sum(sc.score) as allScore from SC sc GROUP BY SId select s.SId, s.Sname, t.count, allScore from Student s left join (select sc.SId as sid, count(sc.CId) as count , sum(sc.score) as allScore from SC sc GROUP BY SId) as t on t.sid = s.SId; select s.SId, s.Sname, t.count, allScore from Student s, (select sc.SId as sid, count(sc.CId) as count , sum(sc.score) as allScore from SC sc GROUP BY SId) as t where t.sid = s.SId and t.allScore is not null # 查询「李」姓老师的数量 select count(t.TId) from Teacher t where t.Tname like '李%'; # 查询学过「张三」老师授课的同学的信息 select * from Teacher t where t.Tname = '张三'; select s.* from Student s, Course c, SC sc, Teacher t where s.SId = sc.SId and sc.CId = c.CId and c.TId = t.TId and t.Tname = '张三'; # 查询没有学全所有课程的同学的信息 select sc.SId from SC sc GROUP BY sc.SId HAVING COUNT(sc.SId) < (select count(*) from Course) select * from Student s where s.SId in (select sc.SId from SC sc GROUP BY sc.SId HAVING COUNT(sc.SId) < (select count(*) from Course)) # 分析 假设所有人都选了所有的课 select Sid, Cid from Student, Course; # 然后左关联SC表查询 SC部分为空的就是没有选全的 再和Student表联查 select distinct s.SId, s.Sname, s.Ssex, s.Sage from (select SId, CId from Student, Course) as t1 left join (select SId, CId from SC) as t2 on t1.CId = t2.CId and t1.SId = t2.SId, Student s where t2.CId is null and t1.SId = s.SId # 查询至少有一门课与学号为" 01 "的同学所学相同的同学的信息 select CId from SC where SId = '01'; select DISTINCT s.* from Student s , SC sc where s.SId = sc.SId and sc.CId in (select CId from SC where SId = '01') and sc.SId != '01' # 查询和" 01 "号的同学学习的课程完全相同的其他同学的信息 select CId from SC where SId = '01' # 假设所有人都选择了01同学选择的课程 select s.SId, t1.CId from Student s, (select CId from SC where SId = '01') as t1 # 左关联SC表 找出SC为空的那部分 就是没有完全选择相同的苏剧 select distinct t2.SId from (select s.SId, t1.CId from Student s, (select CId from SC where SId = '01') as t1 ) as t2 left join SC sc on t2.SId = sc.SId and t2.CId = sc.CId where sc.SId is null # 最终筛选选择了相同的数据 select * from Student where SId not in (select distinct t2.SId from (select s.SId, t1.CId from Student s, (select CId from SC where SId = '01') as t1 ) as t2 left join SC sc on t2.SId = sc.SId and t2.CId = sc.CId where sc.SId is null) # 查询没学过"张三"老师讲授的任一门课程的学生姓名 select TId from Teacher where Tname = '张三' select CId from Course c, Teacher t where c.TId = t.TId and t.Tname = '张三'; select distinct s.* from SC sc, Student s where sc.CId not in (select CId from Course c, Teacher t where c.TId = t.TId and t.Tname = '张三') and s.SId = sc.SId # 查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩 # 注意使用group by的时候查询数据（除了聚合函数）都需要在group by 后面使用 例如 s.Sname select sc.SId, AVG(sc.score) from SC sc where sc.score < 60 GROUP BY sc.SId HAVING COUNT(sc.score) > 1 select s.SId, s.Sname, AVG(sc.score) as avgScore from Student s, SC sc where s.SId = sc.SId and sc.score < 60 GROUP BY sc.SId, s.Sname HAVING COUNT(sc.score) > 1 # 遇到which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by 问题 select @@global.sql_mode; ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION set @@global.sql_mode='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'; # 检索" 01 "课程分数小于 60，按分数降序排列的学生信息 asc 升序 desc降序 select s.* from SC sc, Student s where sc.score < 60 and sc.CId = '01' and s.SId = sc.SId ORDER BY s.SId asc # 按平均成绩从高到低显示所有学生的所有课程的成绩以及平均成绩 select SId, AVG(score) as avgScore from SC GROUP BY SId select sc.*, t.avgScore from SC sc left join (select SId, AVG(score) as avgScore from SC GROUP BY SId) as t on sc.SId = t.SId ORDER BY t.avgScore desc # 查询各科成绩最高分、最低分和平均分： 以如下形式显示：课程 ID，课程 name，最高分，最低分，平均分，及格率，中等率，优良率，优秀率 及格为>=60，中等为：70-80，优良为：80-90，优秀为：>=90 要求输出课程号和选修人数，查询结果按人数降序排列，若人数相同，按课程号升序排列 # case when sc.score > 60 then 1 else 0 end 类似lua脚本 select sc.CId as '课程号', c.Cname as '课程名', MAX(sc.score) as '最高成绩', min(sc.score) as '最低成绩', avg(sc.score) as '平均成绩', COUNT(sc.SId) as '选课人数', sum(case when sc.score > 60 then 1 else 0 end)/count(*) as '及格率', sum(case WHEN sc.score >= 70 and sc.score < 80 then 1 else 0 end)/count(*) as '中等率', sum(case when sc.score >= 80 and sc.score < 90 then 1 else 0 end)/count(*) as '优良率', sum(case when sc.score >= 90 then 1 else 0 end)/count(*) as '优秀率' from SC sc, Course c where sc.CId = c.CId GROUP BY sc.CId, c.Cname ORDER BY COUNT(*) desc, sc.CId ASC # 按各科成绩进行排序，并显示排名， Score 重复时保留名次空缺 # @curRank:=0 初始化 相当于 set @curRank = 0 select sc.CId ,@curRank:=@curRank+1 as rank,sc.score from (select @curRank:=0) as t ,SC sc ORDER BY sc.score desc # 按各科成绩进行排序，并显示排名， Score 重复时合并名次 select sc.CId, (case when @fonrscore = score then @curRank when @fontscore:=score then @curRank:=@curRank+1 end) as rank,sc.score from (select @curRank:=0, @fontage:=null) as t, SC sc ORDER BY sc.score desc # 查询学生的总成绩，并进行排名，总分重复时保留名次空缺 将总成绩结果统计出来再加上排名 select t1.*, @curRank:= @curRank + 1 as rank from (select sc.SId, sum(sc.score) from SC sc group by sc.SId ORDER BY sum(sc.score)) as t1, (select @curRank:=0) as t2 # 查询学生的总成绩，并进行排名，总分重复时不保留名次空缺 select sc.SId, sum(sc.score) as sumscore from SC sc GROUP BY sc.SId ORDER BY sum(sc.score) desc # 解释：如果当前总成绩等于上一名的总成绩，就是用上一名的总成绩,否则重新中间标记成绩fontscore 然后当前排名加1 select t1.*, (case when @fontscore=t1.sumscore then @curRank when @fontscore:=t1.sumscore then @currank:=@currank+1 end ) as rank from (select sc.SId, sum(sc.score) as sumscore from SC sc GROUP BY sc.SId ORDER BY sum(sc.score) desc) as t1, (select @curRank:=0,@fontscore:=null) as t2 # 统计各科成绩各分数段人数：课程编号，课程名称，[100-85]，[85-70]，[70-60]，[60-0] 及所占百分比 select sc.CId, CONCAT(sum(case when sc.score >=85 and sc.score =70 and sc.score =60 and sc.score =0 and sc.score =85 and sc.score =70 and sc.score =60 and sc.score =0 and sc.score sc.score and sc.CId = t.CId ) < 3 ORDER BY sc.CId asc, sc.score desc # 查询每门课程被选修的学生数 select sc.CId, COUNT(sc.SId) from SC sc GROUP BY sc.CId # 查询出只选修两门课程的学生学号和姓名 select s.SId, s.Sname from SC sc, Student s where sc.SId = s.SId GROUP BY sc.SId, s.Sname HAVING COUNT(sc.SId) = 2 # .查询男生、女生人数 select s.Ssex, count(s.Ssex) from Student s GROUP BY s.Ssex # 查询名字中含有「风」字的学生信息 select * from Student s where s.Sname like '%风%' # 查询同名同性学生名单，并统计同名人数 select s.Sname, s.Ssex, COUNT(*) as tongji from Student s GROUP BY s.Sname, s.Ssex select * from Student ss LEFT join (select s.Sname, s.Ssex, COUNT(*) as tongji from Student s GROUP BY s.Sname, s.Ssex) as t on ss.Sname = t.Sname and ss.Ssex = t.Ssex where t.tongji > 1 # .查询 1990 年出生的学生名单 select * from Student where YEAR(Sage) = 1990 # .查询每门课程的平均成绩，结果按平均成绩降序排列，平均成绩相同时，按课程编号升序排列 select sc.CId, avg(sc.score) from SC sc GROUP BY sc.CId ORDER BY avg(sc.score) asc, sc.CId desc # .查询平均成绩大于等于 85 的所有学生的学号、姓名和平均成绩 select sc.SId, avg(sc.score) from SC sc GROUP BY sc.SId having avg(sc.score) >= 85 select s.SId, s.Sname, t.avgScore from Student s, (select sc.SId as SId, avg(sc.score) as avgScore from SC sc GROUP BY sc.SId having avg(sc.score) >= 85) as t where s.SId = t.SId # 查询课程名称为「数学」，且分数低于 60 的学生姓名和分数 select c.CId from Course c where c.Cname = '数学' select s.SId, s.Sname, sc.score from Student s, SC sc, Course c where c.Cname = '数学' and c.CId = sc.CId and sc.score < 60 and sc.SId = s.SId # 查询所有学生的课程及分数情况（存在学生没成绩，没选课的情况） select s.*, sc.CId, sc.score from Student s left join SC sc on s.SId = sc.SId # 查询任何一门课程成绩在 70 分以上的姓名、课程名称和分数 select s.Sname, c.Cname, sc.score from Student s, SC sc, Course c where s.SId = sc.SId and sc.CId = c.CId and sc.score > 70 # .查询存在不及格的课程 select distinct sc.CId from SC sc where sc.score < 60 # 查询课程编号为 01 且课程成绩在 80 分以上的学生的学号和姓名 select s.SId, s.Sname from Student s, SC sc where s.SId = sc.SId and sc.score > 80 # 求每门课程的学生人数 select sc.CId, count(sc.SId) from SC sc GROUP BY sc.CId # 成绩不重复，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩 select c.CId from Course c, Teacher t where t.Tname = '张三' and c.TId = t.TId select s.*, sc.score, sc.CId from Student s, Course c, Teacher t, SC sc where t.Tname = '张三' and c.TId = t.TId and sc.CId = c.CId and s.SId = sc.SId ORDER BY sc.score desc limit 1 # 成绩有重复的情况下，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩 select s1.*, sc1.score from Student s1, SC sc1, Course c1, Teacher t1 where t1.Tname = '张三' and t1.TId = c1.TId and sc1.CId = c1.CId and s1.SId = sc1.SId and sc1.score = (select max(sc.score) from Teacher t, Course c, SC sc where t.Tname = '张三' and t.TId = c.TId and sc.CId = c.CId) # 查询不同课程成绩相同的学生的学生编号、课程编号、学生成绩 可以使用左关联 select t.* from SC t where EXISTS (select * from SC sc where sc.score = t.score and sc.CId != t.CId) # 查询每门功成绩最好的前两名 select t1.CId, t1.SId from SC t1 where (select count(*) from SC t2 where t2.score > t1.score and t2.CId = t1.CId) < 2 ORDER BY t1.CId # 统计每门课程的学生选修人数（超过 5 人的课程才统计） select sc.CId, COUNT(sc.SId) from SC sc GROUP BY sc.CId having count(*) > 5 # 检索至少选修两门课程的学生学号 select SId from SC group by SId having count(*) >=2 # 查询选修了全部课程的学生信息 select count(*) from Course select s.* from Student s, SC sc where s.SId = sc.SId GROUP BY sc.SId having count(*) = (select count(*) from Course) # 查询各学生的年龄，只按年份来算 select s.SId, TIMESTAMPDIFF(YEAR,s.Sage,CURRENT_DATE) from Student s #按照出生日期来算，当前月日 < 出生年月的月日则，年龄减一 select s.SId, TIMESTAMPDIFF(YEAR,s.Sage,CURRENT_DATE) from Student s # 查询本周过生日的学生 select * from Student where YEARWEEK(Sage) = YEARWEEK(CURRENT_DATE()) # 查询下周过生日的学生 select * from Student where YEARWEEK(Sage) = YEARWEEK(CURRENT_DATE + 1) # 查询本月过生日的学生 EXTRACT 函数用于返回日期/时间的单独部分，比如年、月、日、小时、分钟等等。 select * from Student s where EXTRACT(MONTH FROM s.Sage) = EXTRACT(MONTH FROM CURRENT_DATE) # 查询下月过生日的学生 select * from Student s where EXTRACT(MONTH FROM s.Sage) = EXTRACT(MONTH FROM DATE_ADD(CURRENT_DATE ,INTERVAL 1 MONTH))]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[看尚硅谷韩顺平老师数据结构与算法有感]]></title>
    <url>%2F2019%2F10%2F10%2Fkan-shang-huo-gu-han-shun-ping-lao-shi-shu-ju-jie-gou-yu-suan-fa-you-gan%2F</url>
    <content type="text"><![CDATA[从国庆开始到今天（10/10）持续10天看尚硅谷韩顺平老师数据结构与算法。除了最后四个算法（克鲁斯卡尔、迪杰斯特、弗洛伊德、骑士周游问题）实在是坚持不下去了，其他每到算法都坚持听一遍，再自己手写一边。虽然很多数据结构和算法表面上看懂了，理解了实际的逻辑，并实现了。但还是会遗忘的，正如韩顺平老师说的，数据结构和算法考验的是思想，没有弄懂他的思想，最终也会是走马观花。所以，再之后的一段时间内，我需要间隔式的自己实现相应的算法。保持自己不会松懈。 代码传送门 视频内容简要介绍在这套视频中，主要讲解了基本的数据结构线性表（链表、数组）、树、图。他们的基本结构、特性，衍生出来的单链表、双链表、队列、栈、二叉树、多叉树、无向图、多向图等多种结构和他们衍生出来的各种算法：8大查找算法、4大搜索算法、最短路径问题（最小生成树）等等 个人收获思想收获 解决算法问题，将问题拆分为一个个不可分解的小的问题，比如获取数据，查找数据，将这些小的问题不考虑前因后果封装成独立的小方法。然后按照规律组装起来 大部分算法问题可以理解为分而化之解决。关键是怎么分，比如二分查找、快排、基数排序等，都是找到小的不可拆分的规律，在循环处理。那么需要着重考虑的是循环处理，起始点、终止点是那些，步长多少 在这里视频中感觉算法就是截取规律中一小段（不可分割的），将需要的参数视为理想状态，不考虑该参数是受前面状态的影响，形成单独的方法（代码片段），然后递归或者循环。如此解决了大部分规律问题，然后考虑第一次或者前n次规律的影响。比如二分查找的递归调用，不考虑开始，先实现规律，然后将开始的情况单独处理。 代码展示 递归实现，我们正确的编写思路应该是先写规律，再把特殊情况特殊处理 /** * @param arr 数组 * @param left 左边索引 * @param right 右边索引 * @param value 要寻找的值 */ public static int binarySearch1(int[] arr, int left, int right, int value) { //结束递归 没有找到值 if (left > right || arr[0] > value || arr[arr.length - 1] &lt; value) { return -1; } int mid = (left + right) / 2; int midVal = arr[mid]; if (midVal > value) { //向左递归 return binarySearch1(arr, left, mid - 1, value); } else if (midVal &lt; value) { //向右递归 return binarySearch1(arr, mid + 1, right, value); } else { return mid; } } 循环遍历实现 /** * 非递归实现 * * @param arr 升序数组 * @param target 查找目标 * @return */ public static int binarySearch(int[] arr, int target) { int left = 0; int right = arr.length - 1; int mid; while (left &lt;= right) { mid = (left + right) / 2; if (target == arr[mid]) { return mid; } else if (target > arr[mid]) { left = mid + 1; } else { right = mid - 1; } } return -1; } 编程收获 重载的实际运用，在写代码的时候，先写最基本、保证足够兼容性的底层代码。然后，在针对使用场景对参数（形参、返回参数）的逐一封装（这是在暑假实习写代码的时候完全没有考虑的问题） 代码演示：这样的代码既保证了无参的情况下的调用，又保证了有参的调用 /** * 中序遍历 */ public void infixOrder() { infixOrder(root); } public void infixOrder(Node node) { if (node == null) { throw new RuntimeException("玩锤锤！"); } node.infixOrder(); } 基本方法的定位，什么类主要起什么作用，比如在链表相关代码中，关于节点的CRUD操作全都在Node节点类中实现，而相关的调用则在相关链表（LinkedList）中调用相关底层代码，最终暴露出去的只有相关LinkedList，保证了代码的健壮与用户的良好使用 相关代码：https://github.com/hmlr123/dataStructrePractice/blob/master/src/main/java/com/hmlr123/avlTree/AVLTreeDemo.java 装饰者模式在代码中具体运用，在排序算法相关测试中，有部分测试代码中总是重复。偷懒的我使用使用接口增强了基本的排序算法 代码如下： /** * 比较排序算法时间复杂度. * * @param arr 数组 * @param sort 排序算法 */ public static void show(int[] arr, Sort sort) { SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss SSS"); Date date1 = new Date(); String time1 = simpleDateFormat.format(date1); // System.out.println("排序前："+Arrays.toString(arr)); sort.sort(arr); Date date2 = new Date(); String time2 = simpleDateFormat.format(date2); // System.out.println("排序后："+Arrays.toString(arr)); System.out.println("开始时间：" + time1); System.out.println("结束时间：" + time2); long ss = date2.getTime() - date1.getTime(); System.out.printf("间隔时间：%d ms", Integer.valueOf((int) ss)); } finally关于各种算法，暂时就不做总结了，我也只是懂了，而不是真正懂了，不敢随便写下去。关于各种算法的实现思路在我的代码里面都有所注释（关于解决问题类型没有写上）。但还是希望看了视频在看代码，毕竟这是我个人总结，最适合我自己。 做个小总结，当作这10天的收获。学算法更重要的是学思想！]]></content>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链接文档]]></title>
    <url>%2F2019%2F10%2F10%2Flian-jie-wen-dang%2F</url>
    <content type="text"><![CDATA[主要记录自己平时开发过程中一些小知识查询的链接，容易遗忘又懒的写文档的知识点。当汇成一片的时候就知道自己那里有很大问题了，嘿嘿，懒人的做法。这个还是暑假实习受邓哥的影响，养成的习惯，要一直保持下去，不然对不起邓哥！ 性能调优https://www.cnblogs.com/xybaby/p/9055734.html 关于管道流https://www.cnblogs.com/littleatp/p/8419796.html 持续集成CI 持续交付CD持续集成Continuous Integration（CI） 持续交付Continuous Delivery（CD） https://linux.cn/article-9926-1.html 自动打包部署到服务器配置https://www.cnblogs.com/zluckiy/p/10220030.html &lt;plugin> &lt;groupId>org.codehaus.mojo&lt;/groupId> &lt;artifactId>wagon-maven-plugin&lt;/artifactId> &lt;version>1.0&lt;/version> &lt;configuration> &lt;fromFile>target/${pack-name}&lt;/fromFile> &lt;url>&lt;![CDATA[scp://${remote-username}:${remote-passwd}@${remote-addr}${service-path}]]>&lt;/url> &lt;commands> &lt;!-- Kill Old Process --> &lt;command>kill -9 `ps -ef |grep ${project.artifactId}.jar|grep -v "grep" |awk '{print $2}'` &lt;/command> &lt;!-- Restart jar package，write result into renren.log --> &lt;command> &lt;![CDATA[nohup java -jar ${service-path}/${pack-name} --spring.profiles.active=test > ${service-path}/renren.log 2>&amp;1 &amp; ]]>&lt;/command> &lt;command>&lt;![CDATA[netstat -nptl]]>&lt;/command> &lt;command>&lt;![CDATA[ps -ef | grep java | grep -v grep]]>&lt;/command> &lt;/commands> &lt;!-- 运行命令 mvn clean package wagon:upload-single wagon:sshexec--> &lt;displayCommandOutputs>true&lt;/displayCommandOutputs> &lt;/configuration> &lt;/plugin> springboot yml占位符问题 以及 开发环境配置https://www.jianshu.com/p/363ad244bb06 &lt;profiles> &lt;!--开发环境 --> &lt;profile> &lt;id>dev&lt;/id> &lt;properties> &lt;build.profile.id>dev&lt;/build.profile.id> &lt;/properties> &lt;/profile> &lt;!--生产环境--> &lt;profile> &lt;id>prod&lt;/id> &lt;properties> &lt;build.profile.id>prod&lt;/build.profile.id> &lt;/properties> &lt;/profile> &lt;!--测试环境，默认测试环境 --> &lt;profile> &lt;id>test&lt;/id> &lt;properties> &lt;build.profile.id>test&lt;/build.profile.id> &lt;/properties> &lt;activation> &lt;activeByDefault>true&lt;/activeByDefault> &lt;/activation> &lt;/profile> &lt;/profiles> spring: # 环境 dev|test|prod profiles: active: @build.profile.id@ 开发环境切换 https://www.cnblogs.com/javabg/p/10058753.html springboot打包成镜像https://blog.csdn.net/u012562943/article/details/78636318 &lt;plugin> &lt;groupId>com.spotify&lt;/groupId> &lt;artifactId>docker-maven-plugin&lt;/artifactId> &lt;version>0.4.14&lt;/version> &lt;!--&lt;executions>--> &lt;!--&lt;execution>--> &lt;!--&lt;phase>package&lt;/phase>--> &lt;!--&lt;goals>--> &lt;!--&lt;goal>build&lt;/goal>--> &lt;!--&lt;/goals>--> &lt;!--&lt;/execution>--> &lt;!--&lt;/executions>--> &lt;configuration> &lt;imageName>renren/fast&lt;/imageName> &lt;dockerDirectory>${project.basedir}&lt;/dockerDirectory> &lt;resources> &lt;resource> &lt;targetPath>/&lt;/targetPath> &lt;directory>${project.build.directory}&lt;/directory> &lt;include>${project.build.finalName}.jar&lt;/include> &lt;/resource> &lt;/resources> &lt;/configuration> &lt;!-- 运行命令 mvn clean package docker:build 打包并生成docker镜像 --> &lt;/plugin> 手动构建docker容器1. 默认用root用户登录 sudo su - 2. 手动部署操作流程，以前端为例 2.1 获取前端的dist压缩文件，unzip dist.zip 将其复制到 /root/webploy/frontend/html中 2.2. 在webploy目录下 docker-compose stop 将容器停止。 2.3. 删除容器 docker rm 容器的名字 删除镜像docker rmi c6cd0 可以简写 2.4 进入到 /root/webploy/frontend/ 下，因为有dockerFile文件，执行打包到镜像命令 docker build -t thundersoft-front-end . 3. 在webploy下面，批量启动容器 docker-compose up -d servlet原理https://www.ibm.com/developerworks/cn/java/j-lo-servlet/ kafkahttps://www.jb51.net/article/142626.htm 状态机状态机案例：https://blog.csdn.net/xinghuanmeiying/article/details/81586954 状态机案例：https://www.jianshu.com/p/404386fec797 状态机两种方式：https://www.cnblogs.com/qianqiannian/p/6959469.html 横向 事件驱动 纵向 状态驱动 状态机订单系统案例：https://www.jianshu.com/p/fe292b15a06a Httpshttps://www.cnblogs.com/liuxianan/p/https.html springboot定时器https://blog.csdn.net/weixin_40085570/article/details/80581815 约束： （1）定时方法不能有参数 （2）定时方法不能有返回值 （3）此类中不能包含其他带任何注解的方法（发现新大陆） 连接：https://blog.csdn.net/wlj323/article/details/80448291 引用传递和值传递应用 //根据删除的用例判断测试任务是否改变状态 List&lt;TestResultEntity> testResultEntities = testResultService.queryRwid(ids); //获取caseid的所属任务及所属任务下所有caseid Map&lt;Long, List&lt;Long>> rwids = new HashMap(); for (TestResultEntity testResultEntity : testResultEntities) { List&lt;Long> caseids = new ArrayList&lt;>(); if (rwids.get(testResultEntity.getRwid()) == null) { caseids.add(testResultEntity.getCaseid()); rwids.put(testResultEntity.getRwid(), caseids); } else { List&lt;Long> longs = rwids.get(testResultEntity.getRwid()); longs.add(testResultEntity.getCaseid()); } } 微服务的概念 值得多次研读https://mp.weixin.qq.com/s/fzk-kENu0I22P3F2Vu7KBA 技术组件集成 Nodejs 淘宝镜像使用命令 npm install cnpm -g --registry=https://registry.npm.taobao.org 原有的node_modules卸载，使用cnpm下载 cnpm优势 解决访问国外镜像速度慢的问题 https://blog.csdn.net/jack_bob/article/details/80644376 java Data、String、Long三种日期类型之间的相互转换http://www.blogjava.net/weishuangshuang/archive/2012/09/27/388712.html // date类型转换为String类型 // formatType格式为yyyy-MM-dd HH:mm:ss//yyyy年MM月dd日 HH时mm分ss秒 // data Date类型的时间 public static String dateToString(Date data, String formatType) { return new SimpleDateFormat(formatType).format(data); } // long类型转换为String类型 // currentTime要转换的long类型的时间 // formatType要转换的string类型的时间格式 public static String longToString(long currentTime, String formatType) throws ParseException { Date date = longToDate(currentTime, formatType); // long类型转成Date类型 String strTime = dateToString(date, formatType); // date类型转成String return strTime; } // string类型转换为date类型 // strTime要转换的string类型的时间，formatType要转换的格式yyyy-MM-dd HH:mm:ss//yyyy年MM月dd日 // HH时mm分ss秒， // strTime的时间格式必须要与formatType的时间格式相同 public static Date stringToDate(String strTime, String formatType) throws ParseException { SimpleDateFormat formatter = new SimpleDateFormat(formatType); Date date = null; date = formatter.parse(strTime); return date; } // long转换为Date类型 // currentTime要转换的long类型的时间 // formatType要转换的时间格式yyyy-MM-dd HH:mm:ss//yyyy年MM月dd日 HH时mm分ss秒 public static Date longToDate(long currentTime, String formatType) throws ParseException { Date dateOld = new Date(currentTime); // 根据long类型的毫秒数生命一个date类型的时间 String sDateTime = dateToString(dateOld, formatType); // 把date类型的时间转换为string Date date = stringToDate(sDateTime, formatType); // 把String类型转换为Date类型 return date; } // string类型转换为long类型 // strTime要转换的String类型的时间 // formatType时间格式 // strTime的时间格式和formatType的时间格式必须相同 public static long stringToLong(String strTime, String formatType) throws ParseException { Date date = stringToDate(strTime, formatType); // String类型转成date类型 if (date == null) { return 0; } else { long currentTime = dateToLong(date); // date类型转成long类型 return currentTime; } } // date类型转换为long类型 // date要转换的date类型的时间 public static long dateToLong(Date date) { return date.getTime(); } Mysql时间转换工具https://www.cnblogs.com/cyfblogs/p/10069404.html 时间戳转换成日期 select FROM_UNIXTIME(1429063399,'%Y年%m月%d日') 把日期转换为时间戳，和 FROM_UNIXTIME 正好相反 select UNIX_TIMESTAMP('2015-04-15') 上述方法不太好用 查询获取的值不能进入函数内 就不能进行转换 Spring bean加载顺序和Spring 后置处理器结合看 https://www.cnblogs.com/twelve-eleven/p/8080038.html 总之，afterPropertiesSet 和init-method之间的执行顺序是afterPropertiesSet 先执行，init-method 后执行。从BeanPostProcessor的作用，可以看出最先执行的是postProcessBeforeInitialization，然后是afterPropertiesSet，然后是init-method，然后是postProcessAfterInitialization。 postProcessBeforeInitialization afterPropertiesSet init-method postProcessAfterInitialization Spring 后置处理器 BeanPostProcessorhttps://www.cnblogs.com/dengpengbo/p/10464892.html postProcessBeforeInitialization 实例化、依赖注入完毕， 在调用显示的初始化之前完成一些定制的初始化任务 postProcessAfterInitialization 实例化、依赖注入、初始化完毕时执行 指定后置处理器顺序通过让BeanPostProcessor接口实现类实现Ordered接口getOrder方法，该方法返回一整数，默认值为 0，优先级最高，值越大优先级越低 Redis序列化替换 和 Spring后置处理器使用Springboot整合redis默认使用jdk的序列化 效果差，使用如下序列化 https://blog.csdn.net/m0_37708405/article/details/88842801 参看此链接 这里使用的是第二种当时 ，om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); 会被sona扫描出漏洞 博主建议使用第三种方式 */ @Configuration public class StringRedisTemplateBeanConfig implements BeanPostProcessor { //bean初始化之前执行 @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { return bean; } //bean初始化之后执行 @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { if (bean.getClass() == StringRedisTemplate.class) { StringRedisTemplate redisTemplate = (StringRedisTemplate) bean; //切换序列化方式， 默认使用非jdk的 Jackson2JsonRedisSerializer&lt;Object> jsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;Object>( Object.class); ObjectMapper om = new ObjectMapper(); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jsonRedisSerializer.setObjectMapper(om); redisTemplate.setValueSerializer(jsonRedisSerializer); redisTemplate.setHashKeySerializer(jsonRedisSerializer); redisTemplate.setHashValueSerializer(jsonRedisSerializer); } return bean; } } Module对象映射https://blog.csdn.net/K_Ohaha/article/details/82670758 跨域配置解释http://www.ruanyifeng.com/blog/2016/04/cors.html 有三个与CORS请求相关的字段，都以Access-Control-开头。 （1）Access-Control-Allow-Origin 该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。 （2）Access-Control-Allow-Credentials 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 （3）Access-Control-Expose-Headers 该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader(&#39;FooBar&#39;)可以返回FooBar字段的值。 maven继承和模块的概念与区别https://www.cnblogs.com/shirley18/p/9635824.html 再读AOP:https://blog.csdn.net/paincupid/article/details/81583749 https://blog.csdn.net/anurnomeru/article/details/79798659 接入点（join point）： 菜单 切入点（point cut）： 你点的菜 通知（advice 增强）： 你点的菜什么时候吃随你 切面（Aspect）： 你点的菜和你什么时候吃的集合体 aspect 由 pointcount 和 advice 组成, 它既包含了横切逻辑的定义, 也包括了连接点的定义. Spring AOP就是负责实施切面的框架, 它将切面所定义的横切逻辑织入到切面所指定的连接点中.AOP的工作重心在于如何将增强织入目标对象的连接点上, 这里包含两个工作: 如何通过 pointcut 和 advice 定位到特定的 joinpoint 上 如何在 advice 中编写切面代码. 可以简单地认为, 使用 @Aspect 注解的类就是切面. JSON 对象 List转换https://www.cnblogs.com/xiaohouzai/p/8972286.html 复杂JSON类型转换https://www.jianshu.com/p/b82761a64581 Maven可以继承的POM标签https://blog.csdn.net/zhagzheguo/article/details/81942155 某位大佬https://18xm.cn/micro_service/ Springboot打包 打成包含依赖和不包含依赖的jar包CSDN: https://blog.csdn.net/qq_33249725/article/details/95470178 博客园解释： https://www.cnblogs.com/lenve/p/11156340.html 路径参数https://www.cnblogs.com/zhangdiIT/p/8193369.html zuul文件上传https://blog.csdn.net/qq_26440803/article/details/82917766 zuul的文件上传使用的servlet 可以使用SpringMVC zuul转发的时候会复制一份转发，大文件容易内存碉堡 大文件容易超时，需要设置超时时间 Postman下载上传测试https://blog.csdn.net/maowendi/article/details/80537304 header Key：Content-Type Value：multipart/form-data body 选择form-data key:file （选择是file） value:文件 Maven私服设置Maven仓库搭建 https://www.jianshu.com/p/09a6cab3785a setting设置 https://www.cnblogs.com/MDK-L/p/4872384.html 公共得只能desplay 不能install Dockerfilehttps://blog.51cto.com/9291927/2310444 Jenkins maven地址https://blog.csdn.net/cc_want/article/details/86657983 Mysql最大上传包设置https://blog.csdn.net/binglong_world/article/details/81386346 MarriDB命令 https://blog.csdn.net/ymaini/article/details/82258028 QPS TPS 并发数https://blog.csdn.net/u010889616/article/details/83245695 QPS: Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。 TPS:是TransactionsPerSecond的缩写，也就是事务数/秒。它是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数 一个TPS可以是多个QPS组成 QPS（TPS）：每秒钟request/事务 数量 并发数： 系统同时处理的request/事务数 Lambda表达式过滤器使用https://blog.csdn.net/AcesLi/article/details/73752757 /** * 过滤需求池数据. * @param xuQiuEntityList 需求实体数据 * @param conReqPool 是否过滤需求池 */ private List&lt;XuQiuEntity> fiterReqPool(List&lt;XuQiuEntity> xuQiuEntityList, boolean conReqPool) { //collect(Collectors.toList()) 返回数据实体，貌似lambda表达式不支持引用传递 if (!conReqPool) { return xuQiuEntityList.stream().filter((XuQiuEntity xuQiuEntity) -> null != xuQiuEntity.getProjid() &amp;&amp; 0 != xuQiuEntity.getProjid()).collect(Collectors.toList()); } return xuQiuEntityList; } Idea手动打jar包https://blog.csdn.net/weixin_33691598/article/details/86015762]]></content>
      <tags>
        <tag>小零碎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[美食]]></title>
    <url>%2F2019%2F09%2F30%2Fmei-shi%2F</url>
    <content type="text"><![CDATA[经常会看到一些美食，记录一下，去旅游的时候就可以扫荡，嘿嘿。 北京涮肚小店：店位于西城区鼓楼西大街168号 南锣鼓巷交道口南大街49号 砸么：南锣鼓巷106号院，近平安大街（有点贵） 门钉肉饼：故宫旁边 葫芦娃牛板筋火锅：后海附近（鼓楼大街） 恩元居炒疙瘩、爆肚冯、奶酪魏：九门小吃（德内大家孝友一号） 门前张记刷肉：门前煤市街95号 聚恩园 炙热童年地址:北京市南锣鼓巷沙井胡同11号 开心一百串：广顺南大街望京园609号楼2层220-1 烤鸭：北京市三街坊小吃一条街旁 田府聚源脆皮烤鸭店 武汉精粉世家：余记 马场角横路79号富豪花园西区商铺 江岸区高雄路与台北一路交叉口那边去试试王师傅豆皮，超好吃 长堤街：桂萍牛杂 吴长子卤菜馆：靠经武汉关小学 德胜桥：舒氏烧烤 上海东东私房菜：上海市田子坊旁（日月光后面） 阿叔阿姨炸串：上海市双阳路588号03]]></content>
      <tags>
        <tag>美食</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有意思的话]]></title>
    <url>%2F2019%2F09%2F30%2Fyou-yi-si-de-hua%2F</url>
    <content type="text"><![CDATA[总会有些出动心旋的话。 我一辈子都喜欢跟着让我有感觉有兴趣的人在一起，因为在我心目中，真正的人都是疯疯癫癫的，他们爱生活，不露锋芒，希望拥有一切，他们从不疲倦，从不讲些平凡的东西，而是像奇妙的黄色罗马烟火那样，不停地喷发火花。——凯鲁亚克《在路上》 时间是最大的成本 ——某群友 知识的正向、高效、输出就是力量 ——陈华俊 思想是没有成本，行动是需要付出代价的 ——罗振宇 talk is cheap，show me the code. – Linus Torvalds]]></content>
      <tags>
        <tag>思想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发技巧]]></title>
    <url>%2F2019%2F09%2F30%2Fkai-fa-ji-qiao%2F</url>
    <content type="text"><![CDATA[记录平时突然发现的技巧，不定时更新 lombok使用lombok 注解 减少实体类的setter getter toString等 https://blog.csdn.net/sunayn/article/details/85252507 idea模板开发快捷键在live Templates中添加自己的代码模板，并设置快捷键 //forthread10 默认生成10个线程 for (int i = 0; i &lt; 10; i++) { new Thread(() ->{ }, String.valueOf(i)).start(); } //nthread 创建新线程已经继承了Runnable的 new Thread(() -> { }, "").start(); //trylock 生成锁 .lock(); try{ } catch (Exception e) { e.printStackTrace(); } finally { .unlock(); } //tsleep 线程睡眠n秒钟 try{ TimeUnit.SECONDS.sleep(); } catch (InterruptedException e) { e.printStackTrace(); } idea快捷键ctrl + alt + m 代码块生成方法 ctrl + d 复制同一行，和eclipse的快捷键不同 ctrl + y 删除某一行]]></content>
      <tags>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile]]></title>
    <url>%2F2019%2F09%2F29%2Fvolatile%2F</url>
    <content type="text"><![CDATA[摘自https://www.jianshu.com/p/ccfe24b63d87 非常感谢！ 1. hsdis 通过hsdis可以查看 Java 编译后的机器指令。 window 32/64 位，可以下载hsdis-amd64.dll/hsdis-i386.dll 下载后拷贝至 $JAVA_HOME\jre\bin\server 目录下。 或者 linxu 下载hsdis-amd64.so 下载后拷贝至 $JAVA_HOME/jre/lib/amd64/server 目录下。 拷贝完成后，运行 java -XX:+UnlockDiagnosticVMOptions。 提示 Could not load hsdis-amd64.dll; library not loadable; PrintAssembly is disabled，则没有加载成功，检查文件名称是否正确。 或者设置 export LD_LIBRARY_PATH=$JAVA_HOME/jre/lib/amd64/server/ 安装成功后提示。 ...... -agentpath:&lt;pathname>[=&lt;options>] load native agent library by full pathname -javaagent:&lt;jarpath>[=&lt;options>] load Java programming language agent, see java.lang.instrument -splash:&lt;imagepath> show splash screen with specified image See http://www.oracle.com/technetwork/java/javase/documentation/index.html for more details. 0x00007fd34511a20f: mov %rsp,%rdx 0x00007fd34511a212: and $0xfffffffffffffff0,%rsp 0x00007fd34511a216: callq 0x00007fd35a935a40 ; {runtime_call} 0x00007fd34511a21b: hlt [Deopt Handler Code] 0x00007fd34511a21c: mov $0x7fd34511a21c,%r10 ; {section_word} 0x00007fd34511a226: push %r10 0x00007fd34511a228: jmpq 0x00007fd345047240 ; {runtime_call} 0x00007fd34511a22d: hlt 0x00007fd34511a22e: hlt 0x00007fd34511a22f: hlt 可以运行以下命令生成日志。 Test 为 class 文件名称。 java -XX:+UnlockDiagnosticVMOptions -XX:+TraceClassLoading -XX:+LogCompilation -XX:LogFile=jit.log -XX:-BackgroundCompilation -XX:+PrintAssembly Test 使用jitwatch工具，可以帮助分析该日志。 linux 编译 jitwatch 可能会出现缺少 javafx 包的情况，可通过该方法解决。https://chriswhocodes.com/ 如果出现 GLIBC_2.14’ not found 问题，可通过该方法解决。https://blog.csdn.net/heylun/article/details/78833050 2. volatile volatile 是一个类型修饰符。volatile 的作用是作为指令关键字，确保本条指令不会因编译器的优化而省略。 2.1 volatile 的特性 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。（实现可见性） 禁止进行指令重排序。（实现有序性） volatile 只能保证对单次读/写的原子性。i++ 这种操作不能保证原子性。 2.2 volatile 的实现原理2.2.1 volatile 可见性实现 volatile 变量的内存可见性是基于内存屏障（Memory Barrier）实现。 内存屏障，又称内存栅栏，是一个 CPU 指令。 在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障来禁止特定类型的编译器重排序和处理器重排序，插入一条内存屏障会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序。 写一段简单的 Java 代码，声明一个 volatile 变量，并赋值。 public class Test { private volatile int a; public void update() { a = 1; } public static void main(String[] args) { Test test = new Test(); test.update(); } } 通过 hsdis 和 jitwatch 工具可以得到编译后的汇编代码。 ...... 0x0000000002951563: and $0xffffffffffffff87,%rdi 0x0000000002951567: je 0x00000000029515f8 0x000000000295156d: test $0x7,%rdi 0x0000000002951574: jne 0x00000000029515bd 0x0000000002951576: test $0x300,%rdi 0x000000000295157d: jne 0x000000000295159c 0x000000000295157f: and $0x37f,%rax 0x0000000002951586: mov %rax,%rdi 0x0000000002951589: or %r15,%rdi 0x000000000295158c: lock cmpxchg %rdi,(%rdx) //在 volatile 修饰的共享变量进行写操作的时候会多出 lock 前缀的指令 0x0000000002951591: jne 0x0000000002951a15 0x0000000002951597: jmpq 0x00000000029515f8 0x000000000295159c: mov 0x8(%rdx),%edi 0x000000000295159f: shl $0x3,%rdi 0x00000000029515a3: mov 0xa8(%rdi),%rdi 0x00000000029515aa: or %r15,%rdi ...... lock 前缀的指令在多核处理器下会引发两件事情。 1）将当前处理器缓存行的数据写回到系统内存。 2）写回内存的操作会使在其他 CPU 里缓存了该内存地址的额数据无效。 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2 或其他）后再进行操作，但操作完不知道何时会写到内存。 如果对声明了 volatile 的变量进行写操作，JVM 就会向处理器发送一条 lock 前缀的指令，将这个变量所在缓存行的数据写回到系统内存。 为了保证各个处理器的缓存是一致的，实现了缓存一致性协议（MESI），每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 所有多核处理器下还会完成：3）当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。 volatile 变量通过这样的机制就使得每个线程都能获得该变量的最新值。 2.2.1.1 lock 指令 在 Pentium 和早期的 IA-32 处理器中，lock 前缀会使处理器执行当前指令时产生一个 LOCK# 信号，会对总线进行锁定，其它 CPU 对内存的读写请求都会被阻塞，直到锁释放。 后来的处理器，加锁操作是由高速缓存锁代替总线锁来处理。 因为锁总线的开销比较大，锁总线期间其他 CPU 没法访问内存。 这种场景多缓存的数据一致通过缓存一致性协议（MESI）来保证。 2.2.1.2 缓存一致性 缓存是分段（line）的，一个段对应一块存储空间，称之为缓存行，它是 CPU 缓存中可分配的最小存储单元，大小 32 字节、64 字节、128 字节不等，这与 CPU 架构有关，通常来说是 64 字节。 LOCK# 因为锁总线效率太低，因此使用了多组缓存。 为了使其行为看起来如同一组缓存那样。因而设计了 缓存一致性协议。 缓存一致性协议有多种，但是日常处理的大多数计算机设备都属于 “ 嗅探（snooping）” 协议。 所有内存的传输都发生在一条共享的总线上，而所有的处理器都能看到这条总线。 缓存本身是独立的，但是内存是共享资源，所有的内存访问都要经过仲裁（同一个指令周期中，只有一个 CPU 缓存可以读写内存）。 CPU 缓存不仅仅在做内存传输的时候才与总线打交道，而是不停在嗅探总线上发生的数据交换，跟踪其他缓存在做什么。 当一个缓存代表它所属的处理器去读写内存时，其它处理器都会得到通知，它们以此来使自己的缓存保持同步。 只要某个处理器写内存，其它处理器马上知道这块内存在它们的缓存段中已经失效。 2.2.2 volatile 有序性实现2.2.2.1 volatile 的 happens-before 关系 happens-before 规则中有一条是 volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。 //假设线程A执行writer方法，线程B执行reader方法 class VolatileExample { int a = 0; volatile boolean flag = false; public void writer() { a = 1; // 1 线程A修改共享变量 flag = true; // 2 线程A写volatile变量 } public void reader() { if (flag) { // 3 线程B读同一个volatile变量 int i = a; // 4 线程B读共享变量 …… } } } 根据 happens-before 规则，上面过程会建立 3 类 happens-before 关系。 根据程序次序规则：1 happens-before 2 且 3 happens-before 4。 根据 volatile 规则：2 happens-before 3。 根据 happens-before 的传递性规则：1 happens-before 4。 VolatileExample 因为以上规则，当线程 A 将 volatile 变量 flag 更改为 true 后，线程 B 能够迅速感知。 2.2.2.2 volatile 禁止重排序 为了性能优化，JMM 在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序。JMM 提供了内存屏障阻止这种重排序。 Java 编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。 JMM 会针对编译器制定 volatile 重排序规则表。 volatile 重排序规则表 “ NO “ 表示禁止重排序。 为了实现 volatile 内存语义时，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎是不可能的，为此，JMM 采取了保守的策略。 在每个 volatile 写操作的前面插入一个 StoreStore 屏障。 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障。 在每个 volatile 读操作的后面插入一个 LoadLoad 屏障。 在每个 volatile 读操作的后面插入一个 LoadStore 屏障。 volatile 写是在前面和后面分别插入内存屏障，而 volatile 读操作是在后面插入两个内存屏障。 内存屏障 说明 StoreStore 屏障 禁止上面的普通写和下面的 volatile 写重排序。 StoreLoad 屏障 防止上面的 volatile 写与下面可能有的 volatile 读/写重排序。 LoadLoad 屏障 禁止下面所有的普通读操作和上面的 volatile 读重排序。 LoadStore 屏障 禁止下面所有的普通写操作和上面的 volatile 读重排序。 volatile 写插入内存屏障 volatile 读插入内存屏障 2.3 volatile 的应用场景 使用 volatile 必须具备的条件 对变量的写操作不依赖于当前值。 该变量没有包含在具有其他变量的不变式中。 只有在状态真正独立于程序内其他内容时才能使用 volatile。 模式 #1 状态标志 也许实现 volatile 变量的规范使用仅仅是使用一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。 volatile boolean shutdownRequested; ...... public void shutdown() { shutdownRequested = true; } public void doWork() { while (!shutdownRequested) { // do stuff } } 模式 #2 一次性安全发布（one-time safe publication） 缺乏同步会导致无法实现可见性，这使得确定何时写入对象引用而不是原始值变得更加困难。在缺乏同步的情况下，可能会遇到某个对象引用的更新值（由另一个线程写入）和该对象状态的旧值同时存在。（这就是造成著名的双重检查锁定（double-checked-locking）问题的根源，其中对象引用在没有同步的情况下进行读操作，产生的问题是您可能会看到一个更新的引用，但是仍然会通过该引用看到不完全构造的对象）。 public class BackgroundFloobleLoader { public volatile Flooble theFlooble; public void initInBackground() { // do lots of stuff theFlooble = new Flooble(); // this is the only write to theFlooble } } public class SomeOtherClass { public void doWork() { while (true) { // do some stuff... // use the Flooble, but only if it is ready if (floobleLoader.theFlooble != null) doSomething(floobleLoader.theFlooble); } } } 模式 #3：独立观察（independent observation） 安全使用 volatile 的另一种简单模式是定期 发布 观察结果供程序内部使用。例如，假设有一种环境传感器能够感觉环境温度。一个后台线程可能会每隔几秒读取一次该传感器，并更新包含当前文档的 volatile 变量。然后，其他线程可以读取这个变量，从而随时能够看到最新的温度值。 public class UserManager { public volatile String lastUser; public boolean authenticate(String user, String password) { boolean valid = passwordIsValid(user, password); if (valid) { User u = new User(); activeUsers.add(u); lastUser = user; } return valid; } } 模式 #4 volatile bean 模式 在 volatile bean 模式中，JavaBean 的所有数据成员都是 volatile 类型的，并且 getter 和 setter 方法必须非常普通 —— 除了获取或设置相应的属性外，不能包含任何逻辑。此外，对于对象引用的数据成员，引用的对象必须是有效不可变的。（这将禁止具有数组值的属性，因为当数组引用被声明为 volatile 时，只有引用而不是数组本身具有 volatile 语义）。对于任何 volatile 变量，不变式或约束都不能包含 JavaBean 属性。 @ThreadSafe public class Person { private volatile String firstName; private volatile String lastName; private volatile int age; public String getFirstName() { return firstName; } public String getLastName() { return lastName; } public int getAge() { return age; } public void setFirstName(String firstName) { this.firstName = firstName; } public void setLastName(String lastName) { this.lastName = lastName; } public void setAge(int age) { this.age = age; } } 模式 #5 开销较低的读－写锁策略 volatile 的功能还不足以实现计数器。因为 ++x 实际上是三种操作（读、添加、存储）的简单组合，如果多个线程凑巧试图同时对 volatile 计数器执行增量操作，那么它的更新值有可能会丢失。 如果读操作远远超过写操作，可以结合使用内部锁和 volatile 变量来减少公共代码路径的开销。 安全的计数器使用 synchronized 确保增量操作是原子的，并使用 volatile 保证当前结果的可见性。如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及 volatile 读操作，这通常要优于一个无竞争的锁获取的开销。 @ThreadSafe public class CheesyCounter { // Employs the cheap read-write lock trick // All mutative operations MUST be done with the 'this' lock held @GuardedBy("this") private volatile int value; public int getValue() { return value; } public synchronized int increment() { return value++; } } 模式 #6 双重检查（double-checked） 单例模式的一种实现方式，但很多人会忽略 volatile 关键字，因为没有该关键字，程序也可以很好的运行，只不过代码的稳定性总不是 100%，说不定在未来的某个时刻，隐藏的 bug 就出来了。 class Singleton { private volatile static Singleton instance; public static Singleton getInstance() { if (instance == null) { syschronized(Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; } } 推荐懒加载优雅写法 Initialization on Demand Holder（IODH）。 public class Singleton { static class SingletonHolder { static Singleton instance = new Singleton(); } public static Singleton getInstance(){ return SingletonHolder.instance; } } 参考https://www.jianshu.com/p/157279e6efdbhttps://blog.csdn.net/devotion987/article/details/68486942]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你做了些什么？]]></title>
    <url>%2F2019%2F07%2F20%2Fni-zuo-liao-xie-shi-me%2F</url>
    <content type="text"><![CDATA[记录一下2019这半年我做了些什么？ 我又收获了那些？ 时间眨眼而逝，在这个学期刚开始的时候就定下了很多计划，但是真正有质量实施下去的着实不多，多谢愧疚，多些收获，更多些激励。 开学在3月份，在3、4月份我断断续续的是看完了java核心卷1，在这本书中， 最开始的面向对象思想，各种数据类型，对应的字节，易错点 到java的三大特性（继承、多态、封装） java的异常机制 ,错误异常 泛型的使用，注意事项，泛型的实质 集合框架 并发编程 看了很多，记住的不多，但是让我对java基础有了更全面的认识 5月份开始就开始看数据库（深入浅出mysql） 基本数据类型，数据库与java的对应类型 数据库引擎 数据库索引注意事项 数据库基本语句DML DCL DDL语句 存储过程函数 上课数据库设计的原理注意事项 6月份开始就准备各种面试 java集合框架 并发 JVM 数据库 数据结构 网络原理 操作系统等 6月中旬就开始上班，在上班期间我做了 PMS系统初步理解 解决了一些bug 公司redis使用场景，封装方法 kafka zookeeper初步认识使用 jwt加密 shiro权限 spring boot框架的使用 日志框架使用 以及各种编码的技巧 ​ 在上班的路上，我完成了spring boot的基本内容视频和相关整合框架视频，初步认识spring boot框架和其整合框架等。还有java的并发编程。其中并发编程更深入理解，需要博客记录一下。 接下来的到9月份需要完成vue前端入门、数据结构相关视频、spring cloud入门，公司项目理解。 存钱。 今天是2019.10.10 计划很美好，现实很骨感。很多计划没有完成 7、9 月份上班，大部分的情况下都没时间整理系统的学习，全是借口！！！加班忙，还有周六周日捏？？？果然，人总是有很多借口的，请记住现在的尴尬场景，还没找到工作！！！学那么多都没整理！！！ 从8.31号实习期结束，离开了武汉中科创达软件有限公司，理由很简单 不太想呆在武汉 竞争机制不全，成长较慢 从9.1开始到9.5将个人博客全部改版，当然是套框架。然后练习docker在个人阿里云上配置各种开发测试环境、个人电脑升级。换系统、备份环境、重装开发环境 从9月5号到9月20号跟着尚硅谷徐硕博老师完成了Gmall商城的练习。简单了解了各种技术的实际使用场景（elasticSearch、activeMQ、分布式锁、dubbo、zookeeper、第三方登录、单点登录…）但这些都不是我掌握的知识，需要系统的学习。 从9月21号到9月30号看尚硅谷最新的面试题，中途回家了一次，感觉了解了很多，但知识点很零碎，真正系统掌握的不多，需要系统的大补一次（JUC、JVM、NIO）. 10月初到今天（10.10）看了尚硅谷韩顺平老师的数据结构与算法，学到了很多东西，勾起了我大二学的数据结构（当时只是听老师讲，并没有自己代码实现）,现在跟着视频全部写一遍，很多东西理解的更深入了。但需要更持续的学习 接下来，争取在11月份之前拿到中意的offer，期间再次深入理解下Springboot（这个实在暑假实习上班路上学完的，很多知识点没有编程实战练习）。 然后出去玩一趟（今年一直在压抑的学习，感觉自己整个人变坏了），然后再上班实习期间完成设计模式（尚硅谷版本），以及SpringCloud的深入理解 路很长，很久需要一步一步的走，踏实一点儿]]></content>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[飘向北方]]></title>
    <url>%2F2019%2F05%2F27%2Fpiao-xiang-bei-fang%2F</url>
    <content type="text"><![CDATA[]]></content>
      <tags>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些应该知道HTTP知识]]></title>
    <url>%2F2019%2F05%2F22%2Fyi-xie-ying-gai-zhi-dao-http-zhi-shi%2F</url>
    <content type="text"><![CDATA[主要是常见状态码以及请求方法 概念HTTP协议，即超文本传输协议(Hypertext transfer protocol)。是一种详细规定了浏览器和万维网(WWW = World Wide Web)服务器之间互相通信的规则，通过因特网传送万维网文档的数据传送协议。 HTTP协议是用于从WWW服务器传输超文本到本地浏览器的传送协议。它可以使浏览器更加高效，使网络传输减少。它不仅保证计算机正确快速地传输超文本文档，还确定传输文档中的哪一部分，以及哪部分内容首先显示(如文本先于图形)等。 HTTP是一个应用层协议，由请求和响应构成，是一个标准的客户端服务器模型。HTTP是一个无状态的协议。 在Internet中所有的传输都是通过TCP/IP进行的。HTTP协议作为TCP/IP模型中应用层的协议也不例外。HTTP协议通常承载于TCP协议之上，有时也承载于TLS或SSL协议层之上，这个时候，就成了我们常说的HTTPS。如下图所示： HTTP默认的端口号为80，HTTPS的端口号为443。 统一资源定位符 浏览器请求资源过程 浏览器分析网页获取URL 浏览器想DNS请求解析域名的IP（比如www.hmlr123.com）地址 域名系统DNS解析出服务器IP地址，返回给浏览器 浏览器与服务器建立连接 浏览器请求资源 服务器响应，返回资源 浏览器接受资源显示 释放连接 请求报文方法GET:获取资源。请求读取URL标识的信息 POST:传输实体主体 PUT:传输文件 HEAD:获取报文首部，和GET方法一样，只是不返回报文主体部分，用于确定URI的有效性和资源更新的日期等 DELETE:删除文件 OPTIONS:查询针对请求URI指定的资源支持的方法 TRACE:追踪路径，让服务器将之前的请求通信返回给客户端 CONNECT:要求与代理服务器通信时建立隧道 Keep-alive在HTTP1.0时，请求一次建立一次TCP连接断开一次 在HTTP1.1，使用Keep-alive，只要任意一方没有提出断开连接，则保持TCP连接 管线化并行发送请求 状态码 1xx 表示通知信息的，如请求收到了或正在进行处理。 2xx 表示成功，如接受或知道了。 3xx 表示重定向，表示要完成请求还必须采取进一步的行动。 4xx 表示客户的差错，如请求中有错误的语法或不能完成。 5xx 表示服务器的差错，如服务器失效无法完成请求。 常见详解： 状态码 状态码英文名称 中文描述 100 Continue 继续。客户端应继续其请求 200 OK 请求成功。一般用于GET与POST请求 201 Created 已创建。成功请求并创建了新的资源 202 Accepted 已接受。已经接受请求，但未处理完成 300 Multiple Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 301 Moved Permanently 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 302 Found 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI 304 Not Modified 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源。访问浏览器缓存资源 400 Bad Request 客户端请求的语法错误，服务器无法理解 401 Unauthorized 请求要求用户的身份认证 403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求 404 Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面 500 Internal Server Error 服务器内部错误，无法完成请求]]></content>
      <tags>
        <tag>网络原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP首部字段]]></title>
    <url>%2F2019%2F05%2F21%2Fhttp-shou-bu-zi-duan%2F</url>
    <content type="text"><![CDATA[这一块一直是空白，刚好看书补补，记录一下 参考链接：https://www.cnblogs.com/jycboy/archive/2017/02/17/http_head.html 授人以渔https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers HTTP报文首部HTTP请求报文HTTP请求报文由方法、URI、HTTP版本、HTTP首部字段等组成 :authority: www.jd.com :method: GET :path: / :scheme: https accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3 accept-encoding: gzip, deflate, br accept-language: zh-CN,zh;q=0.9 cache-control: no-cache cookie: o2Control=webp; __jda=122270672.15584083038411514702.... pragma: no-cache upgrade-insecure-requests: 1 user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36 HTTP响应报文HTTP响应报文由HTTP版本、状态吗（数字和原因短语）、HTTP首部字段3部分组成 age: 10 cache-control: max-age=30 content-encoding: gzip content-length: 31783 content-type: text/html; charset=utf-8 date: Tue, 21 May 2019 03:11:46 GMT expires: Tue, 21 May 2019 03:12:06 GMT ser: 4.126 server: JDWS/2.0 status: 200 strict-transport-security: max-age=7776000 vary: Accept-Encoding via: BJ-Y-NX-110(EXPIRED), http/1.1 WH-CT-1-JCS-26 ( [cRs f ]) HTTP首部字段使用首部字段是为了给浏览器和服务器提供报文主体大小、所使用的语言、认证信息等内容。 HTTP首部字段结构HTTP 首部字段是由首部字段名和字段值构成的，中间用冒号“:” 分隔。 四种HTTP首部字段类型通用首部字段：请求报文和响应报文都会用的首部 请求首部字段：从客户端向服务器端发送请求报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关优先级等信息。 响应首部字段：从服务器端向客户端返回响应报文时使用的首部。补充了响应的附加内容，也会要求客户端附加额外的内容信息。 实体首部字段：针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体有关的信息。 在有无缓存时HTTP的不同行为HTTP 首部字段将定义成缓存代理和非缓存代理的行为 端到端首部（End-to-end Header）:此类别中的首部会转发给请求 / 响应对应的最终接收目标，且必须保存在由缓存生成的响应中，另外规 定它必须被转发。（无缓存服务器） 逐跳首部（Hop-by-hop Header）:此类别中的首部只对单次转发有效，会因通过缓存或代理而不再转发。HTTP/1.1 和之后版本中，如果要使用 hop-by-hop 首部，需提供 Connection 首部字段。（有缓存无服务器） 逐级首部字段： Connection Keep-Alive Proxy-Authenticate Proxy-Authorization Trailer TE Transfer-Encoding Upgrade HTTP1.1通用首部字段 常见详解： Cache-Control这部分涉及到Http缓存，前端的优化，请看https://www.cnblogs.com/chenqf/p/6386163.html 缓存了解一波保存资源的缓存 缓存是指代理服务器或客户端本地磁盘内保存的资源副本，利用缓存服务器减少对源服务器的的访问，节省通信流量和通信时间，减少服务器压力。 缓存服务器是代理服务器的一种，归类在缓存代理类型中，换句话说，当代理转发从服务器返回响应时，代理服务器还保存一份副本 缓存的有效期限 源服务器资源改变，缓存资源更新 客户要求请求最新资源，多久请求源服务器。。。 客户端缓存 缓存保存时间。服务器资源更新，本地缓存更新。 缓存请求指令指令 参数 说明no-cache 无 强制向源服务器再次验证no-store 无 不缓存请求或响应的任何内容max-age = [ 秒] 必需 响应的最大Age值max-stale( = [ 秒]) 可省 略接收已过期的响应min-fresh = [ 秒] 必需 期望在指定时间内的响应仍有效no-transform 无 代理不可更改媒体类型only-if-cached 无 从缓存获取资源cache-extension - 新指令标记（token） 缓存响应指令指令 参数 说明public 无 可向任意方提供响应的缓存private 可省略 仅向特定用户返回响应no-cache 可省略 缓存前必须先确认其有效性no-store 无 不缓存请求或响应的任何内容no-transform 无 代理不可更改媒体类型must-revalidate 无 可缓存但必须再向源服务器进行确认proxy-revalidate 无 要求中间缓存服务器对缓存的响应有效性再进行 确认max-age = [ 秒] 必需 响应的最大Age值s-maxage = [ 秒] 必需 公共缓存服务器响应的最大Age值cache-extension - 新指令标记（token） Cache-Control 是最重要的规则。常见的取值有private、public、no-cache、max-age，no-store，默认为private。private: 客户端可以缓存public: 客户端和代理服务器都可缓存（前端的同学，可以认为public和private是一样的）max-age=xxx: 缓存的内容将在 xxx 秒后失效no-cache: 需要使用对比缓存来验证缓存数据（后面介绍）no-store: 所有内容都不会缓存，强制缓存，对比缓存都不会触发（对于前端开发来说，缓存越多越好，so…基本上和它说886） no-cache：使用no-cache目的是为了防止从缓存中弄返回过期资源。如果客户端请求包含该指令，表示客户端将不会接受缓存过的响应。即，中间的缓存服务器必须把客户端请求转发给源服务器。如果源服务器返回包含该指令，缓存服务器不能对资源进行缓存。源服务器也不会对缓存服务器请求提取资源有效性验证，且禁止响应资源进行缓存。如果服务器响应首部报文包含该字段，切no-cache字段指定参数值，客户端接收到这个报文后，（客户端）就不能使用缓存。也就是说，客户端接收报文中no-cache字段有参数就不能缓存，没参数可以缓存。 no-store:禁止缓存，不管是客户端还是缓存服务器，注意区分no-cache ConnectionConnection 首部字段具备如下两个作用: 控制不再转发给代理的首部字段 管理持久连接 控制不再转发给代理的首部字段 Connection: 不再转发的首部字段名 在客户端发送请求和服务器返回响应内，使用 Connection 首部字段，可控制不再转发给代理的首部字段（即 Hop-by-hop 首部）。 管理持久连接 HTTP/1.1 版本的默认连接都是持久连接。为此，客户端会在持久连接上连续发送请求。当服务器端想明确断开连接时，则指定 Connection 首部字段的值为 Close。 HTTP/1.1 之前的 HTTP 版本的默认连接都是非持久连接。为此，如果想在旧版本的 HTTP 协议上维持 持续连接，则需要指定 Connection 首部字段的值为 Keep-Alive。 Date 首部字段Date 表明创建 HTTP 报文的日期和时间 Pragma历史遗留字段，自己看书 Trailer首部字段 Trailer 会事先说明在报文主体后记录了哪些首部字段。该首部字段可应用在 HTTP/1.1 版本分块传 输编码时。 HTTP/1.1 200 OK Date: Tue, 03 Jul 2012 04:40:56 GMT Content-Type: text/html ... Transfer-Encoding: chunked Trailer: Expires ...(报文主体)... 0 Expires: Tue, 28 Sep 2004 23:59:59 GMT Upgrade首部字段 Upgrade 用于检测 HTTP 协议及其他协议是否可使用更高的版本进行通信，其参数值可以用来指定 一个完全不同的通信协议。 Via使用首部字段 Via 是为了追踪客户端与服务器之间的请求和响应报文的传输路径。 经过多少个代理服务器。。。 请求首部字段请求首部字段是从客户端往服务器端发送请求报文中所使用的字段，用于补充请求的附加信息、客户端信 息、对响应内容相关的优先级等内容。 首部字段名 说明Accept 用户代理可处理的媒体类型Accept-Charset 优先的字符集Accept-Encoding 优先的内容编码Accept-Language 优先的语言（自然语言）Authorization Web认证信息Expect 期待服务器的特定行为From 用户的电子邮箱地址Host 请求资源所在服务器，多个服务器的时候，访问特定服务器If-Match 比较实体标记（ETag）If-Modified-Since 比较资源的更新时间If-None-Match 比较实体标记（与 If-Match 相反）If-Range 资源未更新时发送实体 Byte 的范围请求If-Unmodified-Since 比较资源的更新时间（与If-Modified-Since相反）Max-Forwards 最大传输逐跳数Proxy-Authorization 代理服务器要求客户端的认证信息Range 实体的字节范围请求Referer 对请求中 URI 的原始获取方TE 传输编码的优先级User-Agent HTTP 客户端程序的信息 AcceptAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8​ Accept 首部字段可通知服务器，用户代理能够处理的媒体类型及媒体类型的相对优先级。可使用 type/subtype 这种形式，一次指定多种媒体类型。 比如，如果浏览器不支持 PNG 图片的显示，那 Accept 就不指定 image/png，而指定可处理的 image/gif 和 image/jpeg 等图片类型。 若想要给显示的媒体类型增加优先级，则使用 q= 来额外表示权重值 1，用分号（;）进行分隔。权重值 q 的 范围是 0~1（可精确到小数点后 3 位），且 1 为最大值。不指定权重 q 值时，默认权重为 q=1.0。 Accept-Charset 、Accept-Encoding、Accept-Language ，都可以采用优先级 Accept-EncodingAccept-Encoding: gzip, deflate​ Accept-Encoding 首部字段用来告知服务器用户代理支持的内容编码及内容编码的优先级顺序。可一次性指 定多种内容编码。 不同的压缩算法 Form首部字段 From 用来告知服务器使用用户代理的用户的电子邮件地址。通常，其使用目的就是为了显示搜索 引擎等用户代理的负责人的电子邮件联系方式。使用代理时，应尽可能包含 From 首部字段（但可能会因代 理不同，将电子邮件地址记录在 User-Agent 首部字段内）。 响应首部字段首部字段名 说明Accept-Ranges 是否接受字节范围请求Age 推算资源创建经过时间ETag 资源的匹配信息Location 令客户端重定向至指定URIProxy-Authenticate 代理服务器对客户端的认证信息Retry-After 对再次发起请求的时机要求Server HTTP 服务器的安装信息Vary 代理服务器缓存的管理信息WWW-Authenticate 服务器对客户端的认证信息 Age首部字段 Age 能告知客户端，源服务器在多久前创建了响应。字段值的单位为秒。若创建该响应的服务器是缓存服务器，Age 值是指缓存后的响应再次发起认证到认证完成的时间值。代理创 建响应时必须加上首部字段 Age。 ETag能告知客户端实体标识，他是一种可将资源以字符串的形式做成唯一标识的方式。服务器会为每一个资源分配对应的ETag值。 当资源更新的时候，该值也会更新 例如，同样的访问URI，但是资源分为英文版和中文版，这时候需要区分，就靠这个。 强Etag和弱Etag区分 强Etag：无论实体发生多么细微的变化都会该变该值 Etag:"usagi-1234" 弱Etag：只用于提示资源是否相同，只有当资源发生根本性改变时，才会改变该值，这时会在最开始加上W/ Etag:"W/usagi-1234" 实体首部字段首部字段名 说明Allow 资源可支持的HTTP方法Content-Encoding 实体主体适用的编码方式Content-Language 实体主体的自然语言Content-Length 实体主体的大小（单位：字节）Content-Location 替代对应资源的URIContent-MD5 实体主体的报文摘要Content-Range 实体主体的位置范围Content-Type 实体主体的媒体类型Expires 实体主体过期的日期时间Last-Modified 资源的最后修改日期时间 Allow首部字段 Allow 用于通知客户端能够支持 Request-URI 指定资源的所有 HTTP 方法。当服务器接收到不支持 的 HTTP 方法时，会以状态码 405 Method Not Allowed 作为响应返回。与此同时，还会把所有能支持的 HTTP 方法写入首部字段 Allow 后返回。 Cookie首部字段Cookie 的工作机制是用户识别及状态管理。Web 网站为了管理用户的状态会通过 Web 浏览器，把一些数据 临时写入用户的计算机内。接着当用户访问该Web网站时，可通过通信方式取回之前发放的 Cookie。 为 Cookie 服务的首部字段 首部字段名 说明 首部类型Set-Cookie 开始状态管理所使用的Cookie信息 响应首部字段Cookie 服务器接收到的Cookie信息 请求首部字段 Set-Cookie当服务器准备开始管理客户端的状态时，会事先告知各种信息。 Set-Cookie: status=enable; expires=Tue, 05 Jul 2011 07:26:31 GMT; path=/; domain=.hackr.jp;​ 属性 说明NAME=VALUE 赋予 Cookie 的名称和其值（必需项）expires=DATE Cookie的有效期（若不明确指定则默认为浏览器关闭前为止）path=PATH 将服务器上的文件目录作为Cookie的适用对象（若不指定则默认为文档 所在的文件目录）domain=域名 作为 Cookie 适用对象的域名 （若不指定则默认为创建 Cookie 的服务 器的域名）Secure 仅在 HTTPS 安全通信时才会发送 CookieHttpOnly 加以限制，使 Cookie 不能被 JavaScript 脚本访问 CookieCookie: status=enable 首部字段 Cookie 会告知服务器，当客户端想获得 HTTP 状态管理支持时，就会在请求中包含从服务器接收到的 Cookie。接收到多个 Cookie 时，同样可以以多个 Cookie 形式发送。 其他首部字段HTTP 首部字段是可以自行扩展的。所以在 Web 服务器和浏览器的应用上，会出现各种非标准的首部字段。 X-Frame-Options X-XSS-Protection DNT P3P X-Frame-OptionsX-Frame-Options属于HTTP响应首部，控制网站内容在其他Web网站的Frame标签的显示问题，主要目的是防止点击劫持攻击 X-XSS-ProtectionX-XSS-Protection属于HTTP响应首部，针对跨站脚本攻击（XSS），控制XSS防护机制的开关 0：将XSS过滤设置成无效状态 1：将XSS过滤设置成有效状态 DNTHTTP请求首部，Do Not Track，拒绝个人信息被手机，表示被精准广告追踪的一种方法 0：同意被追踪 1：拒绝被追踪 P3PHTTP响应首部，P3P（The Platform for privaccy Preferences,在线隐私偏好技术） 让web网站上的个人隐私变成一种仅供程序理解的形式，以保护用户隐私 练手识别通用首部（General）： Request URL: https://www.tmall.com/ 请求路径 Request Method: GET 请求方法 Status Code: 200 返回状态吗 Remote Address: 127.0.0.1:53314 远程地址、路由地址 Referrer Policy: unsafe-url 再次请求代理服务器时间。。。。不是很懂 请求首部（Request Headers） :authority: www.tmall.com 验证地址 :method: GET :path: / 请求路径 :scheme: https 请求协议约束 accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3 可以接受的数据类型，以及权重 accept-encoding: gzip, deflate, br 科技接受的数据编码，压缩算法 accept-language: zh-CN,zh;q=0.9 可以接受的语言及权重 cache-control: no-cache 缓存控制 cookie: cna=dfdnFX6DIUQCAdNDN+J 本地cookie 不完整嘻嘻 pragma: no-cache 历史遗留字段 它用来向后兼容只支持 HTTP/1.0 协议的缓存服务器，那时候 HTTP/1.1 协议中的 Cache-Control 还没有出来。 upgrade-insecure-requests: 1 我理解为请求安全的标志符，标志是否开启安全XXX user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36 客户端信息 响应首部（Response Headers） age: 26 首部字段 Age 能告知客户端，源服务器在多久前创建了响应。字段值的单位为秒。 若创建该响应的服务器是缓存服务器，Age 值是指缓存后的响应再次发起认证到认证完成的时间值。代理创 建响应时必须加上首部字段 Age。 ali-swift-global-savetime: 1558416087 应该是天猫自己的一种技术，记载什么的全局保存时间 cache-control: max-age=0, s-maxage=120 缓存（客户端和代理缓存）时间 s-maxage仅仅应用于共享缓存.而不引用于用户代理的本地缓存,等针对单用户的缓存. 另外,s-maxage的优先级要高于max-age. content-encoding: gzip 数据类型 content-type: text/html; charset=utf-8 内容类型 date: Tue, 21 May 2019 05:21:27 GMT http响应报文创建时间 eagleeye-traceid: b6f230a715584160870783622e eagleid: 74d3f9ce15584161132898039e etag: W/"37755-uKo1cPkII7DgKj6Ubs+6mkTJEUI" 资源标识 应该是多级标识 realpath: page/portal/act/fp 真正访问路径 server: Tengine 服务器信息 status: 200 状态吗 strict-transport-security: max-age=0 strict-transport-security: max-age=31536000 timing-allow-origin: *, * vary: Accept-Encoding 代理服务器缓存的管理信息 vary: Accept-Encoding vary: Origin, Ali-Detector-Type, X-Host via: cache38.l2cn1732[0,200-0,H], cache5.l2cn1732[1,0], cache6.cn557[0,200-0,H], cache6.cn557[1,0] 服务器路径 x-cache: HIT TCP_MEM_HIT dirn:-2:-2 x-readtime: 93 x-server-id: wormholesource011020214076.center.na61 x-swift-cachetime: 96 x-swift-savetime: Tue, 21 May 2019 05:21:51 GMT x-via: cn1266.l1, cache1.cn1266, l2cn1732.l2, cache38.l2cn1732, wormholesource011020214076.center.na61 应该是性能优化的一部分，以后涉及到了深入一波]]></content>
      <tags>
        <tag>网络原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双重校验锁实现对象单例]]></title>
    <url>%2F2019%2F05%2F20%2Fshuang-chong-xiao-yan-suo-shi-xian-dui-xiang-dan-li%2F</url>
    <content type="text"><![CDATA[干干干货 双重校验锁实现对象单例 public class Singleton { private volatile static Singleton uniqueInstance; private Singleton() { } public static Singleton getUniqueInstance() { //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) { //类对象加锁 synchronized (Singleton.class) { if (uniqueInstance == null) { uniqueInstance = new Singleton(); } } } return uniqueInstance; } } 问题：为什么需要两次判断if(singleTon==null)? 分析：第一次校验：由于单例模式只需要创建一次实例，如果后面再次调用getInstance方法时，则直接返回之前创建的实例，因此大部分时间不需要执行同步方法里面的代码，大大提高了性能。如果不加第一次校验的话，那跟上面的懒汉模式没什么区别，每次都要去竞争锁。 第二次校验：如果没有第二次校验，假设线程t1执行了第一次校验后，判断为null，这时t2也获取了CPU执行权，也执行了第一次校验，判断也为null。接下来t2获得锁，创建实例。这时t1又获得CPU执行权，由于之前已经进行了第一次校验，结果为null（不会再次判断），获得锁后，直接创建实例。结果就会导致创建多个实例。所以需要在同步代码里面进行第二次校验，如果实例为空，则进行创建。 需要注意的是，private static volatile SingleTon3 singleTon=null;需要加volatile关键字，否则会出现错误。问题的原因在于JVM指令重排优化的存在。在某个线程创建单例对象时，在构造方法被调用之前，就为该对象分配了内存空间并将对象的字段设置为默认值。此时就可以将分配的内存地址赋值给instance字段了，然而该对象可能还没有初始化。若紧接着另外一个线程来调用getInstance，取到的就是状态不正确的对象，程序就会出错]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码]]></title>
    <url>%2F2019%2F05%2F20%2Farraylist-yuan-ma%2F</url>
    <content type="text"><![CDATA[面试前突击看的，感觉还行，看懂了，更要多看 参考：https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/collection/ArrayList-Grow.md 首先三个变量 private static final int DEFAULT_CAPACITY = 10; private static final Object[] EMPTY_ELEMENTDATA = {}; private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; 构造方法： public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } public ArrayList(int initialCapacity) { if (initialCapacity > 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); } } public ArrayList(Collection&lt;? extends E> c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; } } 可以发现无参构造方法并没有创建数组 Collection参数的构造方法里同样没有 查看add方法 理解size变量：The size of the ArrayList (the number of elements it contains). 指数组中元素的个苏，每加一个，递增一次 public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; } ensureCapacityInternal private void ensureCapacityInternal(int minCapacity) { ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); } calculateCapacity计算容量 private static int calculateCapacity(Object[] elementData, int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { return Math.max(DEFAULT_CAPACITY, minCapacity); } return minCapacity; } 如果元素等于DEFAULTCAPACITY_EMPTY_ELEMENTDATA，即无参构造方法的那个，容量为默认10、和穿入size+1中大的那位 不是无参构造方法，就是传入的size+1那位 ensureExplicitCapacity确定容量 private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length > 0) grow(minCapacity); } 如果需要的容量小于元素的长度，需要扩容 grow private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; //注意这个变量 private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity >> 1); //容量变为原来的一半 if (newCapacity - minCapacity &lt; 0) //如果新容量小于所需容量 newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE > 0)//新容量大于限制最大容量Integer.MAX_VALUE_8 newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); } Integer里面 @Native public static final int MAX_VALUE = 0x7fffffff; 注意: “&gt;&gt;”（移位运算符）：&gt;&gt;1 右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源 hugeCapacity private static int hugeCapacity(int minCapacity) { if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); //对minCapacity和MAX_ARRAY_SIZE进行比较 //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小 //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小 //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; return (minCapacity > MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; } 可以看出减8是留着缓冲的 copyOf public static &lt;T> T[] copyOf(T[] original, int newLength) { return (T[]) copyOf(original, newLength, original.getClass()); } 接着走copyof public static &lt;T,U> T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]> newType) { @SuppressWarnings("unchecked") T[] copy = ((Object)newType == (Object)Object[].class)//转变成Object类型 ? (T[]) new Object[newLength]//是就创建一个新的Object数组 : (T[]) Array.newInstance(newType.getComponentType(), newLength);//否则创建一个相同类型的数据 System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength));//将原来的数组copy到新建数组，从0到传入新的长度或者原来数组的长度 return copy; } 通过运行结果，我们可以很明显的看出向 ArrayList 添加大量元素之前最好先使用ensureCapacity 方法，以减少增量重新分配的次数]]></content>
      <tags>
        <tag>java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux-tomcat配置]]></title>
    <url>%2F2019%2F05%2F19%2Flinux-tomcat-pei-zhi%2F</url>
    <content type="text"><![CDATA[怕忘记了 摘自https://www.cnblogs.com/wycfm/p/9595550.html 1. tomact 解压到/usr/local/tomcat下 2.vim /usr/local/tomcat/bin/catalina.sh 在OS specific support.前加上 （注意java 安装目录） JAVA_HOME=/usr/java/jdk1.8.0_161 JRE_HOME=$JAVA_HOME/jre 3.配置tomcat service 文件 vi /usr/lib/systemd/system/tomcat.service 输入： [Unit]Description=TomcatAfter=syslog.target network.target remote-fs.target nss-lookup.target [Service]Type=oneshotExecStart=/usr/local/tomcat/bin/startup.shExecStop=/usr/local/tomcat/bin/shutdown.shExecReload=/bin/kill -s HUP $MAINPIDRemainAfterExit=yes [Install]WantedBy=multi-user.target 4.允许开机启动 systemctl enable tomcat 5.启动，查看状态，重启，关闭 tomcat systemctl start tomcat.service systemctl status tomcat.service systemctl restart tomcat.service systemctl stop tomcat.service 6.开启端口 firewall-cmd –zone=public –add-port=8080/tcp –permanent；]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-线索二叉树中序线索化]]></title>
    <url>%2F2019%2F05%2F11%2Fda-hua-shu-ju-jie-gou-xian-suo-er-cha-shu-zhong-xu-xian-suo-hua%2F</url>
    <content type="text"><![CDATA[理解什么事线索二叉树，怎么将二叉树线索化，线索化的二叉树怎么遍历 拓展，前序线索二叉树遍历，后序线索二叉树遍历 搬砖开始：摘自 扩展：后序线索化二叉树 前序遍历：根左右 中序遍历：左根右 后序遍历：左右根 理解他们的前驱结点是什么，后驱结点是什么。画图 线索二叉树原理前面介绍二叉树原理及特殊二叉树文章中提到，二叉树可以使用两种存储结构：顺序存储和二叉链表。在使用二叉链表的存储结构的过程中，会存在大量的空指针域，为了充分利用这些空指针域，引申出了“线索二叉树”。回顾一下二叉链表存储结构，如下图： 通过观察上面的二叉链表，存在着若干个没有指向的空指针域。对于一个有n个节点的二叉链表，每个节点有指向左右节点的2个指针域，整个二叉链表存在2n个指针域。而n个节点的二叉链表有n-1条分支线，那么空指针域的个数=2n-(n-1) = n+1个空指针域，从存储空间的角度来看，这n+1个空指针域浪费了内存资源。 从另外一个角度来分析，如果我们想知道按中序方式遍历二叉链表时B节点的前驱节点或者后继节点时，必须要按中序方式遍历二叉链表才能够知道结果，每次需要结果时都需要进行一次遍历，是否可以考虑提前存储这种前驱和后继的关系来提高时间效率呢？ 综合以上两方面的分析，可以通过充分利用二叉链表中的空指针域，存放节点在某种遍历方式下的前驱和后继节点的指针。我们把这种指向前驱和后继的指针成为线索，加上线索的二叉链表成为线索链表，对应的二叉树就成为“线索二叉树(Threaded Binary Tree)” 。 构建线索二叉树过程1、我们对二叉树进行中序遍历（不了解二叉树遍历请参考二叉树及特殊二叉树介绍），将所有的节点右子节点为空的指针域指向它的后继节点。如下图： 过中序遍历我们知道H的right指针为空，并且H的后继节点为D（如上图第1步），I的right指针为空，并且I的后继节点为B（如上图第2步），以此类推，知道G的后继节点为null，则G的right指针指向null。 2、接下来将这颗二叉树的所有节点左指针域为空的指针域指向它的前驱节点。如下图： ​ 如上图，H的left指针域指向Null（如第1步），I的前驱节点是D，则I的left指针指向D，以此类推。通过上面两步完成了整个二叉树的线索化，最后结果如下图： 通过观察上图（蓝色虚线代表后继、绿色虚线代表前驱），可以看出，线索二叉树，等于是把一棵二叉树转变成了一个“特殊的双向链表“(后面会解释为什么叫特殊的双向链表），这样对于我们的新增、删除、查找节点带来了方便。所以我们对二叉树以某种次序遍历使其变为线索二叉树的过程称做是线索化。如下图： 仔细分析上面的双向链表，与线索化之后的二叉树相比，比如节点D与后继节点I，在完成线索化之后，并没有直接线索指针，而是存在父子节点的指针；节点A与节点F，在线索化完成之后，节点A并没有直接指向后继节点F的线索指针，而是通过父子节点遍历可以找到最终的节点F，前驱节点也存在同样的问题，正因为很多节点之间不存在直接的线索，所以我将此双向链表称做“特殊的双向链表”，再使用过程中根据指针是线索指针还是子节点指针来分别处理，所以在每个节点需要标明当前的左右指针是线索指针还是子节点指针。 代码Nodepackage tree.threadedBinaryTree; public class Node&lt;T> { private T data; private Node lNode; private Node rNode; private int lIsThread; //左孩子线索标识符 private int rIsThread; //右孩子线索标识符 public Node(T data) { this.data = data; this.lNode=null; this.rNode=null; this.lIsThread=0; this.rIsThread=0; } public Node(T data, Node lNode, Node rNode) { this.data = data; this.lNode = lNode; this.rNode = rNode; } public Node(T data, Node lNode, Node rNode, int lIsThread, int rIsThread) { this.data = data; this.lNode = lNode; this.rNode = rNode; this.lIsThread = lIsThread; this.rIsThread = rIsThread; } public T getData() { return data; } public void setData(T data) { this.data = data; } public Node getlNode() { return lNode; } public void setlNode(Node lNode) { this.lNode = lNode; } public Node getrNode() { return rNode; } public void setrNode(Node rNode) { this.rNode = rNode; } public int getlIsThread() { return lIsThread; } public void setlIsThread(int lIsThread) { this.lIsThread = lIsThread; } public int getrIsThread() { return rIsThread; } public void setrIsThread(int rIsThread) { this.rIsThread = rIsThread; } } ThreadedBinaryTreepackage tree.threadedBinaryTree; public class ThreadedBinaryTree&lt;T> { private Node root; //根结点 private Node pre; //记录前/后驱结点 public Node getRoot() { return root; } public void setRoot(Node root) { this.root = root; } public ThreadedBinaryTree(T[] value) { this.root=createTree(value,1); //创建二叉树 this.pre=null; } public Node createTree(T[] datas,int index){ if (index>datas.length){ return null; } Node node=new Node(datas[index-1]); Node left=createTree(datas,2*index); Node right=createTree(datas,2*index+1); node.setlNode(left); node.setrNode(right); return node; } /** * 中序线索化 * @param node */ public void inThread(Node node){ if (node==null){ return; } inThread(node.getlNode()); if (null==node.getlNode()){ //左孩子为空 node.setlIsThread(1); node.setlNode(pre); //前驱结点 } if (pre!=null&amp;&amp;null==pre.getrNode()){ //前驱结点右孩子为空 pre.setrIsThread(1); pre.setrNode(node); //后驱节点 } pre=node; inThread(node.getrNode()); } /** *遍历中序线索化 从最左子节点开始 */ public void inThreadList(Node node){ //中序遍历寻找最左节点 while (node!=null&amp;&amp;node.getlIsThread()==0){//就是有左孩子且左孩子不是有左孩子 //左孩子不是线索化 node=node.getlNode(); } while (node!=null){ System.out.print(node.getData()+" "); if (node.getrIsThread()==1){ //右孩子是线索化 node=node.getrNode(); }else { //如果右指针不是线索，找到右子树开始的节点 node=node.getrNode(); while (node!=null&amp;&amp;node.getlIsThread()==0){ //左孩子是线索化 node=node.getlNode(); } } } } public void inList(Node node){ if (node!=null){ inList(node.getlNode()); System.out.print(node.getData()+" "); inList(node.getrNode()); } } } 结果中序遍历：8 4 9 2 5 1 6 3 7 中序遍历线索化：8 4 9 2 5 1 6 3 7 进程完成，退出码 0 分析总结 线索二叉树就是将二叉树的空指针指向前驱结点或后驱节点（此处的前驱、后驱节点可能是该节点的父节点，也肯能是父节点的父节点） 适用于进场需要遍历二叉树或者查找结点的前驱结点和后驱节点]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-二叉树前中后序遍历]]></title>
    <url>%2F2019%2F05%2F09%2Fda-hua-shu-ju-jie-gou-er-cha-shu-qian-zhong-hou-xu-bian-li%2F</url>
    <content type="text"><![CDATA[重点在于 二叉树的构建，满二叉树怎么构建，完全二叉树怎么构建 前序遍历若二叉树为空，则空操作返回，否则先访问根节点，再访问前序遍历左子树，再前序访问右子树 中序遍历若二叉树为空，则空操作返回，否则从根节点开始（不是访问根节点），中序遍历左子树，然后访问根节点，再中序遍历右子树 后序遍历若二叉树为空，则空操作返回，否则从根节点开始（不是访问根节点），后序遍历左子树，在后序遍历右子树，最后访问根结点 层序遍历若二叉树为空，则空操作返回，否则从树的第一层，也就是根节点开始访问，从上到下逐层遍历，在同一层，按从左到右顺序对节点访问 BinaryTreeImplpackage tree.bianli; import java.util.ArrayList; import java.util.List; public class BinaryTreeImpl&lt;T>{ private BinaryTreeImpl lChild; private BinaryTreeImpl rChild; private BinaryTreeImpl root; private T data; public BinaryTreeImpl getRoot() { return root; } public void setRoot(BinaryTreeImpl root) { this.root = root; } public BinaryTreeImpl() { } public BinaryTreeImpl(BinaryTreeImpl lChild, BinaryTreeImpl rChild, T data) { this.lChild = lChild; this.rChild = rChild; this.data = data; } public BinaryTreeImpl(T data) { this(null,null,data); } public void createTree(T[] values) { List&lt;BinaryTreeImpl&lt;T>> datas=new ArrayList&lt;>();//存储所有节点树 for (T data:values){ datas.add(new BinaryTreeImpl&lt;T>(data) ); } root=datas.get(0); //获取根节点 /** * 分析: * 构造完全二叉树 区分满二叉树 */ for (int i=0;i&lt;values.length/2;i++){ datas.get(i).lChild=datas.get(2*i+1);//1，3，5，7... if (2*i+2&lt;values.length){//避免偶数时下标越界 datas.get(i).rChild=datas.get(2*i+2);//2,4,6,8,10... } } } public void preOrder(BinaryTreeImpl&lt;T> root) { if (root!=null){ travel(root.data); preOrder(root.lChild); preOrder(root.rChild); } } //中 左 右 public void midOrder(BinaryTreeImpl&lt;T> root) { if (root!=null){ midOrder(root.lChild); travel(root.data); midOrder(root.rChild); } } //左 右 中 public void aftOrder(BinaryTreeImpl&lt;T> root) { if (root!=null){ aftOrder(root.lChild); aftOrder(root.rChild); travel(root.data); } } public void travel(T value){ System.out.print(value+" "); } } Testpackage tree.bianli; public class Test { public static void main(String[] args) { BinaryTreeImpl&lt;Integer> binaryTree=new BinaryTreeImpl&lt;>(); binaryTree.createTree(new Integer[]{1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20}); System.out.println("前序遍历："); binaryTree.preOrder(binaryTree.getRoot()); System.out.println("\n中序遍历："); binaryTree.midOrder(binaryTree.getRoot()); System.out.println("\n后序遍历："); binaryTree.aftOrder(binaryTree.getRoot()); } } 结果 前序遍历： 1 2 4 8 16 17 9 18 19 5 10 20 11 3 6 12 13 7 14 15 中序遍历： 16 8 17 4 18 9 19 2 20 10 5 11 1 12 6 13 3 14 7 15 后序遍历： 16 17 8 18 19 9 4 20 10 11 5 2 12 13 6 14 15 7 3 1 进程完成，退出码 0]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-二叉树]]></title>
    <url>%2F2019%2F05%2F08%2Fda-hua-shu-ju-jie-gou-er-cha-shu%2F</url>
    <content type="text"><![CDATA[纯理论，了解一下 搬砖，摘自 定义二叉树是n(n&gt;=0)个结点的有限集合，该集合或者为空集（称为空二叉树），或者由一个根结点和两棵互不相交的、分别称为根结点的左子树和右子树组成。 特点由二叉树定义以及图示分析得出二叉树有以下特点：1）每个结点最多有两颗子树，所以二叉树中不存在度大于2的结点。2）左子树和右子树是有顺序的，次序不能任意颠倒。3）即使树中某结点只有一棵子树，也要区分它是左子树还是右子树。 性质1）在二叉树的第i层上最多有2^(i-1 )个节点 。（i&gt;=1） 2）二叉树中如果深度为k,那么最多有2^k-1个节点。(k&gt;=1） 3）n0=n2+1 n0表示度数为0的节点数，n2表示度数为2的节点数。 4）在完全二叉树中，具有n个节点的完全二叉树的深度为[log2n]+1，其中[log2n]是向下取整。 5）若对含 n 个结点的完全二叉树从上到下且从左至右进行 1 至 n 的编号，则对完全二叉树中任意一个编号为 i 的 (1) 若 i=1，则该结点是二叉树的根，无双亲, 否则，编号为 [i/2] 的结点为其双亲结点; (2) 若 2i&gt;n，则该结点无左孩子， 否则，编号为 2i 的结点为其左孩子结点； (3) 若 2i+1&gt;n，则该结点无右孩子结点， 否则，编号为2i+1 的结点为其右孩子结点。 斜树斜树：所有的结点都只有左子树的二叉树叫左斜树。所有结点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。 满二叉树满二叉树：在一棵二叉树中。如果所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树。 满二叉树的特点有： 1）叶子只能出现在最下一层。出现在其它层就不可能达成平衡。 2）非叶子结点的度一定是2。 3）在同样深度的二叉树中，满二叉树的结点个数最多，叶子数最多。 完全二叉树完全二叉树：对一颗具有n个结点的二叉树按层编号，如果编号为i(1&lt;=i&lt;=n)的结点与同样深度的满二叉树中编号为i的结点在二叉树中位置完全相同，则这棵二叉树称为完全二叉树。 特点： 1）叶子结点只能出现在最下层和次下层。 2）最下层的叶子结点集中在树的左部。 3）倒数第二层若存在叶子结点，一定在右部连续位置。 4）如果结点度为1，则该结点只有左孩子，即没有右子树。 5）同样结点数目的二叉树，完全二叉树深度最小。 注：满二叉树一定是完全二叉树，但反过来不一定成立。 排序数 存储结构顺序存储结构二叉树的顺序存储结构就是使用一维数组存储二叉树中的结点，并且结点的存储位置，就是数组的下标索引。 图3.6所示的一棵完全二叉树采用顺序存储方式，如图3.7表示： 由图3.7可以看出，当二叉树为完全二叉树时，结点数刚好填满数组。那么当二叉树不为完全二叉树时，采用顺序存储形式如何呢？例如：对于图3.8描述的二叉树： 其中浅色结点表示结点不存在。那么图3.8所示的二叉树的顺序存储结构如图3.9所示： 其中，∧表示数组中此位置没有存储结点。此时可以发现，顺序存储结构中已经出现了空间浪费的情况。那么对于图3.3所示的右斜树极端情况对应的顺序存储结构如图3.10所示： 由图3.10可以看出，对于这种右斜树极端情况，采用顺序存储的方式是十分浪费空间的。因此，顺序存储一般适用于完全二叉树。 二叉链表既然顺序存储不能满足二叉树的存储需求，那么考虑采用链式存储。由二叉树定义可知，二叉树的每个结点最多有两个孩子。因此，可以将结点数据结构定义为一个数据和两个指针域。表示方式如图3.11所示：]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向对象思想]]></title>
    <url>%2F2019%2F05%2F06%2Fmian-xiang-dui-xiang-si-xiang%2F</url>
    <content type="text"><![CDATA[我对面向对象的认识，踩坑！ 什么是面向对象，为什么要面向对象。面向过程，面对一个问题，一个步骤一个步骤的解决。针对的是问题的分析综合解决 面向对象，把构成问题事务分解为一个个对象，目的不是为了完成一个步骤，而是描述某个事物在整个解决问题的步骤中的行为，构造一个仿真环境，最终要解决的问题间建立一个方法 面向对象四大特性抽象提取现实世界中某事物的关键特性，为该事物构建模型的过程。对同一事物在不同的需求下，需要提取的特性可能不一样。得到的抽象模型中一般包含：属性（数据）和操作（行为）。这个抽象模型我们称之为类。对类进行实例化得到对象。 继承概念：一个类继承另外一个类，继承的类就是子类，被继承的类就是父类 目的：实现代码的复用 理解：特殊和泛化关系，子类是父类更加详细的分类，拥有父类的属性和方法，能扩展自己的属性和方法，也能重写父类的方法 封装概念：也称信息隐藏，利用抽象数据类型将数据和基于数据的操作封装到一起，成为一个不可分割的独立实体，数据被保护在抽象数据类型的内部，尽可能的隐藏内部细节，只保留一些对外接口使之对外部发生联系。也就是说用户不用知道对象内部方法的实现细节，但可以通过对象提供的接口访问对象的数据并与之交互 优点： 专业的分工，将能实现特定功能的代码封装到一个独立的实体，其他人可以共同调用 隐藏信息，通过控制权限将不想给其他类看到的方法隐藏起来 多态 多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。 概念：相同的事物，调用其方法，参数相同时，行为也不同 实现三大要素：继承、重写、父类引用子类 重写：子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法。 实现两种方式：继承实现、接口实现 继承实现的多态子类继承父类，并重写父类的方法，多个子类继承父类并重写父类的方法，就会产生差异性。当我们使用父类变量指向子类对象的时候，调用相同的方法，产生的效果不同。 如果父类是抽象类，子类必须实现父类中的所有抽象方法。 接口实现的多态接口可以被很多类实现，一个类可以实现很多不同的接口的方法 不同的类实现接口的方法不同 使用接口变量指向实现接口的类，就会产生差异 向上向下转型理解什么是向上，什么是向下。向上是实例化的子类被指向父类。向下是被实例化的父类指向子类。 向上转型：父类变量指向子类对象，自动转型，父类有的方法，都可以使用，调用的是子类的方法 向下转型：子类变量指向父类对象，强制转型，将会失去子类特有的方法。调用的是父类的方法]]></content>
      <tags>
        <tag>java</tag>
        <tag>思想</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试]]></title>
    <url>%2F2019%2F05%2F06%2Fmian-shi%2F</url>
    <content type="text"><![CDATA[记录一下自己的不足 走走停停，5月份了，投了很多建立，很多石沉大海，偶有回信，记录一下。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树的存储结构]]></title>
    <url>%2F2019%2F05%2F06%2Fshu-de-cun-chu-jie-gou%2F</url>
    <content type="text"><![CDATA[纯理论，让我们了解一下先人的智慧，各种树的存储结构，后面有大作用。不懂多看大话数据结构那部分内容 摘自 What is a tree?树的定义树(Tree)是 n(n≥0)n(n≥0)个结点的有限集。n=0n=0时称为空树。在任意一颗非空树中 有且仅有一个特定的称为根(Root)的结点 当 n&gt;1时，其余结点可分为 m(m&gt;0)m(m&gt;0)个互不相交的有限集 T1、T2、……、TmT1、T2、……、Tm， 其中每一个集合本身又是一棵树，并且称为根的子树(SubTree)，如下图所示 注意： n&gt;0时，根节点唯一，不存在多个根节点 m&gt;0时，子树个数没有限制，但一定互不相交 树的概念 度(Degree)：结点拥有的子树树称为结点的度。度为0的结点称为 叶节点(Leaf)或终端结点。度不为0的结点称为非终端结点或分支结点。除根节点外，分支结点也称为内部结点。树的度就是树内各结点的度的最大值。 结点的子树的根称为该结点的 孩子(Child)， 相应的，该结点称为汉子的双亲(Parent)。同一个双亲的孩子之间互称 兄弟(Sibling)。结点的祖先是从根到该结点所经分支上的所有结点。以某结点为根的子树中的任一结点都称为该结点的 子孙 结点的 层次(Level)从根开始定义起，根为第一层，根的孩子为第二层。树中结点的最大层次称为树的 深度(Depth)或高度。 有序数：树中结点的各子树从左至右有次序，不能互换，否则为 无序树 森林(Forest)：是 m(m&gt;0)m(m&gt;0)课互不相交的树的集合 What can I do?ADT 树 (tree) Data 树是由一个根节点和若干棵子树构成。树中结点具有相同数据类型及层次关系 Operation InitTree(*T): 构造空树 T DestroyTree(*T)：销毁树 T CreateTree(*T, definition)：按 definitin 中给出树的定义来构造树 ClearTree(*T)：若树 T 存在， 则将树 T清为空树 TreeEmpty(T)： 若 T 为空树，返回 true， 否则返回 false。 TreeDepth(T)： 返回 T 的深度 Root(T)：返回 T 的根节点 Value(T, cur_e)：cur_e 是树 T 中一个结点，返回此节点的值 Assign(T, cur_e, value)：给树 T 的结点 cur_e 赋值为 value Parent(T, cur_e)：若 cur_e 是树 T 的非根节点，则返回它的双亲，否则返回空 LeftChild(T, cur_e)：若 cur_e 是树 T 的非叶节点，则返回它的最左孩子，否则返回空 RightSibling(T, cur_e)：若 cur_e 有右兄弟，则返回它的右兄弟，否则返回空 InsertChild(*T, *p, i, c)：其中 p 指向树 T 的某个结点，i 为所指结点 p 的度加上 1， 非空树 c 与 T不相交， 操作结果为插入 c 为树 T 中 p 所指结点的第 i 课子树 DeleteChild(*T, *p, i)：其中 p 指向树 T 的某个节点， i 为所指结点 p 的度，操作结果为删除 T 中 p 所指结点的第 i 棵子树 endADT Storage structure of tree双亲表示法树的结点以一组连续空间表示，且在每个结点中，附设一个指示器指示其双亲结点到链表中的位置。 其中data是数据域，存储结点的数据信息。而parent是指针域，存储该结点的双亲在数组中的下标 根节点没有双亲，故根节点的域设置为 -1，双亲表示法根据parent指针很容易找到它的双亲结点，时间复杂度为O(1)。但无法确定结点的孩子，必须遍历整个结构。当然可以改进，比如增加孩子域，兄弟域等(注：就是添加字段，但是如果有很多孩子，怎么办？？？每个节点存储多个数据？？) 孩子表示法把每个结点的孩子结点排列起来，以单链表作存储结构，则n个结点有n个孩子链表，如果是叶子节点则此单链表为空。然后n个头指针又组成一个线性表，采用顺序存储结构，采用个顺序存储结构，存放进一个一维数组中。 为此，有两种结点结构 孩子链表的孩子结点, child为数据域，存储某个结点在表头数组中的下标，next为指针域，存储指向下一孩子结点的指针 表头数组的表头结点，data是数据域，存储某结点的数据信息。firstchild是头指针域，存储该结点的孩子链表的头指针。 优点是方便查找孩子以及兄弟结点 缺点：对于双亲则需要遍历整棵树。优化方法可以是添加 双亲域 解决办法：添加parentid字段（双亲孩子表示法） 类似HashMap的存储结构，只不过HashMap的链表节点存储的是数据，而不是存储数据的地址 孩子兄弟表示法任意一棵树，它的结点的第一个孩子如果存在就是唯一的，它的右兄弟如果存在也是唯一的。故可设置两个指针，分别指向第一个孩子和此结点的右兄弟。 结点结构如下,其中data是数据域，firstchild是指针域，存储该结点的第一个孩子结点的存储地址，rightsib是指针域，存储该结点的右兄弟结点的存储地址 优点：将复杂树结构转换为二叉树，且对孩子和兄弟查找方便。 缺点：双亲查找麻烦，可增加双亲指针域优化]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-顺序队列]]></title>
    <url>%2F2019%2F05%2F03%2Fda-hua-shu-ju-jie-gou-shun-xu-dui-lie%2F</url>
    <content type="text"><![CDATA[渣渣威，每日一法 顺序队列由数组组成，具体分析见注解 SequenceQueuepackage stack_queue.queue.sequenceQuene; import java.util.Queue; public interface SequenceQueue&lt;T> { /** * 队尾添加元素 */ public void add(T value); /** * 获取队首元素，删除 */ public T remove(); /** * 获取队首元素，不删除 */ public T element(); } MySequenceQueuepackage stack_queue.queue.sequenceQuene; import java.util.Queue; /** * 分析：顺序队列使用数组实现，数组容量有限，如果每次从数组头部获取数据，然后移动数据，消耗资源， * 解决办法：每次输出不移动数组内容，添加变量front 指向队头，使用rear指向队尾， * 问题：当rear用完之后呢？即rear指向数组的最后一个位置，而队首前面还有空间 * 解决办法：rear可以指向队首前面的空闲 * 问题：怎么判断空间是否用完？ * 1. 队列空的条件：front==rear * 2. 也存在 队首前面有空间且用完，此时front==rear * 怎么区分？ * 解决方案： * 方案一： 牺牲空间，队首和队尾之间留一个空间，即rear+1==front时队满 * 计算队列长度，如果rear在front右边，队列长度rear-front * 如果rear在front左边，队列长度：queueSize-front+rear * 通用公式：(queueSize-front+rear)%queueSize * 方案二： 增加变量size表示队列元素个数 ,每次front=rear时判断size是否等于数组的大小 * * 这里采用方案二 * @param &lt;T> */ public class MySequenceQueue&lt;T> implements SequenceQueue&lt;T> { private Object[] queue; private int front; private int rear; private static int max_size=15; public MySequenceQueue(int max_size) { this.queue=new Object[max_size]; this.front=0; this.rear=0; } public MySequenceQueue() { this.queue=new Object[max_size]; this.front=0; this.rear=0; } @Override public void add(T value) { if (isFull()){ System.out.println("队列满了，老哥！"); }else { queue[rear]=value; this.rear=(rear+1)%queue.length; } } @Override public T remove() { if (isEmpty()){ return (T) "被掏空了！"; }else { int flag=front; front=(front+1)%queue.length; return (T) queue[flag]; } } @Override public T element() { if (isEmpty()){ return (T) "被掏空了！"; }else { return (T) queue[front]; } } /** * 判断队列是否满了 * @return */ private boolean isFull(){ if ((rear+1)%queue.length==front){ return true; }else { return false; } } /** * 判断队列是否为空 * @return */ private boolean isEmpty(){ if (rear==front){ return true; }else { return false; } } } Testpackage stack_queue.queue.sequenceQuene; public class Test { public static void main(String[] args) { SequenceQueue&lt;String> sequenceQueue = new MySequenceQueue&lt;>(); sequenceQueue.add("a"); sequenceQueue.add("b"); sequenceQueue.add("c"); sequenceQueue.add("d"); sequenceQueue.add("e"); sequenceQueue.add("f"); System.out.println(sequenceQueue.element().toString()); System.out.println(sequenceQueue.remove().toString()); System.out.println(sequenceQueue.element().toString()); } } 结果a a b 进程完成，退出码 0]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-四则运算]]></title>
    <url>%2F2019%2F05%2F01%2Fda-hua-shu-ju-jie-gou-si-ze-yun-suan%2F</url>
    <content type="text"><![CDATA[使用栈实现四则运算，理解原理，实现过程 What?中缀表达式：即人们常用的算式写法，如8+(9-1)*8+7/2 后缀表达式：运算符放到数字后，如8 9 1 - 8 * + 7 2 /+ How?中缀表达式转后缀表达式从左到右遍历中缀表达式的每一个数字和运算符。如果数字就输出（即存入后缀表达式）；如果是右括号，则弹出左括号之前的运算符；如果优先级低于栈顶运算符，则弹出栈顶运算符，并将当前运算符进栈。遍历结束后，将栈则剩余运算符弹出。 如果是前缀表达式实现就是从右到左实现 后缀表达式计算结果从左到右遍历后缀表达式，遇到数字就进栈，遇到符号，就将栈顶的两个数字出栈运算，运算结果进栈，直到获得最终结果。 代码FourExpressionspackage stack_queue.stack.fourExpressions; import java.util.HashMap; import java.util.Map; import java.util.Stack; /** * 分析： * 1. 将中缀表达式转换成后缀表达式 * 1. 如果遇到数字就输出，变量保存 * 2. 如果是符号，判断该符号与栈顶符号优先级，如果是右符号或者优先级不高于栈顶元素，栈顶元素出栈，当前符号进 * 2. 用后缀表达式进行计算 * 1. 从左到右遍历，数字进栈， * 2. 遇到符号，栈顶两个元素出栈，计算结果值存入栈顶 */ public class FourExpressions&lt;T> { private Stack&lt;String> stack; //定义变量，存储输出内容，由于是字符串类型且经常变化，所以使用StringBuffer类型，减少String带来的创建对象资源的消耗 面试考点 //面试考点：StringBuffer和StringBuilder区别，StringBuffer是线程安全的很多方法使用了synchronized StringBuilder不是线程安全 private StringBuilder suffix=new StringBuilder(); //存储运行过程中的后缀表达式 //初始化栈 public FourExpressions() { this.stack = new Stack&lt;>(); } //设置优先级 private static final Map&lt;String,Integer> priority=new HashMap&lt;>(); static { /** * 理解优先级别)优先级最高，需要匹配( 其次是/ * 最后是+ - ""则是无运算符 */ priority.put("*",2); priority.put("/",2); priority.put("+",1); priority.put("-",1); priority.put("(",0); priority.put("",-1);//无运算符 } /** * 分析： * 1. 字符串拆分获取 * 2. 判断是字符还是数字 * 1. 数字输出 * 2. 字符判断其与栈顶元素的优先级 如果是），站定元素出栈，直到）或者是优先级不高于栈顶元素，栈顶元素出栈，当前符号进栈（原则，优先级高的在栈顶） 此处有迭代循环，进栈就得用相应的规则判断 * 3. 将栈内元素依次输出 * @param value * @return */ public String inffixToSuffix(String value){ char element=' '; for (int i=0;i&lt;value.length();i++){ element=value.charAt(i); //获取指定位置的字符 //判断是字符还是数字 if (isNum(element)){ //数字就输出 suffix.append(element); //判断优先级 两种情况 ）和 优先级 }else { inputOrOutputStack(element); } } while (stack.size()>0){ suffix.append(stack.pop()); } return suffix.toString(); } private void inputOrOutputStack(char element){ String pop=""; if (stack.isEmpty()){ stack.push(String.valueOf(element)); }else { if(")".equals(String.valueOf(element))){ //此处是判断( //栈顶元素输出，直到遇到( 并输出他 pop=stack.pop(); //获取栈顶元素 while (!"(".equals(pop)){ //判断是否是( 不是就要继续输出 suffix.append(pop); pop=stack.pop(); //出栈 最后(出栈 进行比较，所以不存在 } }else{ //进栈判断优先级 如果大于栈顶优先级则进栈 ||"(".equals(String.valueOf(stack.peek())) if("(".equals(String.valueOf(element))||priority.get(String.valueOf(element))>priority.get(stack.peek())){ stack.push(String.valueOf(element)); }else { //element优先级比栈顶优先级低 栈顶元素出来，此元素进去，有个循环迭代 suffix.append(stack.pop()); //栈顶元素出来 inputOrOutputStack(element); //该元素进去 } } } } private static boolean isNum(char c){ if (c>='0'&amp;&amp;c&lt;='9'||c=='.'){ return true; }else { return false; } } public double suffixConculate(String value){ char temp=' '; double anster=0; for (int i=0;i&lt;value.length();i++){ temp=value.charAt(i); if (isNum(temp)){ //数字进栈 stack.push(String.valueOf(temp)); }else if (!stack.isEmpty()){ //不是数字 取值 double num2=Double.valueOf(stack.pop()); double num1=Double.valueOf(stack.pop()); stack.push(String.valueOf(conculate(num1,num2,temp))); } } return Double.parseDouble(stack.pop()); } private double conculate(double num1, double num2, char operate){ double result=0; switch (operate){ case '+': result=num1+num2; break; case '-': result=num1-num2; break; case '*': result=num1*num2; break; case '/': result=num1-num2; break; default: System.out.println("老哥，你操作符有问题！"); break; } return result; } public double getAnswer(String value){ return suffixConculate(inffixToSuffix(value)); } } Testpackage stack_queue.stack.fourExpressions; public class Test { public static void main(String[] args) { FourExpressions&lt;String> expressions = new FourExpressions&lt;>(); System.out.println(expressions.inffixToSuffix("8+(9-1)*8+7+2")); System.out.println(expressions.getAnswer("8+(9-1)*8+7/2")); } } 测试891-8*+72/+ 77.0]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-链栈]]></title>
    <url>%2F2019%2F04%2F29%2Fda-hua-shu-ju-jie-gou-lian-zhan%2F</url>
    <content type="text"><![CDATA[biubiubiu，不难，就是有点麻烦，多种实现方式不能混了 Nodepackage stack_queue.stack.listStack; public class Node&lt;T> { private T data; private Node next; public Node(T data) { this.data = data; } public Node(T data, Node next) { this.data = data; this.next = next; } public T getData() { return data; } public void setData(T data) { this.data = data; } public Node getNext() { return next; } public void setNext(Node next) { this.next = next; } } ListStackpackage stack_queue.stack.listStack; public interface ListStack&lt;T> { //插入栈顶元素 public void push(T value); //输出栈顶元素 public T pop(); //判断栈是否为空 public boolean isEmpty(); //判断栈是否满 public boolean isFull(); //获取栈内元素个数 public int getLength(); //打印栈内元素 public String travel(); } MyListStackpackage stack_queue.stack.listStack; /** * 分析： * 链栈 用链表实现 ，栈的数据结构 * 组成部分： * 1. 节点 ：存储数据，指向下一个节点的指针 * 2. 链表的头节点要不要？ * 3. 栈顶指针，放在那里？链的头部还是尾部 * 合并头节点和 栈顶指针 * 4. 栈顶标识，0 还是-1 都可以存储在栈顶节点里面，里面还可以存放链栈的存有元素的长度，随之变化，不过相对麻烦一些，这里用一个size代替 * @param &lt;T> */ public class MyListStack&lt;T> implements ListStack&lt;T>{ private Node top; private static int max_size=10; //默认栈大小为10 private int size=0;//存放节点个数 public MyListStack() { this(max_size); } public MyListStack(int max_size){ if (max_size>=0){ this.max_size=max_size; this.top=new Node(null,null); } } @Override public void push(T value) { if (!isFull()){ top.setNext(new Node(value,top.getNext())); size++; }else { System.out.println("栈满了，小老弟！"); } } @Override public T pop() { if (!isEmpty()){ Object data = top.getNext().getData(); //获取栈顶元素的值 top.setNext(top.getNext().getNext()); //修改栈顶元素 size--; return (T) data; }else { return (T) "栈空了，小老弟！"; } } @Override public boolean isEmpty() { return size==0; } @Override public boolean isFull() { return size==max_size; } @Override public int getLength() { return size; } @Override public String travel() { StringBuffer sb=new StringBuffer(); Node tempNode=top.getNext(); while (tempNode!=null){ sb.append(tempNode.getData()); sb.append(" "); tempNode=tempNode.getNext(); } return sb.toString(); } } Testpackage stack_queue.stack.listStack; public class Test { public static void main(String[] args) { ListStack&lt;String> listStack = new MyListStack&lt;>(3); System.out.println(listStack.isEmpty()); listStack.push("a"); listStack.push("b"); listStack.push("c"); listStack.push("d"); listStack.push("e"); System.out.println(listStack.travel()); listStack.pop(); System.out.println(listStack.travel()); System.out.println(listStack.getLength()); System.out.println(listStack.isFull()); } } 结果true 栈满了，小老弟！ 栈满了，小老弟！ c b a b a 2 false 进程完成，退出码 0]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-顺序栈]]></title>
    <url>%2F2019%2F04%2F29%2Fda-hua-shu-ju-jie-gou-shun-xu-zhan%2F</url>
    <content type="text"><![CDATA[蛮简单的一种数据结构，栈先进后出 栈顶指针 ，顺序栈使用数组实现 SequenceStackpackage stack_queue.stack.SequenceStack; public interface SequenceStack&lt;T> { //插入栈顶元素 public void push(T value); //输出栈顶元素 public T pop(); //判断栈是否为空 public boolean isEmpty(); //判断栈是否满 public boolean isFull(); //获取栈内元素个数 public int getLength(); //打印栈内元素 public String travel(); } MySequenceStackpackage stack_queue.stack.SequenceStack; /** * 分析： * 1. 顺序栈 使用数组实现 所以数组存储的数据类型要一致 * 2. 栈，先进后出 ，组成部分：栈顶指针 * * 思考： * 1. 栈怎么表示：数组，栈顶指针，栈大小 * 2. 栈顶指针指向哪里？ 两种情况，1. 指向栈顶元素 开始top=-1 （这里采用这个） 2. 指向栈顶的上一个元素 开始top=0 * 3. 栈空怎么判断 top==-1 * 4. 栈满怎么判断 top==max_size * @param &lt;T> */ public class MySequenceStack&lt;T> implements SequenceStack&lt;T> { private T data[]; private static int max_size=10; //默认栈大小为10 public int top; //栈顶指针 指向栈顶元素 public MySequenceStack() { /** * 思考为甚什么不能用new T[max_size] * 1. 这是由于数组不能使用泛型，数组要求确定数据类型，而T是不确定的 * 2. 如果是T类型就意味着该数组可以插入任何数据类型 和数组的定义不符合 */ this(max_size); //调用有参构造函数，减少代码量 } public MySequenceStack(int max_size){ if(max_size>=0){ this.data= (T[]) new Object[max_size]; this.max_size=max_size; top=-1; }else { System.out.println(max_size+"溢出！"); } } @Override public void push(T value) { if (!isFull()){ /** * 这里注意要先加加 在赋值 ，否则会出错 * 如果是top=0为栈空的标准 可以top++ */ data[++top]=value; System.out.println(value+"成功入栈！"); }else { System.out.println("栈满，无法入栈"); } } @Override public T pop() { if (!isEmpty()){ //注意先输出，在减减 return data[top--]; }else { return (T) "栈空！无法出栈"; //思考为什么要转换 } } @Override public boolean isEmpty() { return top == -1 ? true : false; } @Override public boolean isFull() { return top == max_size-1 ? true : false; } @Override public int getLength() { return top+1; } @Override public String travel() { StringBuffer sb=new StringBuffer(); if(top>=0){ for (int i=top;i>=0;i--){ sb.append(data[i]); sb.append(" "); } }else { sb.append("栈内元素为空"); } return sb.toString(); } } Testpackage stack_queue.stack.SequenceStack; public class Test { public static void main(String[] args) { SequenceStack sequenceStack = new MySequenceStack(); sequenceStack.push("a"); sequenceStack.push("b"); sequenceStack.push("c"); sequenceStack.push("d"); sequenceStack.push("e"); System.out.println(sequenceStack.travel()); sequenceStack.pop(); System.out.println(sequenceStack.travel()); System.out.println(sequenceStack.getLength()); } } 结果：a成功入栈！ b成功入栈！ c成功入栈！ d成功入栈！ e成功入栈！ e d c b a d c b a 4 进程完成，退出码 0]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-双向循环链表]]></title>
    <url>%2F2019%2F04%2F28%2Fda-hua-shu-ju-jie-gou-shuang-xiang-xun-huan-lian-biao%2F</url>
    <content type="text"><![CDATA[两种数据结构结合到一起，循环链表＋双向链表，LinkedList底层就是双向链表 Nodepackage bothway_circulation; public class Node&lt;T> { private Node pre; private T data; private Node next; public Node getPre() { return pre; } public void setPre(Node pre) { this.pre = pre; } public T getData() { return data; } public void setData(T data) { this.data = data; } public Node getNext() { return next; } public void setNext(Node next) { this.next = next; } public Node() { } public Node(T data) { this.data = data; } public Node(Node pre, T data, Node next) { this.pre = pre; this.data = data; this.next = next; } @Override public String toString() { StringBuffer sb=new StringBuffer(); sb.append(data); return sb.toString(); } } BothWayCriculetionList package bothway_circulation; public interface BothWayCriculetionList&lt;T> { /** * 添加节点数据 默认添加到链表尾部 * @param value * @return */ public void addNode(T value); /** * 指定节点添加数据 * @param index * @param value * @return */ public void addNodeByIndex(int index,T value); /** * 修改指定位置的元素 * @param index * @param value * @return */ public void updateNode(int index , T value); /** * 获取双向链表的长度 * @return */ public int getLength(); /** * 获取指定位置的节点 * @param index * @return */ public Node&lt;T> getNodeByindex(int index); /** * 打印节点数据 * @return */ public String travel(); /** * 删除指定位置的数据 * @param index * @return */ public T deleteNode(int index); } MyBothWayCriculetionListpackage bothway_circulation; public class MyBothWayCriculetionList&lt;T> implements BothWayCriculetionList&lt;T> { Node&lt;T> head;//头节点不存放数据 private int size=0; //链表长度 /** * 初始化头节点 */ public MyBothWayCriculetionList() { head=new Node&lt;>(null); head.setPre(head); head.setNext(head); } @Override public void addNode(T value) { addNodeByIndex(size,value); } @Override public void addNodeByIndex(int index, T value) { //判断插入点是否溢出 //check(index); size=size+1; //找到要插入位置的node节点 该节点会被挤下去 Node&lt;T> oldNode = getNodeByindex(index); /** * 此处很巧妙 利用构造函数 生成新节点 既有前一个节点位置，又有下一个节点的位置 */ Node&lt;T> newNode=new Node&lt;>(oldNode.getPre(),value,oldNode); oldNode.getPre().setNext(newNode); //旧节点的上一个节点的位置的下一个节点指向新节点 oldNode.setPre(newNode); //更新旧节点的前一个节点为新节点 } @Override public void updateNode(int index, T value) { Node&lt;T> node=getNodeByindex(index); node.setData(value); } @Override public int getLength() { return size; } /** * 此处可以优化为二分查找 * @param index * @return */ @Override public Node&lt;T> getNodeByindex(int index) { //检查是否溢出 check(index); Node&lt;T> node=head.getNext(); //注意head只是头节点，不存储数据，不算在链表中 for (int i=0;i&lt;index;i++){ node=node.getNext(); } return node; } @Override public String travel() { StringBuffer sb=new StringBuffer(); Node&lt;T> node=head.getNext(); //此时node是链表的第一个节点 while (node!=head){ sb.append(node.getData()); sb.append(" "); node=node.getNext(); } return sb.toString(); } @Override public T deleteNode(int index) { check(index); Node&lt;T> node=getNodeByindex(index); node.getPre().setNext(node.getNext()); node.getNext().setPre(node.getPre()); size--; return node.getData(); } /** * 检查链表溢出，溢出报错 * 思考为什么是index>=size * size是从1开始计算的 只有一个节点，长度就是1 * index 是从0开始计算的 * 两种情况 * 尾节点插入 此时我们使用addNodeByindex(size,value); 不用这个检验 包含第一次插入 和尾节点插入两种情况 * 不是尾节点插入 检验长度 * @param index * @throws IndexOutOfBoundsException */ private void check(int index) throws IndexOutOfBoundsException{ if (index>=size||index&lt;0) throw new IndexOutOfBoundsException(); } } Testpackage bothway_circulation; import java.util.LinkedList; public class Test { public static void main(String[] args) { MyBothWayCriculetionList&lt;String> list = new MyBothWayCriculetionList&lt;>(); list.addNode("甲"); list.addNode("乙"); list.addNode("丙"); list.addNode("丁"); list.addNode("戊"); list.addNode("己"); list.addNode("庚"); list.addNode("辛"); list.addNode("壬"); list.addNode("奎"); System.out.println(list.travel()); list.addNodeByIndex(5,"你爸爸"); System.out.println(list.travel()); list.updateNode(5,"彭俊是我儿子"); System.out.println(list.travel()); list.deleteNode(5); System.out.println(list.travel()); System.out.println(list.getNodeByindex(5).toString()); System.out.println(list.getLength()); } } 结果甲 乙 丙 丁 戊 己 庚 辛 壬 奎 甲 乙 丙 丁 戊 你爸爸 己 庚 辛 壬 奎 甲 乙 丙 丁 戊 彭俊是我儿子 己 庚 辛 壬 奎 甲 乙 丙 丁 戊 己 庚 辛 壬 奎 己 10]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-静态链表]]></title>
    <url>%2F2019%2F04%2F28%2Fda-hua-shu-ju-jie-gou-jing-tai-lian-biao%2F</url>
    <content type="text"><![CDATA[静态链表是一种很神奇的数据结构，拥有数组的数据结构，但是解决了数组的数据移动消耗大的问题，但是他失去了顺序结构随机u才存取的特性 静态链表的结构数据的存储是通过数组实现的，每个节点存在数据域和指针域（指向下一个节点的数组地址）。 数组的头节点指向备用链表（备用链表：不存放数据的节点组成的链表）的头节点。 数组的尾节点指向数据链表的头节点 数据链表的尾节点指向数组的头节点 分析思考在代码里 代码Node package lianbiao.staticLinked; /** * 分析节点结构，为什么是cur是int而不是Node 区分单链表 * 单链表的cur是指向下一个节点，而这里cur是只想一个一个节点的数组地址 * @param &lt;T> */ public class Node&lt;T> { //数据域 T data; //指针域 int cur; public Node() { } public Node(T data) { this.data = data; } public Node(T data, int cur) { this.data = data; this.cur = cur; } @Override public String toString() { StringBuffer sb=new StringBuffer(); sb.append(data); sb.append(" "); sb.append(cur+" "); return sb.toString(); } } StaticLinked package lianbiao.staticLinked; /** * 接口类 * 功能： * 添加节点数据 尾插法 * 删除节点数据 * 修改节点数据 * 打印节点数据 * 获取链表长度 */ public interface StaticLinked&lt;T>{ /** * 尾插 * @param value * @return */ public boolean addNode(T value); /** * 指定位置添加节点数据 * 分析：需要先从备用链表申请节点空间，再存放数据 * @param value */ public boolean addNodeByIndex(int index ,T value); /** * 删除节点数据 注意删除后节点空间需要回收到备用链表 * @param index */ public T deleteNode(int index); /** * 修改指定节点的数据 * @param index * @param newValue */ public boolean updateNode(int index,T newValue); /** * 打印链表数据 */ public String travel(); /** * 获取存有数据链表的长度 */ public int getLength(); /** * 从备用链表申请地址空间，用于存放数据 * @return */ public int applySpareAddr(); /** * 回收空闲地址空间，主要用于删除元素的时候，需要将地址空间回收到备用链表 * @param addr 回收节点的数组地址 * @return */ public T recoverSpaceAddr(int addr); } MyStaticLinked package lianbiao.staticLinked; /** * 分析：c里面静态链表用数组实现，有数据域和指针，需要初始化大小，牺牲数据的随机存储换取数据写操作的快捷 * 静态链表结构： * 1. 结构使用数组 * 2. 数组的头节点作为指向备用链表的地址 不存放数据 * 3. 数组的尾节点指向数据链表的头节点的地址 不存放数据 * 4. 数据链表的尾节点指向数组的头节点地址 * * 分析概念： * 数据链表：存放有数据的链表 * 备用链表：没有存放数据的链表 * 空闲空间：存在两种情况，1. 数组没有初始化的时候，但是刚开始就初始化了，不存在的 2. 删除节点数据的时候，就会被回收到备用链表 不存在的 * * 使用java实现 核心地方 *1. 节点怎么表示？ *2. 怎么区分数据链表和备用链表 * @param &lt;T> */ public class MyStaticLinked&lt;T> implements StaticLinked&lt;T>{ private Node[] nodes; //链表数组 private static final int max_size=15; //默认链表长度 //构建备用链表 public MyStaticLinked() { this(max_size); } //构建备用链表 public MyStaticLinked(int max_size) { this.nodes=new Node[max_size]; //创建泛型数组列表 //每个节点需要初始化 for (int i=0;i&lt;max_size-1;i++){ //此处分析静态链表结构，分析为什么max_size-1 nodes[i]=new Node&lt;T>(null,i+1); } //尾节点指向头节点的地址 nodes[max_size-1]=new Node&lt;T>(null,0); } /** * 尾插法 * 寻找数据链表的尾部 * @param value * @return */ @Override public boolean addNode(T value) { return addNodeByIndex(getLength(),value); } /** * 如何实现？ * 需要有地址空间？ 从备用链表申请地址空间， * 怎么获取？ 头节点指向的地址空间 * 区分 是指数组插入点的前一个数据节点还是数据链表插入点的地点 ，这里是数据链表插入点的地点的前一个节点 * * 问题： * 第一次插入和中间插入的区别 分别处理还是统一处理？ * 第一次插入需要插入到链表的头部 修改数组尾节点指向该地址 * 中间插入 只需要插入 修改插入点前一个节点指向的节点 修改新建节点指向的下一个节点 * 中间插入 插入在链表的头节点 插入 修改数组尾节点指向链表的头节点 * * 解决办法： * 区分插入点是否为链表的头节点 * 如果插入点是头节点 则需要修改数组尾节点指向的地址 * 否则直接插入 插入中间无所谓 没有指定插入点 就 尾插法 * * 需要实现的点： * * @param value */ @Override public boolean addNodeByIndex(int index ,T value) {//这里的index指数据链表的插入点 int flag=max_size-1; //数尾节点的位置 if (index>max_size-1){ return false; } int length=getLength(); //解决链表头插的问题 if (index&lt;1){ index=1; } if (index>=length){//超出长度的按尾插法 地址的尾巴 链表的头部 index=length+1; } int addr = applySpareAddr(); //申请添加节点的地址空间 if (addr>0){ nodes[addr].data=value; //节点赋值 for (int i=1;i&lt;index;i++){ flag=nodes[flag].cur; } nodes[addr].cur=nodes[flag].cur; nodes[flag].cur=addr; return true; } return false; /** * 失败的尝试三 */ //插入点范围判断 剔除错误的插入点 /** * 策略： * 小于0 超出索引 错误 * 大于数据链表的长度，插入到数据链表的尾节点 */ // int length = getLength(); // if (index&lt;0){ // return false; // } // // //创建节点 // Node&lt;T> newNode = new Node&lt;>(value, 0);//此处的index代表什么？ 目前没有审核作用 // //申请节点空间 // int addr = applySpareAddr(); // // if (index>length){ //尾节点插入 // index=length+1; // //寻找尾节点，将尾节点的值指向该节点，修改该节点的值。 // int flag=max_size-1; // while (nodes[flag].cur!=0){ // flag=nodes[flag].cur; // } // nodes[flag].cur=addr; // }else { //非尾节点插入 // if(index==0){ // //头节点插入 // nodes[max_size-1].cur=addr; // }else{ // int flag=max_size-1; // //中间插入 // for (int i=0;i&lt;index;i++){ // flag=nodes[flag].cur; // } // } // // } /** * 1. 判断是否是头节点插入 * 2. 判断是否是第一次插入 * * 如何判断 * if(index==0) 说明是头节点插入 * 判断是否是第一次插入 用length * else 说明不是头节点插入 * 判断是中间插入 还是尾节点插入 用length * * 优化 * 先判断是否是尾节点添加 怎么判断？ 用length * 在判断是否是头节点添加 */ /** * 失败的尝试2 */ // if (index==0){ // if (length==0){ // //第一次插入 // nodes[addr]=newNode; // //修改数组尾节点指向数据链表的头节点 // nodes[max_size-1].cur=addr; // return true; // }else { // //说明插入点为头节点 但是之前数据链表存在数据 新建节点的下一个节点指向原数据链表的头节点 // nodes[addr].cur=nodes[max_size-1].cur; // nodes[max_size-1].cur=addr; // return true; // } // }else { // /** // * 数据链表中间插入 // * 策略： // * 1. 寻找前一个节点 // * 2. 修改节点指向 // */ // int flag=nodes[max_size-1].cur; // for (int i=0;i&lt;index;i++){ //循环寻找指定位置的头节点 // flag=nodes[flag].cur; // } // newNode.cur=nodes[flag].cur; // nodes[flag].cur=addr; // return true; // } /** * 失败的尝试一 */ // int length = getLength(); //获取节点的长度 // if (index>=length+1){ //超出可以存放数据链表的索引 // return false; // } //申请地址空间 // int addr = applySpareAddr(); // // //遍历数据链表 找到插入点的前一个节点和下一个节点，修改节点的索引位置 // int flag=max_size-1; // /** // * 此处逻辑问题， // */ // while (nodes[flag].cur!=0){//循环遍历，直到是尾节点结束 // if (flag==index){ //数据链表位置匹配 // int temp=nodes[flag].cur; //中间值，存储匹配上数据链表节点的下一个节点的索引 // nodes[flag].cur=addr; //将匹配上的节点的下一个节点修改到新建节点的地址 // nodes[addr]=new Node(value,index); //将输入插入数组空间内 // nodes[addr].cur=temp; //新建节点的地址指向数据链表插入点的下一个节点 // return true; // } // flag=nodes[flag].cur; // } } /** * 删除指定位置元素 * @param index */ @Override public T deleteNode(int index) { if (index>max_size-1){ //超出数组大小 return null; } int length=getLength(); if (index&lt;1){ //索引小于1 删除头节点 index=1; } if (index>length){ //超出链表索引大小删除尾结点 index=length+1; } //找到要删除节点的地址 int flag=max_size-1; for (int i=1;i&lt;index;i++){//找到要删除节点的前一个节点的地址 flag=nodes[flag].cur; } //要删除节点地址 int m=nodes[flag].cur; //nodes[m].cur 要删除节点的下一个节点 nodes[flag].cur=nodes[m].cur; return recoverSpaceAddr(m); } /** * 修改指定节点的数据 * @param index * @param newValue * @return */ @Override public boolean updateNode(int index,T newValue){ int length=getLength(); if (index&lt;1||index>length){ return false; } int flag=max_size-1; for(int i=0;i&lt;index;i++){ flag=nodes[flag].cur; } nodes[flag].data=newValue; return true; } @Override public String travel() { StringBuffer sb=new StringBuffer(); sb.append("["); sb.append(nodes[0]+" "); int k=nodes[max_size-1].cur; while (k!=0){ sb.append(nodes[k]); k=nodes[k].cur; } sb.append(nodes[max_size-1]+" "); sb.append("]"); return sb.toString(); } /** * 获取存有数据的节点数量，也就是已经使用的节点空间长度 * 为什么要有这个？ * 1. 用户需要知道 * 2. 在尾插的时候，需要获取链表最后节点的地址，以便最后节点的更新 * * 如何实现？ * 存有数据的链表的头节点怎么获取？ 从数组的尾节点获取 * @return */ @Override public int getLength() { int tailNode=nodes[max_size-1].cur; int length=0; while (tailNode!=0){ tailNode=nodes[tailNode].cur; length++; } return length; } /** * 从备用链表申请节点空间 * 分析：刚开始时，备用链表的节点空间是头节点的下一个节点，申请节点空间后应该更新节点空间，同时删除节点也需要更新节点空间 * @return */ @Override public int applySpareAddr() { int spareIndex=nodes[0].cur; if (spareIndex!=0){ //更新备用链表节点空间地址 nodes[0].cur=spareIndex+1; } return spareIndex; } /** * 回收节点，将该节点插入到备用链表的的头部 * 返回删除节点的数据 */ @Override public T recoverSpaceAddr(int addr) { T temp= (T) nodes[addr].data; nodes[addr].cur=nodes[0].cur; nodes[0].cur=addr; return temp; } /** * 顺序输出链表数据 * @return */ public String return_trace(){ StringBuffer sb=new StringBuffer(); int flag=max_size-1; int length=getLength(); for (int i=0;i&lt;=length;i++){ sb.append(nodes[flag].data); sb.append(" "); flag=nodes[flag].cur; } return sb.toString().substring(5); } } Test package lianbiao.staticLinked; import java.util.HashMap; public class Test { public static void main(String[] args) { MyStaticLinked&lt;String> list = new MyStaticLinked&lt;>(); list.addNode("甲"); list.addNode("乙"); list.addNode("丙"); list.addNode("丁"); list.addNode("戊"); list.addNode("己"); list.addNode("庚"); list.addNode("辛"); list.addNode("壬"); list.addNode("奎"); System.out.println(list.return_trace()); System.out.println(list.travel()); System.out.println(list.getLength()); System.out.println(); list.addNodeByIndex(5,"你爸爸"); System.out.println(list.return_trace()); System.out.println(list.travel()); System.out.println(list.getLength()); System.out.println(); list.deleteNode(3); System.out.println(list.return_trace()); System.out.println(list.travel()); System.out.println(list.getLength()); System.out.println(); list.updateNode(4,"而杂"); System.out.println(list.return_trace()); System.out.println(list.travel()); System.out.println(list.getLength()); System.out.println(); list.addNodeByIndex(1,"而杂"); System.out.println(list.return_trace()); System.out.println(list.travel()); System.out.println(list.getLength()); System.out.println(); } } 结果 甲 乙 丙 丁 戊 己 庚 辛 壬 奎 [null 11 甲 2 乙 3 丙 4 丁 5 戊 6 己 7 庚 8 辛 9 壬 10 奎 0 null 1 ] 10 甲 乙 丙 丁 你爸爸 戊 己 庚 辛 壬 奎 [null 12 甲 2 乙 3 丙 4 丁 11 你爸爸 5 戊 6 己 7 庚 8 辛 9 壬 10 奎 0 null 1 ] 11 甲 乙 丁 你爸爸 戊 己 庚 辛 壬 奎 [null 3 甲 2 乙 4 丁 11 你爸爸 5 戊 6 己 7 庚 8 辛 9 壬 10 奎 0 null 1 ] 10 甲 乙 丁 而杂 戊 己 庚 辛 壬 奎 [null 3 甲 2 乙 4 丁 11 而杂 5 戊 6 己 7 庚 8 辛 9 壬 10 奎 0 null 1 ] 10 而杂 甲 乙 丁 而杂 戊 己 庚 辛 壬 奎 [null 4 而杂 1 甲 2 乙 4 丁 11 而杂 5 戊 6 己 7 庚 8 辛 9 壬 10 奎 0 null 3 ] 11 进程完成，退出码 0]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-单链表]]></title>
    <url>%2F2019%2F04%2F28%2Fda-hua-shu-ju-jie-gou-dan-lian-biao%2F</url>
    <content type="text"><![CDATA[单链表的实现 单链表一般有两种 有头节点，没有头节点 相对来说用有头节点的实现算法简单一些，过程可以通用，没有头节点麻烦些，容易出问题 这里实现的是没有头节点，有一些bug，第一次写，请多多指教 代码如下，相关思考也在注释中 Node类 package lianbiao.singleLinked; public class Node&lt;T> { //数据域 T data; //指针域 Node&lt;T> next; public Node() { } public Node(T data) { this.data = data; } } MyLinked类 package lianbiao.singleLinked; /** * 链表要素 * 头节点 可以不要，头节点又不存放数据 * 数据域 * 指针与 */ public class MyLinked&lt;T> { //头节点 链表就是用头节点表示的 Node&lt;T> head; public MyLinked() { } //尾部添加节点 尾插法 也可以用头插法。 public void addNode(T value){ //判断是否是头节点 Node newNode=new Node(value); if (head==null){ head=newNode; }else { /** * 问题： * 区分头节点的下一个节点和尾节点的下一个节点 */ //寻找尾节点 ，将节点添加到尾节点 如何寻找尾结点？ Node temp=head;//移动节点，代表链表 ，不影响原链表 用于链表的移动 while (temp.next!=null){//指向下一个节点的位置为空 temp=temp.next;//往后移动节点 } temp.next=newNode;//当前节点的下一个节点指向新节点 } } //删除指定节点 public void deleteNode(T value){ //判断链表是否为空 if (head == null){ return; } Node temp=head;//移动节点 //匹配节点 while (temp.next!=null){ /** * 问题：当前节点能匹配的上吗？ * 测试结果：不能删除头节点数据， * 分析：头节点是存放了数据，但是在删除的时候从头节点开始找头节点下的数据，进行匹配，忽略了头节点 * 优化：链表结构最后有个头节点 */ if (value.equals(temp.next.data)){ // 匹配当前结点的下一个节点数据是否与当前节点相等 temp.next=temp.next.next; break;//退出循环 } temp=temp.next; //移动节点移动 } } //修改节点 public boolean updateNode(T originalValue,T newValue){ boolean flag=false; //判断链表是否为空 if (head == null){ return flag; } Node temp=head;//移动节点 //匹配节点 while (temp.next!=null){ if (originalValue.equals(temp.next.data)){ // 匹配当前结点的下一个节点数据是否与当前节点相等 temp.next.data=newValue; flag=true; } temp=temp.next; //移动节点移动 } return flag; } public int getLength(){ int flag=1; if (head==null){ return 0; } Node temp=head; /** * 问题：头节点带来的问题！！！没有统计第一个节点 */ while (temp.next!=null){ flag++; temp=temp.next; } return flag; } //打印链表 public void travel(){ Node n=head; while (n!=null){ System.out.print(n.data+", "); n=n.next; } } } Test类 package lianbiao.singleLinked; public class Test { public static void main(String[] args) { MyLinked&lt;Integer> myLinked = new MyLinked&lt;>(); myLinked.addNode(1); myLinked.addNode(2); myLinked.addNode(3); myLinked.addNode(4); myLinked.travel(); System.out.println(); myLinked.deleteNode(3); myLinked.travel(); System.out.println(); myLinked.updateNode(2,10); myLinked.travel(); System.out.println(); System.out.print(myLinked.getLength()); } } 结果 1, 2, 3, 4, 1, 2, 4, 1, 10, 4, 3 进程完成，退出码 0]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL主从复制&主主复制]]></title>
    <url>%2F2019%2F04%2F27%2Fmysql-zhu-cong-fu-zhi-zhu-zhu-fu-zhi%2F</url>
    <content type="text"><![CDATA[科普一下，说不定面试就问了，哈哈哈 英语词汇slave 奴隶 复制原理概述 复制是将主数据库的DML 操作通过日志传到从服务器上，使得从服务器实现了对主服务器的远程备份，并且可以通过应用使得在主服务器繁忙的时候分担一部分负载。mysql 支持同时向多台从服务器进行复制。缺点：不能保证主从同步，只能实现异步复制。 有三种复制架构，解决问题一次递增 主从架构（一主多从）：解决主库请求压力大，将请求分给从库，只负责写操作 多级复制架构：解决主从架构下，主库写的压力大 主主架构：维护的时候使用 原理1.数据库有个bin-log二进制文件，记录了所有sql语句。 2.我们的目标就是把主数据库的bin-log文件的sql语句复制过来。 3.让其在从数据的relay-log重做日志文件中再执行一次这些sql语句即可。 4.下面的主从配置就是围绕这个原理配置 5.具体需要三个线程来操作： binlog输出线程：每当有从库连接到主库的时候，主库都会创建一个线程然后发送binlog内容到从库。在从库里，当复制开始的时候，从库就会创建两个线程进行处理： 从库I/O线程：当START SLAVE语句在从库开始执行之后，从库创建一个I/O线程，该线程连接到主库并请求主库发送binlog里面的更新记录到从库上。从库I/O线程读取主库的binlog输出线程发送的更新并拷贝这些更新到本地文件，其中包括relay log文件。 从库的SQL线程：从库创建一个SQL线程，这个线程读取从库I/O线程写到relay log的更新事件并执行。可以知道，对于每一个主从复制的连接，都有三个线程。拥有多个从库的主库为每一个连接到主库的从库创建一个binlog输出线程，每一个从库都有它自己的I/O线程和SQL线程。 主从复制如图： 步骤一：主库db的更新事件(update、insert、delete)被写到binlog 步骤二：从库发起连接，连接到主库 步骤三：此时主库创建一个binlog dump thread线程，把binlog的内容发送到从库 步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log。 步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db，当relay log读取完之后就会被删除。 三种复制方式BinlogStatement:基于SQL语句的记录 Row：基于行级别的记录，每行数据的变化都会记录到Binlog日志文件中，不记录SQL语句，不会因为存储过程、触发器造成主从数据不一致问题，占存储空间，比Statement更能保证数据一致性 Mixed：混合模式，上面两个混合 主从复制(Master-Slave)什么是主从复制？主从复制，也叫一主多从复制架构，是用来建立一个和主数据库完全一样的数据库环境，称为从数据库；主数据库一般是准实时的业务数据库。 针对实时性要求不高的 主从复制的作用（好处，或者说为什么要做主从）重点1、做数据的热备，作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作，避免数据丢失。 2、架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。 3、读写分离，使数据库能支撑更大的并发。在报表中尤其重要。由于部分报表sql语句非常的慢，导致锁表，影响前台服务。如果前台使用master，报表使用slave，那么报表sql将不会造成前台锁，保证了前台速度。 主从复制的原理（重中之重，面试必问）：就是上面说的复制原理 架构图 双主架构解决一主多从的情况下，主库维护的带来的额外建从库的工作 所有的写操作访问Master1，所有的读操作访问Master1、Master2 DBA维护 关闭Master1的Slave线程 关闭Master2的Slave线程，开始维护Master2. Master2维护完之后，开启Master2的Slave线程，同步Master1的数据。切换写操作到Master2 确认Master1没有访问的时候，开启Master1的Slave线程 这样就完成了对Master2的维护，同样也可以对Master1的维护 多级复制架构解决问题：解决一主多从的情况下，主库写压力大的情况 在一主多从之间添加一个二级主库Master2，Master2不负责读写操作，只负责尽快将binlog传给从库，减少主库Master1的发送Binlog的压力，Master2使用BLACKHOLE引擎 带来问题：多级传递使延时增高 复制种类## 异步复制（Asynchronous replication）MySQL默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。 全同步复制（Fully synchronous replication）指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。 半同步复制（Semisynchronous replication）介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。 ##]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA顺序表]]></title>
    <url>%2F2019%2F04%2F22%2Fjava-shun-xu-biao%2F</url>
    <content type="text"><![CDATA[java实现顺序表 分析顺序表是什么样，有什么特征？ 顺序表是用一段连续的存储单元依次存储线性表的数据元素 划重点，是连续的存储单元，那么我们java用什么表示呢？毫无疑问使用数组 Q：那么我们怎么用数组表示呢？或者说数组有哪些特征呢？ 首先数组是连续的存储单元顺序存储的，它有容量大小限制，他有存储类型的限制，他有下标，他是一种随机存储结构，他的时间性能是O(1)。其次，我们需要对数组初始化，那么需要哪些内容？毫无疑问是上面说的东西。一旦数组被初始化就不能改变其大小、存储类型。 有哪些功能？既然我们知道了用数组表示顺序表，并且知道了他是怎么初始化的，那么我们怎么利用他实现哪些功能呢？ 我们都知道最常见的是CRUD操作，就是增删改查。当然不会只有这些功能，根据我们使用的情况，有扩展出其他功能，比如获取数组当前 长度，获取指定位置的元素，匹配元素的位置等等，可以对边Array的源码。但是基础的功能无疑是CRUD 不多废口舌，挂出功能 * 1.初始化顺序表 * 2.判断顺序表是否为空 * 3.获取顺序表元素个数 * 4.获取指定位置元素 * 5.插入元素 * 6.删除元素 * 7.修改元素 * 8.匹配元素 * 9.清空顺序表 实现接口类package chapter; import java.util.ArrayList; /** * 思路： * 完成功能：模仿ArrayList * 1.初始化顺序表 * 2.判断顺序表是否为空 * 3.获取顺序表元素个数 * 4.获取指定位置元素 * 5.插入元素 * 6.删除元素 * 7.修改元素 * 8.匹配元素 * 9.清空顺序表 * * 问题： * 1. 线性表表示：数组(特点有值和下表,连续存储) */ public interface MyArrayListInterface { /** * 初始化顺序表 * @return */ public void initList(int size); /** * 判断顺序表是否为空 * @return */ public boolean isEmpty() throws Exception; /** * 获取顺序表元素个数 * @return */ public int getLength() throws Exception; /** * 获取指定位置的元素 * @param index * @return */ public Object getElment(int index) throws Exception; /** * 插入元素 * @param value */ public void insertElement(int index, Object value) throws Exception; /** * 删除指定位置的元素 * @param index */ public void deleteElement(int index) throws Exception; /** * 修改指定位置元素 * @param index * @param value * @return */ public void updateElement(int index,Object value) throws Exception; /** * 匹配指定元素 返回指定元素的位置 * @param value * @return */ public int equipElment(Object value) throws Exception; /** * 顺序表的清空 */ public void clearList() throws Exception; } 功能实现类package chapter; /** * 变量： * 数组对象 * 当前长度 * 最大长度 * * * 实现顺序表功能 * 1.初始化顺序表 * 2.判断顺序表是否为空 * 3.获取顺序表元素个数 * 4.获取指定位置元素 * 5.插入元素 * 6.删除元素 * 7.修改元素 * 8.匹配元素 * 9.清空顺序表 */ public class MyArrayList implements MyArrayListInterface { /** * 默认顺序表长度 */ private final int defaultSize=10; /** * 顺序表对象，存储数据 */ private Object[] myArrayList; /** * 最大顺序表长度，用于初始化 */ private int maxSize; /** * 当前顺序表长度 */ public int curSize; public MyArrayList() { initList(defaultSize); } public MyArrayList(int index) { initList(index); } @Override public void initList(int size) { this.maxSize=size; this.curSize=0; this.myArrayList=new Object[maxSize]; } @Override public boolean isEmpty() throws Exception { return curSize==0; } @Override public int getLength() throws Exception { return curSize; } @Override public Object getElment(int index) throws Exception { //判断插入元素位置是否正确 if ( index&lt;0 || index>maxSize){ throw new Exception("error:index溢出！"); } return myArrayList[index]; } @Override public void insertElement(int index,Object value) throws Exception { //判断顺序表是否满了 if (curSize==maxSize){ throw new Exception("error:顺序表为空，无法添加元素"); } //判断插入元素位置是否正确 if ( index&lt;0 || index>maxSize){ throw new Exception("error:index溢出！"); } //判断是否在表尾部 if(index&lt;curSize){ for (int k=curSize;k>index-1;k--){ myArrayList[k+1]=myArrayList[k];//插入位置的元素往后移动 } } myArrayList[index]=value; curSize++; } @Override public void deleteElement(int index) throws Exception { //判断插入元素位置是否正确 if ( index&lt;0 || index>maxSize){ throw new Exception("error:index溢出！"); } for (int k=index;k&lt;curSize-1;k++){ myArrayList[k]=myArrayList[k+1]; } curSize--; } @Override public void updateElement(int index, Object value) throws Exception { //判断插入元素位置是否正确 if ( index&lt;0 || index>maxSize){ throw new Exception("error:index溢出！"); } myArrayList[index]=value; } @Override public int equipElment(Object value) throws Exception { for (int k=0;k&lt;curSize;k++){ if (value.equals(myArrayList[k])) return k; } return -1;//错误 } @Override public void clearList() throws Exception { for (int k=0;k&lt;curSize;k++){ myArrayList[k]=null; } } } test类package chapter; /** * 测试类 */ public class Test { public static void main(String[] args) { MyArrayListInterface arrayList = new MyArrayList(20); try { for (int i=0;i&lt;15;i++){ arrayList.insertElement(i,Math.random()*10); } for (int i=0;i&lt;arrayList.getLength();i++){ System.out.println("第"+i+"个元素："+arrayList.getElment(i)); } arrayList.updateElement(14,"hello world!"); System.out.println(arrayList.getElment(14)); }catch (Exception e){ e.printStackTrace(); } } }]]></content>
      <tags>
        <tag>java</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-优化数据库对象]]></title>
    <url>%2F2019%2F04%2F22%2Fshen-ru-qian-chu-mysql-you-hua-shu-ju-ku-dui-xiang%2F</url>
    <content type="text"><![CDATA[理解三大范式，逆三大范式，牺牲数据的完整性，来减少磁盘IO、CPU等 三大范式网上关于三大范式的讲解有很多，我也说不清，自己google去 这里挂一下老师讲的内容，三大范式一一递增，都是解决一些问题。 MySQL优化建议使用以下语句，MySQL会给出一些字段的优化建议，根据自己的情况使用 select * from table_name procedure analyse() 拆分表纵向将一个表分为多个表，添加外键，使一个数据页可以存放更多的数据，比如，我们在一个表中存在Text 或者Blob字段，当我们对他进行操作的时候会占据很多的资源，特别是删除的时候，他会占用大片的磁盘碎片，浪费资源，我们可以将其单独放在一个表中，使之前的表能存储更多的数据，在查询的时候减少IO次数。 这里补充几个知识 磁盘的数据存储是扇形的，每个扇形的容量大小是一样的，每个扇形就对应的操作系统中一个数据页 我们磁盘获取内容的时候往往是通过磁盘找道获取数据，他每次旋转找道都会获取所需数据之前的数据，这时操作系统也会将其读取出来，存放在内存中，下次获取相关数据的时候就会在内存中查找，减少IO操作。 横向将一个表数据分开存储，放到不同的表中，比如历史数据，很少查找的，这样就可以减少着找数据时的全表扫描带来的IO次数。同时也增加了表容量（表存储的数据库量是有限制的，去掉不必要的数据，存储更多有用的数据） 比如分区存储 逆规范化 增加冗余列：查询频繁的多表操作可以增加冗余列减少表连接，提高查询的效率，问题是增加了数据维护和一致性的复杂 增加派生列（可导性数据）：指增加的列来自其他表中的数据，由其他表中的数据经过计算生成。增 加的派生列其作用是在查询时减少连接操作，避免使用集函数。 重新组表：指如果许多用户需要查看两个表连接出来的结果数据，则把这两个表重新 组成一个表来减少连接而提高性能. 使用中间表就是对一个表复制一个副表，对该表的操作不影响原表 可用空间概念可用空间(有时也叫填充因子)用来保持一部分表空间或索引为空用于存储新添加的数据。规范表空间或索引的可用空间可以减少重组的频率,减少争用并且提升插入的效率。 总的空间=当前数据库的文件大小。已用空间是指已经存储了数据的空间、删除数据之后的空间。剩余空间一般是文件中的空间，但是这个空间还没有分配使用。 理解类似java中hashmap的容量大小和加载因子，当大小超出我们的限定值的时候就会重组开辟更大的存储空间，占用资源。所以我们可以在每个表空间中定期维护，保证一定的可用空间，减少表的重组开辟空间 优缺点优点 当有可用空间时， 插入更快。 当有新行插入时. 它们可以适当地进行集群。 可变长度的行和修改的行有了扩展的空间, 潜在地减少了重新定位行的次数。 一个页面的行减少可以获得更好的并发性, 因为一个页面被其他用户锁定时, 不可用的数据更少。 缺点 磁盘存储的要求更高。 扫描需要的时间更长。 页面上较少的行可能需要更多的I/O操作来访问请求的信息。 因为每个页面行的数目减少了, 每次I/0检索的行减少了, 所以数据缓存的效率也降低了。 确定可用空间大小 插入和修改的频率。 顺序访问和随机访问的次数。 访问非集群数据的影响。 行链接、行迁移和分页的可能性。 不要为静态表定义可用空间, 不需要扩展的空间。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化步骤]]></title>
    <url>%2F2019%2F04%2F21%2Fsql-you-hua-bu-zou%2F</url>
    <content type="text"><![CDATA[一次实验报告，感觉还行，挂上来 查看慢查询参数查看慢查询 开启慢查询 重启慢MySQL客户端，才能生效 设置慢查询时间查看慢查询时间 设置慢查询时间 查看表结构，在没有索引的列查询查看表结构： 可以看到user_id是主键索引，user_weixin是普通索引。 查看没有索引的字段数据 统计慢查询次数统计慢查询次数： 可以看出超过0.01秒的查询有三个（即慢查询） 分析慢查询语句分析语句： Explain语句分析，查看mysql执行情况 可以看出这个查询没有用索引，全表扫描，扫描了100288行。 使用profile分析：查看profile是否开启 发现profile没有开启，开启profile 使用profile分析 发现操作三耗时最久， 查看操作3各部分消耗时间： 可以发现sending data消耗最高。 使用trace分析：分析mysql优化器对语句的执行情况，由于我的版本低于5.6，不带有 这个功能，所以跳过。 建立索引对user_zfb建立索引，在分析查询时间： 再次查询： 可以发现这个是根据索引查询，扫描一行，效率提高了 再用profile分析查询时间 发现加了索引后，操作6，7消耗时间明显降低了很多。 在查看慢查询有哪些： 增加了一次，发现是修改表结构建立索引之前的，即相同语句慢查询没有增加 总结明确三个工具的作用： Profile查看你所有的操作。 Explain查看查询语句的执行情况，特别是多表操作的时候。 Trace查看mysql优化器怎么优化你的sql语句。 注意事项： 每次关闭mysql客户端，profiling都会关闭，需要自己手动开启。 设置慢查询时间后需要重启客户端才行。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-SQL优化]]></title>
    <url>%2F2019%2F04%2F21%2Fshen-ru-qian-chu-mysql-sql-you-hua%2F</url>
    <content type="text"><![CDATA[重中之中 英语词汇好尴尬，貌似都认识。。。 如何分析SQL语句分析SQL语句的方法使用show [session|global] status获取服务器提供的信息，默认session mysql> show global status like 'Com%'; +---------------------------+-------+ | Variable_name | Value | +---------------------------+-------+ | Com_admin_commands | 0 | | Com_assign_to_keycache | 0 | | Com_alter_db | 0 | | Com_alter_db_upgrade | 0 | | Com_alter_event | 0 | | Com_alter_function | 0 | | Com_alter_procedure | 0 | | Com_alter_server | 0 | | Com_alter_table | 6 | | Com_alter_tablespace | 0 | 使用show processlist查看当前MySQL进行的线程 mysql> show processlist; +----+------+----------------+------+---------+------+-------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+------+----------------+------+---------+------+-------+------------------+ | 5 | root | localhost:6029 | NULL | Query | 0 | NULL | show processlist | +----+------+----------------+------+---------+------+-------+------------------+ 1 row in set (0.00 sec) explain使用explain、desc可以获取MySQL是如何执行select语句的信息，包括表连接和连接的顺序 mysql> explain select count(*) from actor \G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: actor type: index possible_keys: NULL key: idx_actor_last_name key_len: 137 ref: NULL rows: 200 Extra: Using index 1 row in set (0.00 sec) ERROR: No query specified 解释 select_type：表示select的类型，常见的取值simple（简单表，不使用表连接或子查询）、primary（主查询，外层的查询）、union（union语句中的第二个或者后面的查询语句）、subquery（子查询中的第一个select）等 table：输出结果集的表 type：表示MySQL在表中找到所需行的方式，访问类型 重点理解 type=all 全表扫描 type=index 索引全扫描 type=range 索引范围扫描,常用于&lt;、&lt;=、&gt;、&gt;=等操作符 type=ref 使用非唯一索引或唯一索引的前缀索引，返回某个单独值得记录行，个人理解就是范围结果不唯一，where条件是等于 mysql> explain select b.*, a.* from payment a, customer b where a.customer_id=b.customer_id \G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: b type: ALL possible_keys: PRIMARY key: NULL key_len: NULL ref: NULL rows: 505 Extra: *************************** 2. row *************************** id: 1 select_type: SIMPLE table: a type: ref possible_keys: idx_fk_customer_id key: idx_fk_customer_id key_len: 2 ref: sakila.b.customer_id rows: 13 Extra: 2 rows in set (0.00 sec) ERROR: No query specified type=eq_ref 类似ref，区别在于使用唯一索引，每个索引键值，表中只有一条匹配记录，多表连接中使用primary key 或者 unique key作为关联条件 就是说外键使用唯一不重复的，多表联合操作返回唯一值。外表的一个元祖，内表只有唯一一条元组与之对应 type=const/system，单表中最多有一个匹配行，查询起来非常迅速，所以这个匹配行中的其他列的值可以被优化器在当前查询中当作常量处理，根据主键primary key 或唯一索引 unique index进行查询。j 就是说查询条件的字段不重复唯一就会当作常量处理。 coast：查询的条件唯一 system：coast的特例，表里面只有一条记录的时候 mysql> explain select * from actor where actor_id=1 \G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: actor type: const possible_keys: PRIMARY key: PRIMARY key_len: 2 ref: const rows: 1 Extra: 1 row in set (0.00 sec) ERROR: No query specified type=null，MySQL不用访问表或者索引，直接就能得到结果. mysql> explain select 1 from dual where 1 \G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: NULL type: NULL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: NULL Extra: No tables used 1 row in set (0.00 sec) ERROR: No query specified type=REF_OR_NUL 类似ref,只是索索条件包括，链接字段的值为空的情况 type=index_merge索引合并优化 type=unique_subquery：in后面是一个查询主键字段的子查询字段 type=index_subquery：in后面是一个普通索引的子查询 possible_keys：查询的时候可能使用的索引 key：实际使用的索引 key_len：索引字段的长度 rows：扫描的行数 extra：执行的情况和描述 using where表示优化器回表查询数据 using index表示查询覆盖索引查询 使用explain extended查看优化器做的修改 使用explain partition查看分区情况 优化器会去掉恒成立的条件 profileprofile可以更清楚的了解SQL执行的过程 查看profiling select @@profiling; 开启profiling set profiling=1; 使用profile mysql> show profiles; +----------+------------+-------------------------------------+ | Query_ID | Duration | Query | +----------+------------+-------------------------------------+ | 1 | 0.00045525 | select count(* ) from actor | | 2 | 0.00022275 | expalinselect count(* ) from actor | | 3 | 0.00007975 | expalin select count(* ) from actor | | 4 | 0.00019775 | explain select count(* ) from actor | | 5 | 0.00031625 | explain select count(* ) from actor | +----------+------------+-------------------------------------+ 5 rows in set (0.00 sec) 使用profile查看CPU、磁盘IO等资源的消耗 mysql> show profile cpu for query 5; +----------------------+----------+----------+------------+ | Status | Duration | CPU_user | CPU_system | +----------------------+----------+----------+------------+ | starting | 0.000096 | 0.000000 | 0.000000 | | checking permissions | 0.000007 | 0.000000 | 0.000000 | | Opening tables | 0.000017 | 0.000000 | 0.000000 | | System lock | 0.000044 | 0.000000 | 0.000000 | | init | 0.000010 | 0.000000 | 0.000000 | | optimizing | 0.000006 | 0.000000 | 0.000000 | | statistics | 0.000010 | 0.000000 | 0.000000 | | preparing | 0.000006 | 0.000000 | 0.000000 | | executing | 0.000011 | 0.000000 | 0.000000 | | end | 0.000007 | 0.000000 | 0.000000 | | query end | 0.000015 | 0.000000 | 0.000000 | | closing tables | 0.000005 | 0.000000 | 0.000000 | | freeing items | 0.000079 | 0.000000 | 0.000000 | | logging slow query | 0.000002 | 0.000000 | 0.000000 | | cleaning up | 0.000003 | 0.000000 | 0.000000 | +----------------------+----------+----------+------------+ 15 rows in set (0.00 sec) 使用show profile source for query xxx可以查看SQL解析执行过程中每个步骤使用的源码文件、函数名、以及具体的源文件行数 注意事项： 每次开启MySQL客户端都要开启profiling traceMySQL5.6提供了对SQL上网跟踪trace，了解优化器执行过程 使用流程 开启trace 设置格式json ，设置trace最大能够使用的内存大小(避免默认内存导致显示不完整) set optimizer_trace='enabled=on' ,en_markers_in_json=on; set optimizer_trace_max_mem_size=100000; 执行想要trace的语句 检查information_schema.optimizer_trace 知道SQL如何执行SQL select * from information_schema.optimizer_trace \G: 由于我的MySQL版本为5.5，不支持trace，所以不做例子 索引问题索引分类见索引章节，大部分内容在该章节有所涉及 MySQL索引最常见的是采用B-tree（ALV平衡树），可以用于全关键字、关键字范围、关键字前缀查询。 使用索引的情况 匹配全值 匹配值的范围查询 匹配最左前缀（复合索引中） 仅仅对索引查询 前缀索引 能够实现索引匹配部分精确而其他部分进行范围查询 mysql> explain select inventory_id from rental where rental_date='2006&2&14 15:16:03' and customer_id>=300 and customer_id explain select * from payment where rental_id is null \G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: payment type: ref possible_keys: fk_payment_rental key: fk_payment_rental key_len: 5 ref: const rows: 5 Extra: Using where 1 row in set (0.10 sec) 5.6引入index Condition Pushdown(ICP)特性优化查询，将某些条件过滤操作下放到存储引擎，以6为例，在5.6一下，数据库的操作如6的所说，但是在5.6及以后，数据库用索引查询出对应数据的地址后，不会立刻回表显示数据，而是在索引customer_id上过滤条件，再从表中读取数据，减少不必要数据的IO读操作 存在索引但是不能使用索引的情况 %开头 数据类型出现隐式转换 复合索引不满足最左原则 or分割 查看索引情况 mysql> show status like 'Handler_read%'; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | Handler_read_first | 2 | | Handler_read_key | 1 | | Handler_read_last | 0 | | Handler_read_next | 202 | | Handler_read_prev | 0 | | Handler_read_rnd | 0 | | Handler_read_rnd_next | 27 | +-----------------------+-------+ 7 rows in set (0.00 sec) Handler_read_key低说明索引不好，用得少 Handler_read_rnd_next高说明查询低效，需要建立索引补救 SQL优化步骤单独写个章节 优化表方法定期分析表分析表 分析和存储表的关键字，得到准确的统计信息 mysql> analyze table payment; +----------------+---------+----------+----------+ | Table | Op | Msg_type | Msg_text | +----------------+---------+----------+----------+ | sakila.payment | analyze | status | OK | +----------------+---------+----------+----------+ 1 row in set (0.09 sec) 检查表 检查单表夺标是否存在错误 mysql> check table payment_myisam; +-----------------------+-------+----------+----------+ | Table | Op | Msg_type | Msg_text | +-----------------------+-------+----------+----------+ | sakila.payment_myisam | check | status | OK | +-----------------------+-------+----------+----------+ 1 row in set (0.01 sec) 定期优化表mysql> optimize table payment_myisam; +-----------------------+----------+----------+-----------------------------+ | Table | Op | Msg_type | Msg_text | +-----------------------+----------+----------+-----------------------------+ | sakila.payment_myisam | optimize | status | Table is already up to date | +-----------------------+----------+----------+-----------------------------+ 会给出相应的优化信息 注意：以上操作都会锁定表 常用SQL语句优化大批量插入数据对MyISAM存储引擎的表 alter table xxx disable keys; #关闭MyISAM表非唯一索引的更新。 load the data; alter table xxx enable keys; #开启 load data infile '路径/文件名' into table xxx; 对InnoDB的表 InnoDB表的按照主键的顺序存储，按主键的顺序存储数据效率高 关闭唯一性校验，在存在索引中遇到。 set unique_checks=0; set unique_checks=1; 关闭自动提交，然后在开启自动提交 set autocommit=0; set autocommit=1; 优化insert语句 一次插入多条数据 索引文件和数据文件放在不同的磁盘 用文本文件导入数据 load data infile xxx into table xxx 使用内存表 优化Order By语句这部分看不懂，等老师讲 优化Group by语句默认情况下group by会对分类的字段排序 避免排序结果的消耗，指定order by null禁止排序 mysql> explain select payment_date,sum(amount) from payment group by payment_date \G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: payment type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 16451 Extra: Using temporary; Using filesort 1 row in set (0.00 sec) ERROR: No query specified mysql> explain select payment_date,sum(amount) from payment group by payment_date order by null\G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: payment type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 16451 Extra: Using temporary 1 row in set (0.00 sec) ERROR: No query specified 查看时间 mysql> show profiles; +----------+------------+------------------------------------------------------------------------------------------+ | Query_ID | Duration | Query | +----------+------------+------------------------------------------------------------------------------------------+ | | 18 | 0.00028650 | explain select payment_date,sum(amount) from payment group by payment_date | | 19 | 0.00015250 | explain select payment_date,sum(amount) from payment group by payment_date order by | | 20 | 0.00026600 | explain select payment_date,sum(amount) from payment group by payment_date order by null | +----------+------------+------------------------------------------------------------------------------------------+ 15 rows in set (0.00 sec) 可以看到query 18明显比20慢点儿，分析上面的explain，发现没有禁止排序分分类存在using filesort，而filesort消耗时间长 优化嵌套查询子查询可以一次性完成多种逻辑操作，同时避免事务、或者表的锁死，但是有的情况下，子查询可以用join替代。原因在于MySQL不需要创建临时表完成逻辑上需要两个步骤的查询工作 mysql> explain select * from customer where customer_id not in (select customer_id from payment)\G; *************************** 1. row *************************** id: 1 select_type: PRIMARY table: customer type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 577 Extra: Using where *************************** 2. row *************************** id: 2 select_type: DEPENDENT SUBQUERY table: payment type: index_subquery possible_keys: idx_fk_customer_id key: idx_fk_customer_id key_len: 2 ref: func rows: 13 Extra: Using index 2 rows in set (0.00 sec) ERROR: No query specified mysql> explain select * from customer a left join payment b on a.customer_id=b.customer_id where b.customer_id is null \G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: a type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 577 Extra: *************************** 2. row *************************** id: 1 select_type: SIMPLE table: b type: ref possible_keys: idx_fk_customer_id key: idx_fk_customer_id key_len: 2 ref: sakila.a.customer_id rows: 13 Extra: Using where; Not exists 2 rows in set (0.00 sec) ERROR: No query specified profile分析 *************************** 14. row *************************** Query_ID: 22 Duration: 0.00227575 Query: explain select * from customer where customer_id not in (select customer_id from payment) *************************** 15. row *************************** Query_ID: 23 Duration: 0.00043550 Query: explain select * from customer a left join payment b on a.customer_id=b.customer_id where b.customer_id is null 15 rows in set (0.00 sec) ERROR: No query specified 可以看出第二种明显快很多 再看各部分消耗时间 mysql> show profile for query 22; +----------------------+----------+ | Status | Duration | +----------------------+----------+ | starting | 0.000077 | | checking permissions | 0.000007 | | checking permissions | 0.000006 | | Opening tables | 0.001802 |# | System lock | 0.000032 | | init | 0.000096 | | optimizing | 0.000010 | | statistics | 0.000029 | | preparing | 0.000012 | | executing | 0.000016 | | optimizing | 0.000006 | | statistics | 0.000010 | | preparing | 0.000023 | | executing | 0.000013 | | end | 0.000010 | | query end | 0.000016 | | closing tables | 0.000012 | | freeing items | 0.000094 | | logging slow query | 0.000004 | | cleaning up | 0.000006 | +----------------------+----------+ 20 rows in set (0.00 sec) mysql> show profile for query 23; +----------------------+----------+ | Status | Duration | +----------------------+----------+ | starting | 0.000094 | | checking permissions | 0.000007 | | checking permissions | 0.000007 | | Opening tables | 0.000036 | | System lock | 0.000037 | | init | 0.000042 | | optimizing | 0.000014 | | statistics | 0.000042 | | preparing | 0.000020 | | executing | 0.000025 | | end | 0.000009 | | query end | 0.000011 | | closing tables | 0.000010 | | freeing items | 0.000075 | | logging slow query | 0.000003 | | cleaning up | 0.000005 | +----------------------+----------+ 16 rows in set (0.00 sec) 可以看出第二种方式比第一种慢的原因在于opending tables,为什么是opending tables,是由于创建了第一种临时表，打开表消耗了时间? 由于我的版本不支持trace，就没办法分析优化器处理流程了 MySQL如何优化or条件含有or的每个条件必须是索引，才会使用索引，复合索引使用or不能使用索引 优化分页查询正常情况下，我们使用limit查询时，会把前面的数据查询到了，但是有舍弃，造成不必要的数据去读操作，解决办法如下。 第一种，在索引上完成排序分页的操作，在根据索引回表获取其他数据。 第二种，添加一个字段，记录上一页的最后一行的标号，然后在查询的时候添加该字段的限制，准确的地址查询，避免，不必要的查询。但是这种情况是适用于不重复的情况，重复的情况下会出现分页结果内容丢失。 过程自行看书，网上关于分页的优化有很多，比树上强一些，google一下。 SQL提示use index希望使用提供的索引 explain select * from table_name use index(xxx) \G; ignore index忽略索引 explain seletc * from table_name ignore index(xxx) \G; force index强制使用某种索引 explain select * from table_name force index(xxx) \G; 常用SQL技巧正则表达式使用regexp 数据库名表名问题MySQL的命名与操作系统有关，linux系统对大小写敏感，windows对大小写不敏感，建议命名的时候（大小写不敏感）不要相同。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化原理]]></title>
    <url>%2F2019%2F04%2F20%2Fmysql-you-hua-yuan-li%2F</url>
    <content type="text"><![CDATA[获益匪浅 请看这里，写的非常好 https://cloud.tencent.com/developer/article/1103154]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL结构层次]]></title>
    <url>%2F2019%2F04%2F20%2Fmysql-jie-gou-ceng-ci%2F</url>
    <content type="text"><![CDATA[MySQL的结构层次 1、Connectors指的是不同语言中与SQL的交互 2、Management Serveices &amp; Utilities： 系统管理和控制工具 3、Connection Pool: 连接池 管理缓冲用户连接，线程处理等需要缓存的需求。 4、SQL Interface: SQL接口 接受用户的SQL命令，并且返回用户需要查询的结果。比如select from就是调用SQL Interface。 5、Parser: 解析器。 SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。 主要功能： a . 将SQL语句分解成数据结构，并将这个结构传递到后续步骤，以后SQL语句的传递和处理就是基于这个结构的 。 b. 如果在分解构成中遇到错误，那么就说明这个sql语句是不合理的。 6、Optimizer: 查询优化器 SQL语句在查询之前会使用查询优化器对查询进行优化。他使用的是“选取-投影-联接”策略进行查询。 用一个例子就可以理解： select uid,name from user where gender = 1; 这个select 查询先根据where 语句进行选取，而不是先将表全部查询出来以后再进行gender过滤。 这个select查询先根据uid和name进行属性投影，而不是将属性全部取出以后再进行过滤。 将这两个查询条件联接起来生成最终查询结果。 7、Cache和Buffer： 查询缓存 如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。 这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。 8、Engine ：存储引擎 存储引擎是MySql中具体的与文件打交道的子系统。也是Mysql最具有特色的一个地方。 Mysql的存储引擎是插件式的。它根据MySql AB公司提供的文件访问层的一个抽象接口来定制一种文件访问机制(这种访问机制就叫存储引擎)。 现在有很多种存储引擎，各个存储引擎的优势各不一样，最常用的MyISAM,InnoDB,BDB。 默认下MySql是使用MyISAM引擎，它查询速度快，有较好的索引优化和数据压缩技术。但是它不支持事务。 InnoDB支持事务，并且提供行级的锁定，应用也相当广泛。 Mysql也支持自己定制存储引擎，甚至一个库中不同的表使用不同的存储引擎，这些都是允许的。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-MySQL分区]]></title>
    <url>%2F2019%2F04%2F11%2Fshen-ru-qian-chu-mysql-mysql-fen-qu%2F</url>
    <content type="text"><![CDATA[分区优化数据库表解决的问题、实现的原理、实现的过程及优点 英语词汇coalesce 联合联结 为什么分区问题很多情况下，我们的一个表达到了上万条，甚至过亿，这时候我们查询时，无论有没有索引，消耗的时间都是极大的，占用的内存也是很浪费（一般索引会占一半的文件大小）。使用分区则可以解决这些问题 分区表的概念分区是根据一定的规则，数据库把一个表分解成多个更小的、更容易管理的部分。就访问数据库应用而言，逻辑上就只有一个表或者一个索引，但实际上这个表可能有N个物理分区对象组成，每个分区都是一个独立的对象，可以独立处理，可以作为表的一部分进行处理。分区对应用来说是完全透明的，不影响应用的业务逻辑。 判断当前MySQL是否支持分区？ show variables like'%partition%' MySQL支持大部分存储引擎（MyISAM、InnoDB、Memery等），不支持Merge、CSV等。 同一分区表的不同分区存储引擎必须一致，不用分区表可以不同存储引擎。 分区表的原理分区表由多个相关的底层表实现，这些底层表是由句柄对象来表示，可以直接访问分区，分区表的索引只是在各个底层表上各自加上一个完全相同的索引，从存储引擎上看，分区表和普通表没有什么不同。 SELECT查询：打开并锁住所有的底层表，优化器判断是否会过滤部分分区，然后调用对应的存储引擎接口访问各个分区的数据。 INSERT操作：打开并锁住所有底层表，确定哪个分区接收记录，写入底层表 DELETE操作：打开并锁住所有底层表，确定数据对应的分区，删除操作。 UPDATE操作：打开并锁住所有的底层表，确定更新的分区，取出更新，判断更新后的数据应该存放的分区位置，写入操作。 分区的种类RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区。 LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择。 HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL 中有效的、产生非负整数值的任何表达式。 KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值。 重点：无论哪种分区，要么你分区表上没有主键/唯一键，要么分区表的主键/唯一键都必须包含分区键，也就是说不能使用主键/唯一键字段之外的其它字段分区。 RANGE分区 取值范围将数据分成区，区间连续且不重叠。 分区键Null值会按最小值处理 创建： mysql> create table emp( -> id int not null, -> ename varchar(20), -> hired date not null default '1123^12&23', -> separated date not null default '1234+12+12', -> job varchar(30) not null, -> store_id int not null) -> partition by range(store_id)( -> partition p0 values less than (10), -> partition p1 values less than (20), -> partition p2 values less than (30) -> ); Query OK, 0 rows affected (0.19 sec) 修改： mysql> alter table emp add partition (partition p3 values less than maxvalue); Query OK, 0 rows affected (0.41 sec) Records: 0 Duplicates: 0 Warnings: 0 删除： alter table emp drop partition p0; LIST分区mysql> create table expenses( -> expense_date date not null, -> category int, -> amount decimal (10,3) -> ) -> partition by list(category)( -> partition p0 values in (3,5), -> partition p1 values in (1,10), -> partition p2 values in (4,9), -> partition p3 values in (2), -> partition p4 values in (6) -> ); Query OK, 0 rows affected (0.20 sec) Columns分区解决list、range分区只支持整数的问题。 columns分区分为 range columns（基于元组的数据比较）和list columns分区,两种都支持整数、字符串、日期。，不支持浮点数，不支持text、blob; columns分区支持多列分区 栗子： mysql> create table rc3( -> a int, -> b int) -> partition by range columns(a,b)( -> partition p01 values less than (0,10), -> partition p02 values less than (10,10), -> partition p03 values less than (10,20), -> partition p04 values less than (10,35), -> partition p05 values less than (10,maxvalue), -> partition p06 values less than (maxvalue,maxvalue) -> ); Query OK, 0 rows affected (0.25 sec) 解释一下： 元组的比较，(a,b) 、(c,d)比较 如果a&gt;b，就不用比较b,d大小，否则，比较b,d; HASH分区MySQL分为两种算法分区： 常规Hash分区（取模） 线性Hash分区（linear hash分区；线性的2的幂的运算法则） create tables xxx () partition by （linear） hash(expr) partitions num; #expr 分区列，num分几个区 expr可以是MySQL中有效的任何函数或者其他表达式，只要他们返回一个既非常数，又非随机的整数，每次增加删除修改的时候都要计算一次，影响性能。 常规Hash分区和线性Hash分区区别 常规HASH在分区管理上很麻烦，如果要增加分区，之前的分区就要重新计算， 线性Hash分区维护的时候很方便，但是分区之间的数据分布不均匀，关于线性Hash分区算法自行看书，不难。 注意：Hash分区只支持整数分区。明白他们的算法不是取模就是取最小2的幂值 KEY分区和Hash分区leisure，但是不允许用户使用自定义的表达式。使用MySQL服务器提供的Hash函数，支持除Blob、Text类型之外其他类型的列作为分区键。 create table xxx() partition by key(expr) partitions num; expr 可以是0个或多个字段名的字段。 默认是主键作为分区键，没有主键，默认使用唯一键（必须非空）， 分区处理null方式一般情况下分区把null当作空值，或者最小值处理。 range分区中，null当最小值处理 list分区中，null必须出现在枚举列表中 hash\key中，当作0处理 解决办法：使用非空字段、默认值绕开MySQL默认NULL值得处理 分区的管理MySQL中提供添加、删除、重定义、合并、拆分分区的命令，使用alter table实现。 range&amp;list分区管理删除 同时也会删除对应分区内的数据 alter table xxx drop partition partition_name; 添加 range添加分区需要从最大值侧添加，类似磁盘分区 list添加，不能出现重复内容 range为例 alter table xxx add partition(partition partition_name value less than (xxx)); 重定义、合并、拆分分区 拆分 alter table xxx reorganize partition xxx into (partition p1 values xxx,partition p2 values xxx,) 合并 alter table xxx reorganize partition p1,p2,p3 into (partition p1 values xxx) 查看分区 mysql> explain partitions select * from stu where id>40 \G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: stu partitions: p2 type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 4 Extra: Using where 1 row in set (0.00 sec) ERROR: No query specified list区间的添加，需要添加新的区间，然后重定义区间 重定义range分区的时候只能定义相邻的分区，重定义的分区区间必须和原分区区间覆盖相同的区间，不能改变区间类型。 重定义list分区的时候只能定义相邻的分区 单张表到单个文件：表的每一行都存储在同一个文件中。 张表到多个文件：用于非常大的表或要求数据在存储级别并行物理分离的表。 多张表到单个文件：用于小表(如查找表和代码表)。 hash&amp;key分区管理添加、删除分区直接修改分区个数 alter table xxx coalesce partition num; 使用分区的优点 分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备。 和单个磁盘或者文件系统相比，可以存储更多数据 优化查询。在where语句中包含分区条件时，可以只扫描一个或多个分区表来提高查询效率；涉及sum和count语句时，也可以在多个分区上并行处理，最后汇总结果。 分区表更容易维护。例如：想批量删除大量数据可以清除整个分区。 可以使用分区表来避免某些特殊的瓶颈，例如InnoDB的单个索引的互斥访问。 分区的限制1.一个表最多只能有1024个分区 2.如果分区字段中有主键或者唯一索引的列，那么多有主键列和唯一索引列都必须包含进来。即：分区字段要么不包含主键或者索引列，要么包含全部主键和索引列。 3.分区表中无法使用外键约束 4.MySQL的分区适用于一个表的所有数据和索引，不能只对表数据分区而不对索引分区，也不能只对索引分区而不对表分区，也不能只对表的一部分数据分区。 区别分区和分表分表分表是将一个大表按照一定的规则分解成多张具有独立存储空间的实体表，我们可以称为子表，每个表都对应三个文件，MYD数据文件，.MYI索引文件，.frm表结构文件。这些子表可以分布在同一块磁盘上，也可以在不同的机器上。 app读写的时候根据事先定义好的规则得到对应的子表名，然后去操作它。 分区分区和分表相似，都是按照规则分解表。不同在于分表将大表分解为若干个独立的实体表，而分区是将数据分段划分在多个位置存放，可以是同一块磁盘也可以在不同的机器。分区后，表面上还是一张表，但数据散列到多个位置了。 app读写的时候操作的还是大表名字，db自动去组织分区的数据。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MYSQL-事务控制和锁定语句]]></title>
    <url>%2F2019%2F04%2F11%2Fshen-ru-qian-chu-mysql-shi-wu-kong-zhi-he-suo-ding-yu-ju%2F</url>
    <content type="text"><![CDATA[对比java、spring的锁、事务机制思考学习 存储类型与锁 授之以渔锁：https://dev.mysql.com/doc/refman/5.7/en/lock-tables.html 事务：https://dev.mysql.com/doc/refman/5.7/en/commit.html 锁类似java的锁机制，java中可以用Lock锁住资源，如果当前锁被其他线程获取，该线程将进入等待队列，直到使用当前锁的线程释放当前锁。 mysql使用lock tables可以锁定当前线程的表，当表被锁定，当前线程就会等待，直到获取锁为止。 使用unlock tables可以释放当前线程获得任意锁，当前线程执行另一个lick tables时，或当前与服务器的连接被关闭的时候，所有的锁会隐式解锁。 LOCK TABLES tbl_name [[AS] alias] lock_type [, tbl_name [[AS] alias] lock_type] ... lock_type: { READ [LOCAL] | [LOW_PRIORITY] WRITE } UNLOCK TABLES 可以看出一次可以锁定多个表 lock_type 重点 查询是读，修改、增加、删除是写。 write：写锁，当前线程使用写锁时，当前线程读写，即可以CRUD操作；其他线程读写操作会等待，直到当前持有锁的线程释放锁。 read：读锁，当前线程使用读锁时，当前线程可以读内容，但是不能写，即只能读。其他线程可以读写，但是写操作会等待，直到占用锁的线程释放锁。 栗子： 使用表： mysql> select * from emp; +-------+------------+----------+--------+ | ename | hiredate | sal | deptno | +-------+------------+----------+--------+ | tom | 2003-12-02 | 200.00 | 3 | | dony | 2005-02-02 | 100.00 | 2 | | tom | 2003-12-02 | 200.00 | 1 | | dony | 2005-02-02 | 100.00 | 2 | | za | 2005-02-03 | 30000.00 | 3 | +-------+------------+----------+--------+ 5 rows in set (0.07 sec) 比较说明，A：当前线程，B：其他线程 读锁 第一步： A: 给当前线程的表emp加读锁 mysql> lock table emp read; Query OK, 0 rows affected (0.00 sec) B:无操作 第二步： A:查询 mysql> select * from emp where deptno=1; +-------+------------+--------+--------+ | ename | hiredate | sal | deptno | +-------+------------+--------+--------+ | tom | 2003-12-02 | 200.00 | 1 | +-------+------------+--------+--------+ 1 row in set (0.00 sec) B:查询 mysql> select * from emp where deptno=1; +-------+------------+--------+--------+ | ename | hiredate | sal | deptno | +-------+------------+--------+--------+ | tom | 2003-12-02 | 200.00 | 1 | +-------+------------+--------+--------+ 1 row in set (0.00 sec) 说明读锁的情况下，其他线程也可以读 第三步： A：给当前表插入数据 mysql> insert into emp values('hello','1002%1%1',246.666,6); ERROR 1099 (HY000): Table 'emp' was locked with a READ lock and can't be updated 说明读锁，当前线程不允许写操作 B：给当前表插入数据 mysql> insert into emp values('hello','1002%1%1',246.666,6); 进入等待状态； 说明其他线程可以读写，但是写操作会等待 第四步： A:释放锁 mysql> unlock tables; Query OK, 0 rows affected (0.00 sec) B：可以进行写操作 Query OK, 1 row affected, 1 warning (2 min 41.82 sec) 说明占用锁的线程释放锁后，其他线程可以写操作 写锁 第一步： A:加写锁 mysql> lock tables emp write; Query OK, 0 rows affected (0.00 sec) B:无任何操作 第二步： A:查询 mysql> select * from emp where deptno=1; +-------+------------+--------+--------+ | ename | hiredate | sal | deptno | +-------+------------+--------+--------+ | tom | 2003-12-02 | 200.00 | 1 | +-------+------------+--------+--------+ 1 row in set (0.00 sec) B:查询 select * from emp where deptno=1; 其他线程读等待。 说明，当前线程持有锁的时候可以读，其他线程读操作会等待。 第三步： A:释放锁 mysql> unlock tables; Query OK, 0 rows affected (0.00 sec) B:无任何操作 +-------+------------+--------+--------+ | ename | hiredate | sal | deptno | +-------+------------+--------+--------+ | tom | 2003-12-02 | 200.00 | 1 | +-------+------------+--------+--------+ 1 row in set (1 min 33.69 sec) 说明当前线程占用写锁的时候，其他线程的读操作会等待，直到当前锁被释放，其他线程可以读。 第四步： A:写操作 mysql> insert into emp values('hello','1002%1%1',246.666,6); Query OK, 1 row affected, 1 warning (0.07 sec) B：写操作 mysql> insert into emp values('hello','1002%1%1',246.666,6); 说明，当前线程持有锁的时候可以读，其他线程写操作会等待。 第五步： A:释放锁 mysql> unlock tables; Query OK, 0 rows affected (0.00 sec) B:无任何操作 mysql> insert into emp values('hello','1002%1%1',246.666,6); Query OK, 1 row affected, 1 warning (2 min 43.79 sec) 说明当前线程占用写锁的时候，其他线程的写操作会等待，直到当前锁被释放，其他线程可以写。 事务控制通过set autocommit、start transaction、commit、rollback等语句支持本地事务。 START TRANSACTION [transaction_characteristic [, transaction_characteristic] ...] transaction_characteristic: { WITH CONSISTENT SNAPSHOT | READ WRITE | READ ONLY } BEGIN [WORK] COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE] ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE] SET autocommit = {0 | 1} 默认情况下，mysql是autocommit的，如果需要通过明确的commit和rollback来提交和回滚事务，那么需要通过明确的事务控制命令来开始事务 start transaction或begin语句可以开始一项新的事务。 commit和rollback用来提交或者回滚事务。 chain和release子句分别用来定义在事务提交或者回滚之后的操作，chain会立即启动一个新事物，并且和刚才的事务具有相同的隔离级别，release则会断开和客户端的连接。 SET AUTOCOMMIT可以修改当前连接的提交方式，如果设置了set autocommit=0，则设置之后的所有事务都需要通过明确的命令进行提交或者回滚。 事务例子栗子： 使用的表： mysql> desc emp; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | ename | varchar(10) | YES | | NULL | | | hiredate | date | YES | | NULL | | | sal | decimal(10,2) | YES | | NULL | | | deptno | int(2) | YES | | NULL | | +----------+---------------+------+-----+---------+-------+ 4 rows in set (0.01 sec) 空表 A：当前线程 B：其他线程 A:开启事务 mysql> start transaction; Query OK, 0 rows affected (0.00 sec) A:插入数据 mysql> insert into emp values('hello','1234*12(4',12.12,1); Query OK, 1 row affected (0.00 sec) A:查询数据 mysql> select * from emp; +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | +-------+------------+-------+--------+ 1 row in set (0.00 sec) B:插入数据 mysql> insert into emp values('hello','1234*12(4',12.12,2); Query OK, 1 row affected (0.07 sec) 说明可以插入数据 B:查询数据 mysql> select * from emp; +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 2 | +-------+------------+-------+--------+ 1 row in set (0.00 sec) 可以看出A线程插入的数据没有显示,B插入的数据显示了 A:查询数据 mysql> select * from emp; +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | +-------+------------+-------+--------+ 1 row in set (0.00 sec) 发现B线程插入的数据没有显示？？？这是什么鬼？？？ A:提交事务 mysql> commit; Query OK, 0 rows affected (0.07 sec) A:查询数据 mysql> select * from emp; +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | | hello | 1234-12-04 | 12.12 | 2 | +-------+------------+-------+--------+ 2 rows in set (0.00 sec) B：查询数据 mysql> select * from emp; +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | | hello | 1234-12-04 | 12.12 | 2 | +-------+------------+-------+--------+ 2 rows in set (0.00 sec) 到这里是不是发现一些奇怪的问题，为什么A开启事务后没办法查询到B对表的操作，B也没办法查询到A的操作？？？ 类比java多线程的内存模型就知道，java的内存模型存在线程内存和主内存。MySQL也是一样的，我们对一个线程开启事务，然后对他进行的操作是在操作系统的内存中进行的，而没开启事务则是在硬盘的存储空间中（这点不一样，java是在主存中，mysql是在硬盘的存储中，其实也一样，可以把mysql的硬盘存储理解成java中的主内存）。 那么现在问题迎刃而解了，事务的处理是在内存中的，所有读写操作都在内存中，而非事务的处理是在硬盘的存储中。两种情况针对的数据不同，自然读写出来的结果不一样了。 当事务提交后，当前线程在内存中读写数据就会写入到硬盘的存储中，其他其他县城也就可以访问该数据了，当前线程也可以访问表的其他数据。 lock是否可以回滚栗子二： 使用相同的表，数据为空 A:加写锁 mysql> lock tables emp write; Query OK, 0 rows affected (0.00 sec) A：插入数据 mysql> insert into emp values('hello','1234*12(4',12.12,1); Query OK, 1 row affected (0.07 sec) B:查询数据 mysql> select * from emp; 进入等待 A：回滚记录 mysql> rollback; Query OK, 0 rows affected (0.00 sec) B:还是等待状态 A:查询数据 mysql> select * from emp; +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | +-------+------------+-------+--------+ 1 row in set (0.00 sec) A:提交解锁 mysql> unlock tables; Query OK, 0 rows affected (0.00 sec) B:等待结束 +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | +-------+------------+-------+--------+ 1 row in set (1 min 20.08 sec) 说明对lock不能回滚，回滚无效 为什么事务可以回滚，锁不能呢？？ 个人认为：锁是作用在硬盘的存储上，写操作就会将内容写进磁盘，没有回滚的余地；事务是作用在内存中，有回滚的余地。 锁情况下开启事务 如果在锁表期间，用start transaction开启了一个新事务，会造成一个隐式的unlock tables被执行 栗子三：验证锁情况下开启事务 A：写锁 mysql> lock tables emp write; Query OK, 0 rows affected (0.00 sec) B:查询 进入等待状态 mysql> select * from emp; A:插入数据 mysql> insert into emp values('hello','1234*12(4',12.12,1); Query OK, 1 row affected (0.07 sec) B:等待状态 A:回滚 mysql> rollback; Query OK, 0 rows affected (0.00 sec) B:等待状态 A：开启事务 mysql> start transaction -> ; Query OK, 0 rows affected (0.00 sec) B：等待解除 +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | +-------+------------+-------+--------+ 1 row in set (1 min 46.22 sec) 可以看到开启新事务后，lock就被解除了。 因此，在同一个事务中，最好不使用不同存储引擎的表，否则rollback时需要对非事务类型的表进行特别的处理，因为commit、rollback只能对事务类型的表进行提交和回滚。 通常情况下，只对提交的事务纪录到二进制的日志中，但是如果一个事务中包含非事务类型的表，那么回滚操作也会被记录到二进制日志中，以确保非事务类型表的更新可以被复制到从的数据库中。 那么为什么开启新事物锁就被解除了呢？？？ 个人理解：开启新事物就意味着该线程可以读写该表内容，可以理解成事务的优先级比锁高。 savepoint回滚 在事务中可以通过定义savepoint，指定回滚事务的一个部分，但是不能指定提交事务的一个部分。对于复杂的应用，可以定义多个不同的savepoint，满足不同的条件时，回滚不同的savepoint。需要注意的是，如果定义了相同名字的savepoint，则后面定义的savepoint会覆盖之前的定义。对于不再需要使用的savepoint，可以通过release savepoint命令删除savepoint，删除后的savepoint，不能再执行rollback to savepoint命令。 栗子四： A:开启事务 mysql> start transaction; Query OK, 0 rows affected (0.07 sec) A:插入数据 mysql> insert into emp values('hello','1234*12(4',12.12,1); Query OK, 1 row affected (0.00 sec) A:查询数据 mysql> select * from emp; +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | +-------+------------+-------+--------+ 1 row in set (0.00 sec) B:查询数据 mysql> select * from emp; Empty set (0.00 sec) A:启用savepoint指定部分回滚内容 mysql> savepoint test; Query OK, 0 rows affected (0.00 sec) A:插入数据 mysql> insert into emp values('hello','1234*12(4',12.12,2); Query OK, 1 row affected (0.00 sec) A:查询数据 mysql> select * from emp; +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | | hello | 1234-12-04 | 12.12 | 2 | +-------+------------+-------+--------+ 2 rows in set (0.00 sec) A:回滚部分数据 mysql> rollback to savepoint test; Query OK, 0 rows affected (0.00 sec) A:提交事务 mysql> commit -> ; Query OK, 0 rows affected (0.06 sec) B:查询数据 mysql> select * from emp; +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | +-------+------------+-------+--------+ 1 row in set (0.00 sec) A:查询数据 mysql> select * from emp; +-------+------------+-------+--------+ | ename | hiredate | sal | deptno | +-------+------------+-------+--------+ | hello | 1234-12-04 | 12.12 | 1 | +-------+------------+-------+--------+ 1 row in set (0.00 sec) 分布式事务用的少，不做介绍，自己看书去，mmp，手都酸了。 目前阶段我还用不上，但是了解下相关概念，为以后打下基础。 在开发中，为了降低单点压力，通常会根据业务情况进行分表分库，将表分布在不同的库中（库可能分布在不同的机器上）。在这种场景下，事务的提交会变得相对复杂，因为多个节点（库）的存在，可能存在部分节点提交失败的情况，即事务的ACID特性需要在各个不同的数据库实例中保证。比如更新db1库的A表时，必须同步更新db2库的B表，两个更新形成一个事务，要么都成功，要么都失败。 分布式服务器用途了解下分布式服务器的用途：https://juejin.im/entry/589abc01128fe10058fc542c 分布式事务原理当前分布式事务只支持InnoDB存储引擎 在MySQL中，使用分布式事务的应用程序涉及到一个或多个资源管理器和一个事务管理器。 资源管理器（resource manager）：用来管理系统资源，是通向事务资源的途径。数据库就是一种资源管理器。资源管理还应该具有管理事务提交或回滚的能力。 事务管理器（transaction manager）：事务管理器是分布式事务的核心管理者。事务管理器与每个资源管理器（resource manager）进行通信，协调并完成事务的处理。事务的各个分支由唯一命名进行标识。 mysql在执行分布式事务（外部XA）的时候，mysql服务器相当于xa事务资源管理器，与mysql链接的客户端相当于事务管理器。 分布式事务分为两个阶段： 阶段一为准备（prepare）阶段。即所有的参与者准备执行事务并锁住需要的资源。参与者ready时，向transaction manager报告已准备就绪。 阶段二为提交阶段（commit）。当transaction manager确认所有参与者都ready后，向所有参与者发送commit命令。如下图所示： 事务协调者transaction manager因为XA 事务是基于两阶段提交协议的，所以需要有一个事务协调者（transaction manager）来保证所有的事务参与者都完成了准备工作(第一阶段)。如果事务协调者（transaction manager）收到所有参与者都准备好的消息，就会通知所有的事务都可以提交了（第二阶段）。MySQL 在这个XA事务中扮演的是参与者的角色，而不是事务协调者（transaction manager）。 Mysql的XA事务分为外部XA和内部XA 外部XA用于跨多MySQL实例的分布式事务，需要应用层作为协调者，通俗的说就是比如我们在PHP中写代码，那么PHP书写的逻辑就是协调者。应用层负责决定提交还是回滚，崩溃时的悬挂事务。MySQL数据库外部XA可以用在分布式数据库代理层，实现对MySQL数据库的分布式事务支持，例如开源的代理工具：网易的DDB，淘宝的TDDL等等。 内部XA事务用于同一实例下跨多引擎事务，由Binlog作为协调者，比如在一个存储引擎提交时，需要将提交信息写入二进制日志，这就是一个分布式内部XA事务，只不过二进制日志的参与者是MySQL本身。Binlog作为内部XA的协调者，在binlog中出现的内部xid，在crash recover时，由binlog负责提交。(这是因为，binlog不进行prepare，只进行commit，因此在binlog中出现的内部xid，一定能够保证其在底层各存储引擎中已经完成prepare)。 以上内容摘自：https://blog.csdn.net/soonfly/article/details/70677138 语法XA {START|BEGIN} xid [JOIN|RESUME] #启动xid事务 (xid 必须是一个唯一值; 不支持[JOIN|RESUME]子句) XA END xid [SUSPEND [FOR MIGRATE]] #结束xid事务 ( 不支持[SUSPEND [FOR MIGRATE]] 子句) XA PREPARE xid #准备、预提交xid事务 XA COMMIT xid [ONE PHASE] #提交xid事务 XA ROLLBACK xid #回滚xid事务 XA recover #返回当前数据库中处于prepare状态的分支事务的详细信息 xid:事务标识符，用来标识一个分布式事务，一般有客户端会MySQL服务器生成，包括三部分 xid: gtrid [, bqual [, formatID ]] gtrid:分布式事务标识符 bqual:分支限定符，默认空串。 formatID:数字，标识gtrid和bqual值，默认1。 例子就不上了，自行百度。 少用他，性能低，又麻烦，还不安全，不完善XA的性能很低。一个数据库的事务和多个数据库间的XA事务性能对比可发现，性能差10倍左右。因此要尽量避免XA事务，例如可以将数据写入本地，用高性能的消息系统分发数据。或使用数据库复制等技术。只有在这些都无法实现，且性能不是瓶颈时才应该使用XA。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-存储过程和函数]]></title>
    <url>%2F2019%2F04%2F08%2Fshen-ru-qian-chu-mysql-cun-chu-guo-cheng-he-han-shu%2F</url>
    <content type="text"><![CDATA[重点是存储过程、函数，他们的书写格式，以及控制流程 有些作用，多练习！ 存储过程、函数用来干什么？个人意愿是从事java开发，但是java开发无法避免涉及到数据库，很多时候我们需要一些测试数据，我们不可能一条一条的输入，这时候我们需要生成测试数据（可以使用第三方的软件实现），存储过程函数就开始起作用了。当然，在一些公司，比如金融、企业、政府等等，使用存储过程很广泛，存储过程一旦调试完成通过后就能稳定运行，这与各个业务在一段时间内是相对稳定和确定是匹配的；存储过程大大地减少了业务系统与数据库的交互，一定程度降低了业务系统与数据库的耦合。但是其可移植性差，很多情况下使用存储过程是得不偿失的。 授人以渔条件定义及处理：https://dev.mysql.com/doc/refman/5.7/en/condition-handling.html 存储过程函数：https://dev.mysql.com/doc/refman/5.7/en/sql-syntax-data-definition.html 游标：https://dev.mysql.com/doc/refman/5.7/en/cursors.html 控制流程：https://dev.mysql.com/doc/refman/5.7/en/control-flow-functions.html 存储过程、函数区别函数必须有返回值，存储过程没有，存储过程参数可以使用IN、OUT、INOUT类型，函数的参数必须是IN类型。 创建函数、存储过程修改创建存储过程或函数的语法 create procedure sp_name(proc_parameter[...]) [characteristic...] routine_body create function fun_name(func_paramter[...]) return type [characteristic...] routine_body 解释： 存储过程、函数参数 proc_parameter：[in|put|inout] param_name type func_paramter:param_name type 函数返回`type` ​ 任意MySQL数据类型 characteristic特征 language sql #说明下面过程的主题是使用sql准备的，有点鸡肋，mysql为今后sql外的其他语言准备 |[not] deterministic #deterministic确定，表明函数的返回值完全由输入参数决定的 |{contains sql|not sql|reads sql data|modifies sql data} #提供子程序使用的内在数据，目前只提供给服务器 #contains sql表示子程序不包含读或写数据的语句 #not sql表示子程序不包含sql语句 #reads sql data表示子程序包含读数据的语句，不包含写语句 #modifies sql data子程序包含写语句 #默认使用contains sql |sql security{definer|invoker} #安全级别 definer定义者 invoker调用者 |comment 'string' #注释 routine_body ​ SQL代码的内容 MySQL允许存储过程、函数包含DDL语句（data define language）,允许存储过程中执行提交（commit）或者回滚（rooback），存储过程和函数不允许执行load data infile（快速导入数据） 栗子： #随机产生字符串 #定义新的命令结束符 delimiter $$ #DROP FUNCTION rand_string $$ CREATE FUNCTION rand_string(n INT) RETURNS varchar(255)#返回字符串 BEGIN DECLARE char_str VARCHAR(100) DEFAULT 'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ'; #定义变量 DECLARE return_str VARCHAR(255) DEFAULT ''; DECLARE i INT DEFAULT 0; WHILE i]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-索引&视图]]></title>
    <url>%2F2019%2F04%2F06%2Fshen-ru-qian-chu-mysql-suo-yin-shi-tu%2F</url>
    <content type="text"><![CDATA[索引的设计与使用、视图操作 核心内容： 视图的创建、联合索引 授人以渔使用explain查看SQL语句执行情况，优化语句 索引索引分类在 MySQL 中，主要有四种类型的索引，分别为：B-Tree索引，Hash 索引，Fulltext 索引和R-Tree 索引。 B-Tree 索引B-Tree 索引是 MySQL 数据库中使用最为频繁的索引类型，使用树形结构 Hash索引散列是一种使用键值开启数据的快速直接访问的技术。 使用一种算法将键值转换成一个指针, 该指针指向包含这些键值的行的物理位置。存储地址=Hash(key） Hash-散列函数 缺点： Hash 索引仅仅只能满足“=”,“IN”和“&lt;=&gt;”查询，不能使用范围查询； Hash 索引无法被利用来避免数据的排序操作； Hash 索引不能利用部分索引键查询； Hash 索引在任何时候都不能避免表扫面； Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高； 全文索引 目前来说，仅有CHAR，VARCHAR和TEXT这三种数据类型的列可以建Full-text索引。MyISAM支持。 like+%只适合文本较少的情况 使用match...against进行全文索引match匹配 against标识关键字 #使用match和against函数 select * from mm_product where match(name,label) against('白猫 洗洁精'); R-Tree索引解决空间数据检索的问题，在 MySQL中，支持一种用来存放空间信息的数据类型GEOMETRY 索引与引擎 MyISAM和InnoDB默认创建的是B-Tree索引 MySQL支持全文本索引、前缀索引 Memery默认使用Hash索引，也支持B-Tree索引 索引的增删改查创建表的时候直接指定索引 create table mytable( id int not null, name varchar(16) not null, index [indexName](name(length)) ); 栗子 mysql> create table test3( -> id int not null, -> name varchar(15) not null, -> index ind_text3_name(name(10)) -> ); Query OK, 0 rows affected (0.08 sec) mysql> show create table test3 \G; *************************** 1. row *************************** Table: test3 Create Table: CREATE TABLE `test3` ( `id` int(11) NOT NULL, `name` varchar(15) NOT NULL, KEY `ind_text3_name` (`name`(10)) ) ENGINE=InnoDB DEFAULT CHARSET=latin1 1 row in set (0.00 sec) ERROR: No query specified 创建索引： create [unique|fulltext|spatial] index index_name [using index_type] on table_name(index_col_name,...) index_col_name: col_name[(length)][asc|desc] 解释： unique|fulltext|spatial索引类型 using index_type表示索引的具体实现方式，在MySQL中，有两种不同的索引：BTREE索引和HASH索引。 index_col_name表示需要创建索引的字段名称，我们还可以针对多个字段创建复合索引，只需要在多个字段名称之间以英文逗号隔开即可。 如果是char或者varchar类型，length可任意小于字段实际长度，如果是blob或者text类型，必须指定长度 create index cityname on city(city(10)); 栗子:这个栗子是接着“创建表的时候直接指定索引”写的 mysql> create index ind_test3_name_1 on test3(name(10)); Query OK, 0 rows affected (0.23 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql> show create table test3 \G; *************************** 1. row *************************** Table: test3 Create Table: CREATE TABLE `test3` ( `id` int(11) NOT NULL, `name` varchar(15) NOT NULL, KEY `ind_text3_name` (`name`(10)), KEY `ind_test3_name_1` (`name`(10)) ) ENGINE=InnoDB DEFAULT CHARSET=latin1 1 row in set (0.00 sec) ERROR: No query specified 说明一个字段可以有多个索引 删除索引 drop index index_name on table_name 修改表结构（添加索引） alter table tablename add index indexName(columnName) 查看表索引 mysql> show index from test3 \G; *************************** 1. row *************************** Table: test3 Non_unique: 1 Key_name: ind_text3_name Seq_in_index: 1 Column_name: name Collation: A Cardinality: 0 Sub_part: 10 Packed: NULL Null: Index_type: BTREE Comment: Index_comment: *************************** 2. row *************************** Table: test3 Non_unique: 1 Key_name: ind_test3_name_1 Seq_in_index: 1 Column_name: name Collation: A Cardinality: 0 Sub_part: 10 Packed: NULL Null: Index_type: BTREE Comment: Index_comment: 2 rows in set (0.00 sec) ERROR: No query specified 查看索引使用情况 show status like 'handler_read%'; #hander_read_key值越高，越高表示索引查询到的次数，查询高效 #hander_read_rnd_next值越高，查询低效 区分key和index key 是数据库的物理结构，它包含两层意义，一是约束（偏重于约束和规范数据库的结构完整性），二是索引（辅助查询用的）。包括primary key, unique key, foreign key 等。 index是数据库的物理结构，它只是辅助查询的，它创建时会在另外的表空间（mysql中的innodb表空间）以一个类似目录的结构存储。索引要分类的话，分为前缀索引、全文本索引等；因此，索引只是索引，它不会去约束索引的字段的行为。 索引利弊利： 提高检索 降低数据的排序成本 弊： 占用存储空间 资源消耗，增加更新带来的IO量和调整索引所导致的计算量 创建索引情况 较频繁的作为查询条件的字段应该创建索引； 唯一性太差的字段不适合单独创建索引，即使频繁作为查询条件； 更新非常频繁的字段不适合创建索引； 高性能索引策略优化篇在深入 独立的列 前缀索引对于内容很长的列，比如blob,text或者很长的varchar列，索引这些列的完整长度代价过高，可以考虑使用前缀索引。 多列索引 复合索引 最左前缀匹配原则：mysql建立联合索引时会遵循最左前缀的原则，即最左优先。 联合索引 ![](https://i.loli.net/2019/04/07/5ca953ac87053.png) 选择合适的索引顺序 从左到右的顺序选择索引 考虑全局基数和选择性，解释一下，就是我们所说的选择性（distinct values/all values），全局基数就是all values, 存在索引但不使用索引的场景 如果like 是以％开始； 数据类型出现隐式转换，比如我们where value=2，表中的类型是varchar，那么value数据类型会转换成varchar。 复合索引的情况下，查询条件不满足索引最左的原则，就是说索引要放在最左边 MySQL使用索引比全局扫描慢的情况 用or分割开的条件，or前条件有索引，or后的列没有索引 视图what?视图（view）是一种虚拟存在的表，是一个逻辑表，本身并不包含数据。作为一个select语句保存在数据字典中的。 通过视图，可以展现基表的部分数据；视图数据来自定义视图的查询中使用的表，使用视图动态生成。 现在大部分视图可以用工具实现，没必要写sql语句，sql语句有些麻烦 创建视图CREATE [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement [WITH [CASCADED | LOCAL] CHECK OPTION] 注意：视图在from关键字 后面不能包含子查询 解释： OR REPLACE：或者替代已经存在的视图 ALGORITHM：选择那种视图算法 select_statement：select语句 WITH [CASCADED | LOCAL] CHECK OPTION：视图在修改更新时的权限 local满足本视图条件就可以更新 cascade满足所有视图条件才可以更新 默认是cascade 删除视图可以一次删除多个视图 DROP VIEW [IF EXISTS] view_name [, view_name] ... 修改视图ALTER [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}] [DEFINER = { user | CURRENT_USER }] [SQL SECURITY { DEFINER | INVOKER }] VIEW view_name [(column_list)] AS select_statement [WITH [CASCADED | LOCAL] CHECK OPTION] DEFINER：指出谁是视图的创建者或定义者 SQL SECURITY：要查询一个视图，首先必须要具有对视图的select权限。 查看视图查看视图信息 show table status like 'staff_list' \G 查询视图定义 show create view xxx \G 有关视图的信息记录在information_schema数据库中的views表中 select * from information_schema.views 部分内容摘自老师的PPT 参考链接： https://tech.meituan.com/2014/06/30/mysql-index.html https://www.cnblogs.com/geaozhang/p/6792369.html]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-选择合适数据类型和字符集]]></title>
    <url>%2F2019%2F04%2F06%2Fshen-ru-qian-chu-mysql-xuan-ze-he-gua-shu-ju-lei-xing-he-zi-fu-ji%2F</url>
    <content type="text"><![CDATA[合适的才是最好的！ 选择合适字符类型char与varchar char列数据在检索的时候会删除尾部的空格，对长度变化不大，并且对查询速度速度有较高要求的可以考虑使用char varchar列数据 ‘’表示一个字节 char处理速度比varchar快 InnoDB的char和varchar性能主要考虑行使用的存储总量 text和blob常见问题： BLOB和TEXT值会引起一些性能问题，特别是在执行了大量的删除操作的时候； 删除操作会在数据表中留下很大的空洞，以后填入这些空洞的记录性能上有影响；建议经常使用optimize table功能对表的碎片整理，避免空洞导致性能问题。 可以使用合成的（Synthetic）索引来提高大文本字段（BLOB或者TEXT）的查询性能。 合成索引就是根据大文本的内容建立一个散列值，并存储在单独的列中，这种只适用于精确的匹配查询，使用md5()、sha1()、crc32()或者自己的应用程序逻辑计算。如果散列值尾部有空格，不能存储在char或者varchar中。 在不必要的时候避免检索大型的BLOB或者TEXT的值； 把BLOB或者TEXT列分离到单独的表中； 把原数据表中的数据列转换为固定长度的数据行数据，减少主表中的碎片，得到固定数据行的性能优势。 浮点数和定点数 浮点数存在误差问题； 对货币等精度敏感的数据，应该使用定点数表示或者存储； 在编程中，如果用到浮点数，要特别注意误差问题， 并尽量避免做浮点数的比较； 要注意浮点数中一些特殊值的处理； 日期类型 根据需要选择能够满足应用的最小存储的日期类型； TIMESTAMP表示的日期范围比DATETIME要短的多； 如果记录的日期需要让不同的时区的用户使用，那么最好使用TIMESTAMP，因为日期类型中只有它能够和实际的时区对应； 字符集查看可用字符集的命令 mysql> show character set; +----------+-----------------------------+---------------------+--------+ | Charset | Description | Default collation | Maxlen | +----------+-----------------------------+---------------------+--------+ | big5 | Big5 Traditional Chinese | big5_chinese_ci | 2 | | dec8 | DEC West European | dec8_swedish_ci | 1 | | cp850 | DOS West European | cp850_general_ci | 1 | | hp8 | HP West European | hp8_english_ci | 1 | | koi8r | KOI8-R Relcom Russian | koi8r_general_ci | 1 | | latin1 | cp1252 West European | latin1_swedish_ci | 1 | ... mysql> desc information_schema.character_sets; +----------------------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------------------+-------------+------+-----+---------+-------+ | CHARACTER_SET_NAME | varchar(32) | NO | | | | | DEFAULT_COLLATE_NAME | varchar(32) | NO | | | | | DESCRIPTION | varchar(60) | NO | | | | | MAXLEN | bigint(3) | NO | | 0 | | +----------------------+-------------+------+-----+---------+-------+ 4 rows in set (0.01 sec) 校对规则（collation）定义比较字符串的方式，字符集和校对规则是一对多关系 查看校对规则 mysql> show collation like 'utf8%'; +--------------------------+---------+-----+---------+----------+---------+ | Collation | Charset | Id | Default | Compiled | Sortlen | +--------------------------+---------+-----+---------+----------+---------+ | utf8_general_ci | utf8 | 33 | Yes | Yes | 1 | | utf8_bin | utf8 | 83 | | Yes | 1 | | utf8_unicode_ci | utf8 | 192 | | Yes | 8 | 校对规则命名：以相关的字符集名开始，通常包括一个语言名，以_ci（大小写不敏感）_cs(大小写敏感)、_bin(二元，基于字符编码的值比较) 字符集设置服务器级字符集 校对规则设置 在配置文件my.cnf中设置 启动项中设置 C:\Users\liwei>mysqld character-set-server=utf8 190406 17:31:00 [Note] --secure-file-priv is set to NULL. Operations related to importing and exporting data are disabled 190406 17:31:00 [Note] mysqld (mysqld 5.5.62) starting as process 1920 ... 数据库级设置先查看数据库默认字符集和校对规则 show variables like 'character_set_database'; show variables like 'collation_database'; 再创建数据库，创建数据库的时候指定字符集和校对规则 mysql> create database test2 character set 'utf8' collate 'utf8_general_ci'; Query OK, 1 row affected (0.00 sec) mysql> show create database test2; +----------+----------------------------------------------------------------+ | Database | Create Database | +----------+----------------------------------------------------------------+ | test2 | CREATE DATABASE `test2` /*!40100 DEFAULT CHARACTER SET utf8 */ | +----------+----------------------------------------------------------------+ 1 row in set (0.00 sec) 数据表级设置create table zhazha( id int(11) default null )engine=innodb default charset=utf8 collate=utf_general_ci; 字符集的修改步骤]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-存储引擎]]></title>
    <url>%2F2019%2F04%2F06%2Fshen-ru-qian-chu-mysql-cun-chu-yin-qing%2F</url>
    <content type="text"><![CDATA[常见MySQL存储引擎比较，及使用情况 英语词汇： restrict 限制 constraint 约束 cascade 串联 optimize 优化 查看数据库引擎查看当前的默认存储引擎，可以使用如下的命令： mysql > show variables like ‘table_type’; 查看mysql提供的引擎 show engines \G; show variables like 'have%'; 查看当前默认引擎 show variables like '%storage_engine%'; 查看某个表使用什么引擎 show create table 表名 各种引擎特点 MyISAMMyISAM不支持事务，也不支持外键，其优势是访问的速度快，对事务完整性没有要求或者以SELECT、INSERT为主的应用基本上都可以使用这个引擎来创建表； MyISAM磁盘上存储成三个文件，文件名和表名都一样，扩展名分别是： .frm（存储表定义） .DYD（MYdata 存储数据） .MYI（MYIndex 存储引擎） 数据文件和索引文件可以放置在不同的目录，需要在创建表的时候通过DATA DIRECTORY和INDEX DIRECTORY语句指定，也就是说不同的MyISAM表的索引文件和数据文件可以防止到不同的路径下。文件路径需要的是绝对路径，并且具有访问权限 MyISAM的表还支持3中不同的存储格式，分别是： 静态（字段都是固定长度）表； 动态表； 压缩表； 静态表默认存储方式，里面的字段是非变长字段，这样每个记录都是固定长度，优点是存储迅速，容易缓存，出现故障容易恢复；缺点占用空间大。数据在存储时，需要保存的内容后面用空格补充，返回值的时候，后面不带空格。 动态表是变长字段，频繁的更新删除记录会产生碎片，需要定期执行optimize table 或者 myisamchk-r来改善性能。但是出现故障时恢复难 压缩表，每个记录都是单独压缩的 InnoDBInnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全。但是对比MyISAM的存储引擎，InnoDB写的处理效率差一些，并且会占用更多的磁盘空间以保留数据和索引； 自动增长 自动增长字段如果为null 或者0，实际增长的值就是自动增长后的值 每次自动增长都会是从最大的那个值开始自增 使用alter table *** auto_increment=n;时语句强制设置成自动增长，默认从1开始，但是该修改是保存在内存中的，如果数据重启，默认值会丢失，需要重新设置 last_insert_id()查询当前线程最后插入记录的值 如果一次插入多个值，返回的是第一条记录使用的自动增长 自动增长必须是索引，如果是组合索引，也必须是组合索引的第一列，MyISAM没有这个限制 外键约束创建外键 mysql> create table city( -> city_id smallint unsigned not null auto_increment, -> city varchar(50) not null, -> country_id smallint unsigned not null, -> last_update timestamp not null default current_timestamp on update current_timestamp, -> primary key(city_id) -> key idx_fk_country_id (country_id), -> constraint 'fk_city_country' foreign key(country_id) references country (country_id) on delete restrict on update cascade -> )engine=innodb default charset=utf8; 父表必须要有对应的索引，子表在创建外键的时候也会自动创建对应夫人索引 在创建子表索引时，可以指定删除、修改父表时，字表的相应操作，包括restrict、cascade、set null、no action。restrict和no action作用一样，限制在子表有关联的情况下父表不能更新，cascade表父表在更新或删除的时候，更新或删除子表对应记录。set null表示父表在更新或删除的时候，子表对应字段被set null 当某个表被其他表创建外键参照的时候，该表的对应索引或者主键禁止被删除 导入数据的时候，可以关闭外键约束set foreign_key_checks=0;导入数据完成之后，使用set foreign_key_checks=0;恢复 存储方式MySQL的Innodb包含两种表空间文件模式，默认的共享表空间和每个表分离的独立表空间。 一般来说，当数据量很小的时候建议使用共享表空间的管理方式。数据量很大的时候建议使用独立表空间的管理方式。 共享表空间： Innodb的所有数据保存在一个单独的表空间里面，而这个表空间可以由很多个文件组成，一个表可以跨多个文件存在，所以其大小限制不再是文件大小的限制，而是其自身的限制。 从Innodb的官方文档中可以看到，其表空间的最大限制为64TB，也就是说，Innodb的单表限制基本上也在64TB左右了，当然这个大小是包括这个表的所有索引等其他相关数据。 优点： 以放表空间分成多个文件存放到各个磁盘上（表空间文件大小不受表大小的限制，如一个表可以分布在不同的文件上）。 表数据和表描述放在一起方便管理。 缺点：所有的数据和索引存放到一个文件中，将有一个很庞大的文件，虽然可以把一个大文件分成多个小文件，但是多个表及索引在表空间中混合存储，这样对于一个表做了大量删除操作后表空间中将会有大量的空隙，特别是对于统计分析，日志系统这类应用最不适合用共享表空间 独立表空间（在配置文件（my.cnf）中设置innodb_file_per_table=1）： 独立表空间是每个表都有独立的多个数据文件，而且做到了索引和数据的分离，每一个表都有一个.frm表描述文件，还有一个.ibd文件(这个文件包括了单独一个表的数据内容以及索引内容)。 优点： 每个表都有自已独立的表空间。 每个表的数据和索引都会存在自已的表空间中。 可以实现单表在不同的数据库中移动 空间可以回收。 对于使用独立表空间的表，不管怎么删除，表空间的碎片不会太严重的影响性能，而且还有机会处理（表空不能自已回收）,处理方式如下：Drop table操作自动回收表空间 如果对于统计分析或是日志表，删除大量数据后可以通过:alter table TableName engine=innodb;回收不用的空间对于使innodb-plugin的Innodb使用turncate table也会使空间收缩 使用独占表空间的效率以及性能会更高一点。 缺点：单表增加过大，如超过100个G 当使用独享表空间来存放Innodb的表的时候，每个表的数据以一个单独的文件来存放，这个时候的单表限制，又变成文件系统的大小限制了。 参考链接：https://blog.csdn.net/nawenqiang/article/details/80010675 MEMORYMEMORY存储引擎使用存在于内存中的内容来创建表，每个MEMORY表只实际对应一个磁盘文件，格式为.frm。MEMORY类型的表访问非常的快，因为它的数据值放在内存中的，并且默认使用HASH索引，但是一旦服务关闭，表中的数据就会丢失掉； MEMORY表主要是用于那些内容变化不频繁的代码表，或者作为统计操作的中间结果表，便于高效地对中间结果进行分析并得到最终的统计结果。对存储引擎为MEMORY的表进行更新操作需要谨慎，因为数据并没有实际写入到磁盘中，所以一定要对下次重新启动服务之后如何获取这些修改后的数据所考虑； MERGEMERGE存储引擎把一组MyISAM数据表当做一个逻辑单元来对待，让我们可以同时对他们进行查询。构成一个MERGE数据表结构的各成员MyISAM数据表必须具有完全一样的结构。每一个成员数据表的数据列必须按照同样的顺序定义同样的名字和类型，索引也必须按照同样的顺序和同样的方式定义。 常用于多表合并。查询时他会把所有表中的数据查询出来，插入数据时需要指定表 假设日志数据表的当前集合包括 log_2004、log_2005、log_2006、log_2007 ，而你可以创建一个如下所示的MERGE数据表把他们归拢为一个逻辑单元： CREATE TABLE log_YY ( dt DATETIME NOT NULL, info VARCHAR(100) NOT NULL, INDEX (dt) ) ENGINE = MyISAM; CREATE TABLE log_merge ( dt DATETIME NOT NULL, info VARCHAR(100) NOT NULL, INDEX(dt) ) ENGINE = MERGE UNION = (log_2004, log_2005, log_2006, log_2007); TokuDB第三方存储引擎 特性： Fractal树索引保证高效的插入性能 优秀的压缩性能，比InnoDB高近10倍 支持在线创建索引和田间删除属性列等DDL操作 使用Bulk Loader快速加载数据 主从延迟消除技术 支持ACID和MVCC 适用情况： 日志数据，日志数据通常插入平凡，存储量大 历史数据，通常不会有写数据，利用TokuDB的高压缩特性存储 在线DDL较频繁的场景，提高可用性 引擎选择 注意：5.5以前默认引擎是MyISAM，5.5之后是InnoDB]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-常用函数]]></title>
    <url>%2F2019%2F04%2F06%2Fshen-ru-qian-chu-mysql-chang-yong-han-shu%2F</url>
    <content type="text"><![CDATA[很多函数很有用，多百度，不要死记硬背 授人以渔https://dev.mysql.com/doc/refman/5.5/en/date-and-time-functions.html 相关函数请看官方文档，比我这还详细，谷歌翻译是个好东西。 这里只说个人觉得应该注意的事项。 字符串函数 concat()，任何字符串和null连接的结果都将是null left(str,x)和right(str,x)入轨第二个函数为null，将不返回字符串 数值函数 补充： sum()函数：返回指定字段的数据之和 count()函数：返回指定字段的数据的行数（记录数） avg()函数：平均数 round(x,y)函数：如果是整数，将保留y为数量的0，如果没有y，默认0，即将x四舍五入后取整。 truncate仅仅只是截断，不进行四舍五入 日期和时间函数 流程函数 其他常用函数]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-运算符]]></title>
    <url>%2F2019%2F04%2F06%2Fshen-ru-qian-chu-mysql-yun-suan-fu%2F</url>
    <content type="text"><![CDATA[so easy 算数运算符 注意事项： 当除法、取余、DIV、MOD操作的时候，参数2为0或者为null，结果为null 比较运算符 注意事项： 比较运算符用于数字、字符串、表达式。数字作为浮点数比较，字符串不区分大小写比较 between用法 a between b and c；当a、b、c类型相同的时候直接比较，不同的时候先转换数据类型，在比较。 REGEXP用法：str REGEXP str_pat 逻辑运算符 位运算符 运算符优先级 注意:=含义：表示赋值 区别=和:=区别，在大多数情况下=表示相等的意思，就是比较运算符。只有在set或者update情况下，才是赋值的意思 &lt;=&gt;表示左边等于右边，右边等于左边，和=区别，&lt;=&gt;可以用于null的比较，而=的null比较是无效的]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-数据类型]]></title>
    <url>%2F2019%2F04%2F01%2Fshen-ru-qian-chu-mysql-shu-ju-lei-xing%2F</url>
    <content type="text"><![CDATA[MySQL的数据类型，主要包括数值型、字符串类型、日期和时间。不同版本MySQL类型不同 本章节较为简单，重点关注常用数据类型以及注意事项内容 英语词汇binary 二进制 hexadecimal 十六进制 decimal 小数、十进制 tiny 微小的，很少的 medium 中等 precision 精度 unsigned 无符号 数值类型严格数值数据类型(INTEGER、SMALLINT、DECIMAL和NUMERIC)，以及近似数值数据类型(FLOAT、REAL和DOUBLE PRECISION) 注意事项： 当我们指定长度时，比如int(5)表示当数值宽度小于5位是，前面将被填充，默认int int(11)。一般配合zerofill使用，表示用0填充 可选属性unsigned表示无符号。适用于非负数，或需要较大上限值时。他的取值范围，下限0，上限为原来的两倍，例如tinyint有符号-128+127，无符号0255。如果一个列指定为zerofill,MySQL默认自动为该列添加该属性 Auto_increment自增长，一个表只允许一个字段又该属性 decimal在MySQL内部是字符串存储，比浮点数更精确，适用于货币等精度高的 数据 M表示精度，有多少位数（整数+小数）D表示标度，小数点后面位数 在没有制定进度的情况，浮点数会存储实际精度，但是这个精度有实际的硬件和系统控制，不同情况可能有所不同。decimal不指定精度，默认整数位10，小数位0。溢出会waring，多出的部分被截掉。 Bit默认1 日期类型 注意事项： 如果经常插入或者更新数据为当前系统时间，用时间撮，不同时区，用时间撮，显示的时间不同。时区时间转换 timestamp不插入值是，系统毁人创建current_timestamp ，MySQL只给表中的第一个timestamp字段设置为默认时间，第二个默认为0 查看当前时间 就是上一节说的吃查询元数据 show variables like 'time_zone' 注意时间表示范围，timestamp取值范围为1970.01.01. 08：00：01到2038年某一天，不适合存放很久的日期 日期的分割符没有强制限制，2019-04-01、2019-4-1、20190401、201941、2019+04+01…都可以 字符串类型 注意事项： 在检索的时候，char列删除尾部的空格，varchar保留空格 枚举类型ENUM字符串类型 创建表，gender字段为枚举类型 create table t (gender enum('M','F')); 插入记录 insert into t values('M'),('n'),('1'),(null); 注意事项： enum是忽略大小写的 enum只允许从值集合中选取单个值。不能一次多个值 SET类型]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出MySQL-SQL基础]]></title>
    <url>%2F2019%2F03%2F31%2Fshen-ru-qian-chu-mysql-sql-ji-chu%2F</url>
    <content type="text"><![CDATA[从今天起，深入学习MySQL ，:smile: 英语词汇DDL(Data Definition Languages):数据定义语句，定义了不停的数据段、数据库、表、列、索引等数据库对象，常用关键字create、drop、alter等。 DML(Data Manipulation Languages):数据操纵语句，用于添加、删除、更新、查询数据库记录，并检查数据完整性，常用关键字insert、delete、update、select等。 DCL(Data Control Languages):数据控制语句，控制不同数据段直接的许可和访问级别，定义了数据库、表、字段、用户访问级别和安全级别。常用关键字grant、revoke等。 授人以鱼不如授人以渔？ contents查看显示所有可供查询的分类，（我的数据库没安装这个，无法演示） 查看相关帮助： 例子 mysql> ? create table Name: 'CREATE TABLE' Description: Syntax: CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name (create_definition,...) [table_options] [partition_options] CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name [(create_definition,...)] [table_options] [partition_options] [IGNORE | REPLACE] [AS] query_expression CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name { LIKE old_tbl_name | (LIKE old_tbl_name) } ... DDL 数据定义语句创建数据库 create database test1; 使用数据库 use test1; 删除数据库 drop database test1; 创建表 mysql的表名以目录的形式存放于存盘中。 mysql> create table emp( -> ename varchar(10) , -> hiredate date , -> sal decimal(10,2) , -> deptno int(2) -> ); Query OK, 0 rows affected (0.09 sec) 小知识: desc 查看表结构 mysql> desc table_emp; +----------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------+---------------+------+-----+---------+-------+ | ename | varchar(10) | YES | | NULL | | | hiredate | date | YES | | NULL | | | sal | decimal(10,2) | YES | | NULL | | | deptno | int(2) | YES | | NULL | | +----------+---------------+------+-----+---------+-------+ 4 rows in set (0.01 sec) #查看数据库创建详细信息 mysql> show create table table_emp \G; *************************** 1. row *************************** Table: table_emp Create Table: CREATE TABLE `table_emp` ( `ename` varchar(10) DEFAULT NULL, `hiredate` date DEFAULT NULL, `sal` decimal(10,2) DEFAULT NULL, `deptno` int(2) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=latin1 1 row in set (0.00 sec) ERROR: No query specified \G使记录能够按照字段竖向排列 删除表 mysql> drop table table_emp; 修改表 修改表类型modify alter table tablename modify [column] column_definition [first/after col_name] mysql> alter table emp modify column ename varchar(10); Query OK, 0 rows affected (0.14 sec) Records: 0 Duplicates: 0 Warnings: 0 增加表字段add alter table tablename add [column] column_definition [first/after col_name] mysql> alter table emp add column age int(3); Query OK, 0 rows affected (0.19 sec) Records: 0 Duplicates: 0 Warnings: 0 删除表字段drop alter table tablename drop [column] col_name mysql> alter table emp drop qwe; Query OK, 0 rows affected (0.18 sec) Records: 0 Duplicates: 0 Warnings: 0 字段改名change alter table tablename change [column] old_col_name_definition [first/after col_name] mysql> alter table emp change age age1 int(4); Query OK, 0 rows affected (0.12 sec) Records: 0 Duplicates: 0 Warnings: 0 **change和modify都可以修改表的定义，但是change后面需要写两次列名，可以修改列名，modify不能** 修改字段排列顺序 注意前面有的[first/after xx]字段 mysql> alter table emp add birth date after ename; Query OK, 0 rows affected (0.18 sec) Records: 0 Duplicates: 0 Warnings: 0 其他类似 更改表名 alter table tablename rename [to] new_tablename; mysql> alter table emp rename emp1; Query OK, 0 rows affected (0.07 sec) DML 数据操纵语句 插入语句 insert into tablename(field1,field2...,fieldn) values(value1,value2...valuen) 修改（更新）语句 update tablename set field1=value1,field2=value2...[where condition] 可以同时更改多个表数据 update t1,t2,...set field1=xxx,field2=xxx... [where condition] mysql> update emp a,dept b set a.sal=a.sal*b.deptno,b.deptname=a.ename where a.deptno=b.deptno; Query OK, 4 rows affected (0.09 sec) Rows matched: 4 Changed: 4 Warnings: 0 多表更新常用于根据一个表的字段来动态修改另外一个表的的字段 删除记录 delete from tablename [where condition] 可以一次删除多个表记录 delete t1,t2,...tn from t1,t2,t3,...,tn [where condition] mysql> delete a,b from emp a, dept b where a.deptno=b.deptno; Query OK, 3 rows affected (0.07 sec) ​ 4. 查询记录select * from tablename [where condition] distinct去掉重复的值，先查询，再去重复 mysql> select distinct deptno from emp; +--------+ | deptno | +--------+ | 3 | | 2 | | 1 | +--------+ 3 rows in set (0.00 sec) 条件查询 mysql> select * from emp where deptno in (select distinct deptno from emp ); +-------+------------+--------+--------+ | ename | hiredate | sal | deptno | +-------+------------+--------+--------+ | tom | 2003-12-02 | 200.00 | 3 | | dony | 2005-02-02 | 100.00 | 2 | | tom | 2003-12-02 | 200.00 | 1 | | dony | 2005-02-02 | 100.00 | 2 | +-------+------------+--------+--------+ 4 rows in set (0.00 sec) 排序和限制order by select * from tablename [where condition] [order by field1 [desc/asc],field2 [desc/asc],field3 [desc/asc]]... desc降序，asc升序 默认升序 order by可以跟多个排序字段 limit限制显示的条数 mysql> select * from emp order by deptno, sal desc limit 1,3; +-------+------------+--------+--------+ | ename | hiredate | sal | deptno | +-------+------------+--------+--------+ | dony | 2005-02-02 | 100.00 | 2 | | dony | 2005-02-02 | 100.00 | 2 | | tom | 2003-12-02 | 200.00 | 3 | +-------+------------+--------+--------+ 3 rows in set (0.00 sec) 先按deptno排序，如果有字段相同，按desc排序，最后输出从第二条开始的3条记录 limit常用来分页 聚合 select [field1,field2,field3,...fieldn] fun_name from tablename [where condition] [group by field1,field2,field3,...fieldn [with rollup]] [having where_condition] fun_name:表示聚合函数，sum、count、max、max groud up：表示要进行分类聚合的字段，比如按部门统计员工数 with rollup：可选字段，聚合之后的结果汇总 having：分类后的结果过滤 having 和 where区别：having是对聚合之后的结果过滤，where是聚合之前就对记录过滤。尽量先用where过来记录，这样结果集减少，聚合效率提高，最后在根据逻辑是否用having进行过滤 mysql> select deptno,count(1) from emp group by deptno; +--------+----------+ | deptno | count(1) | +--------+----------+ | 1 | 1 | | 2 | 2 | | 3 | 1 | +--------+----------+ 3 rows in set (0.00 sec) mysql> select deptno,count(*) from emp group by deptno; +--------+----------+ | deptno | count(*) | +--------+----------+ | 1 | 1 | | 2 | 2 | | 3 | 1 | +--------+----------+ 3 rows in set (0.00 sec) mysql> select deptno,count(1) from emp group by deptno with rollup; +--------+----------+ | deptno | count(1) | +--------+----------+ | 1 | 1 | | 2 | 2 | | 3 | 1 | | NULL | 4 | +--------+----------+ 4 rows in set (0.00 sec) mysql> select deptno,count(1) from emp group by deptno having count(1)>1; +--------+----------+ | deptno | count(1) | +--------+----------+ | 2 | 2 | +--------+----------+ 1 row in set (0.00 sec) mysql> select sum(sal),max(sal),min(sal) from emp; +----------+----------+----------+ | sum(sal) | max(sal) | min(sal) | +----------+----------+----------+ | 600.00 | 200.00 | 100.00 | +----------+----------+----------+ 1 row in set (0.00 sec) 表连接 内连接：会显示出其他不匹配的记录 就是用where语句 外连接：会显示两张表中相互匹配的记录 左外连接 ：左边表全部显示，右边不匹配的为空 右外连接 ：右边表全部显示，左边不匹配的为空 完全外连接 ：两边都会显示，两边不匹配的为空 mysql> select ename,deptname from emp left join dept on emp.deptno=dept.deptno; +-------+----------+ | ename | deptname | +-------+----------+ | tom | NULL | | dony | NULL | | tom | tech | | dony | NULL | +-------+----------+ 4 rows in set (0.00 sec) 交叉连接：交叉连接返回左表中的所有行，左表中的每一行与右表中的所有行组合。交叉连接也称作笛卡尔积，没有用条件 mysql> select * from emp,dept; +-------+------------+----------+--------+--------+----------+ | ename | hiredate | sal | deptno | deptno | deptname | +-------+------------+----------+--------+--------+----------+ | tom | 2003-12-02 | 200.00 | 3 | 1 | tech | | tom | 2003-12-02 | 200.00 | 3 | 5 | fine | | dony | 2005-02-02 | 100.00 | 2 | 1 | tech | | dony | 2005-02-02 | 100.00 | 2 | 5 | fine | | tom | 2003-12-02 | 200.00 | 1 | 1 | tech | | tom | 2003-12-02 | 200.00 | 1 | 5 | fine | | dony | 2005-02-02 | 100.00 | 2 | 1 | tech | | dony | 2005-02-02 | 100.00 | 2 | 5 | fine | | za | 2005-02-03 | 30000.00 | 3 | 1 | tech | | za | 2005-02-03 | 30000.00 | 3 | 5 | fine | +-------+------------+----------+--------+--------+----------+ 10 rows in set (0.00 sec) 子查询 in、not in 、 = 、！=、exists、not exists等 mysql> select * from emp where deptno in(select deptno from dept); +-------+------------+--------+--------+ | ename | hiredate | sal | deptno | +-------+------------+--------+--------+ | tom | 2003-12-02 | 200.00 | 1 | +-------+------------+--------+--------+ 1 row in set (0.00 sec) 记录联合 select * from t1 union|union all select * from t2 ... union|union all select * from tn; union和union all区别union all把结果集直接合并到一起，而union将union all的结果进行一次distinct，去出重复的结果。 mysql> select deptno from emp -> union all -> select deptno from dept; +--------+ | deptno | +--------+ | 3 | | 2 | | 1 | | 2 | | 1 | | 5 | +--------+ 6 rows in set (0.00 sec) mysql> select deptno from emp -> union -> select deptno from dept; +--------+ | deptno | +--------+ | 3 | | 2 | | 1 | | 5 | +--------+ 4 rows in set (0.00 sec) DCL 数据控制语句DBA管理系统中的对象权限时使用。 了解 授予权限grant mysql> grant select,insert on test1.* to 'z1'@'localhost' identified by '123'; Query OK, 0 rows affected (0.06 sec) 移除权限revoke mysql> revoke insert on test1.* to 'z1'@'localhost'; Query OK, 0 rows affected (0.06 sec) 查询元数据三种方式 1）show语句 2）从INFORMATION_SCHEMA数据库里查询相关表 3）命令行程序，如mysqlshow, mysqldump show语句show databases; --列出所有数据库 show create database db_name; --查看数据库的DDL show tables; --列出默认数据库的所有表 show tables from db_name; --列出指定数据库的所有表 show table status; --查看表的描述性信息 show table status from db_name; show create table tbl_name; --查看表的DDL show columns from tbl_name; --查看列信息 show index from tbl_name; --查看索引信息 有几种show语句还可以带有一条like ‘pattern’字句，用来限制语句的输出范围，其中’pattern’允许包含’%’和’_’通配符，比如下面这条语句返回domaininfo表中以s开头的所有列: show columns from domaininfo like 's%'; mysql> show create table emp; +-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Table | Create Table | +-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | emp | CREATE TABLE `emp` ( `ename` varchar(10) DEFAULT NULL, `hiredate` date DEFAULT NULL, `sal` decimal(10,2) DEFAULT NULL, `deptno` int(2) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=latin1 | +-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 剩下两种不做介绍，自行百度（渣渣威也不是很懂）:pensive:]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入浅出MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java核心卷Ⅰ-并发]]></title>
    <url>%2F2019%2F03%2F31%2Fjava-he-xin-juan-i-bing-fa%2F</url>
    <content type="text"><![CDATA[看了很久的书，总算对多线程并发有所了解，记录一下 了解知识基础知识操作系统 我们知道一台计算机的资源是有限的，我们需要利用有限的资源完成很多事情，但是又要保证公平，那么我们该怎么做呢？操作系统是这样做的，在这段时间内（时间片）将这些资源给你用，其他人不能做。过了这段时间，又将资源分给其他人做。就像小时候吃蛋糕，蛋糕只有一个，我想吃，姐姐也想吃，又不能同时吃，又不能切开，怎么办？你吃一口，然后我吃一口啊。 线程和进程： 进程就是我们电脑有很多软件同时运行，比如QQ、IDEA、360啊 进程就是我们在用QQ的时候，同时接受n个小姐姐的消息，我们又给别人发文件。 不懂得自行谷歌：放一个链接 并发和并行 并发：通过cpu调度算法，让用户看上去同时执行，实际上从cpu操作层面不是真正的同时。并发往往在场景中有公用的资源，那么针对这个公用的资源往往产生瓶颈，我们会用TPS或者QPS来反应这个系统的处理能力。 并行：多个cpu实例或者多台机器同时执行一段处理逻辑，是真正的同时。 如何编写多线程程序捏(￣▽￣)* 继承Thread类，重写该类的run()方法 class MyThread extends Thread { private int i = 0; @Override public void run() { for (i = 0; i &lt; 100; i++) { System.out.println(Thread.currentThread().getName() + " " + i); } } } public class ThreadTest { public static void main(String[] args) { for (int i = 0; i &lt; 100; i++) { System.out.println(Thread.currentThread().getName() + " " + i); if (i == 30) { Thread myThread1 = new MyThread(); // 创建一个新的线程 myThread1 此线程进入新建状态 Thread myThread2 = new MyThread(); // 创建一个新的线程 myThread2 此线程进入新建状态 myThread1.start(); // 调用start()方法使得线程进入就绪状态 myThread2.start(); // 调用start()方法使得线程进入就绪状态 } } } } 继承Thread类，重写run方法，run方法里面的就是线程执行体。当创建此线程类对象时一个新线程得以创建，并进入线程新建状态。通过调用线程对象引用的start()方法，使得该线程进入到就绪状态，此时此线程并不一定会马上得以执行，这取决于CPU调度时机。 实现Runnable接口，实现run()方法，该run()方法同样是线程执行体。创建Runnable实现类的实例，并以此实例作为Thread类的target来创建Thread对象，该Thread对象才是真正的线程对象。此处是不是很萌币，接下来看代码，要静心哦。 class MyRunnable implements Runnable { private int i = 0; @Override public void run() { for (i = 0; i &lt; 100; i++) { System.out.println(Thread.currentThread().getName() + " " + i); } } } public class ThreadTest { public static void main(String[] args) { for (int i = 0; i &lt; 100; i++) { System.out.println(Thread.currentThread().getName() + " " + i); if (i == 30) { Runnable myRunnable = new MyRunnable(); // 创建一个Runnable实现类的对象 Thread thread1 = new Thread(myRunnable); // 将myRunnable作为Thread target创建新的线程 Thread thread2 = new Thread(myRunnable); thread1.start(); // 调用start()方法使得线程进入就绪状态 thread2.start(); } } } } 走到这里是不是有些想法，怎么这么麻烦。有了Thread为什么还要用Runnable，是来抢我饭碗的吗？？？还真是的，来抢Thread的饭碗的。 使用Runnable能够避免单继承的局限，可以实现多个接口 Runnable适合资源的共享，Thread每次创建一个，都是不同的对象，都分家了，不适合共享。 Thread和Runnable关系 public class ThreadTest { public static void main(String[] args) { for (int i = 0; i &lt; 100; i++) { System.out.println(Thread.currentThread().getName() + " " + i); if (i == 30) { Runnable myRunnable = new MyRunnable(); Thread thread = new MyThread(myRunnable); thread.start(); } } } } class MyRunnable implements Runnable { private int i = 0; @Override public void run() { System.out.println("in MyRunnable run"); for (i = 0; i &lt; 100; i++) { System.out.println(Thread.currentThread().getName() + " " + i); } } } class MyThread extends Thread { private int i = 0; public MyThread(Runnable runnable){ super(runnable); } @Override public void run() { System.out.println("in MyThread run"); for (i = 0; i &lt; 100; i++) { System.out.println(Thread.currentThread().getName() + " " + i); } } } ​ 这个时候你可能会有疑惑，到底这里到底是使用Thread的run()方法呢，还是使用MyThread方法呢，咚咚脑子，发现是MyThread继承重写了Thread的Run()，那么现在是运行那个一目了然。 ​ 底层探究一波： ​ Runnable接口 public interface Runnable { public abstract void run(); } ​ Thread类 ​ 其实在底层，Thread是实现了Runnable方法滴。Thread对run方法的实现 @Override public void run() { if (target != null) { target.run(); } } ​ 也就是说，当执行到Thread类中的run()方法时，会首先判断target是否存在，存在则执行target中的run()方法，也就是实现了Runnable接口并重写了run()方法的类中的run()方法。但是上述给到的列子中，由于多态的存在，根本就没有执行到Thread类中的run()方法，而是直接先执行了运行时类型即MyThread类中的run()方法。 ​ 现在我们是不是可以理解之前为什么要用Thread(Runnable)了呢。 使用Callable和Future接口创建线程。具体是创建Callable接口的实现类，并实现call()方法。并使用FutureTask类来包装Callable实现类的对象，且以此FutureTask对象作为Thread对象的target来创建线程。 public class ThreadTest { public static void main(String[] args) { Callable&lt;Integer> myCallable = new MyCallable(); // 创建MyCallable对象 FutureTask&lt;Integer> ft = new FutureTask&lt;Integer>(myCallable); //使用FutureTask来包装MyCallable对象 for (int i = 0; i &lt; 100; i++) { System.out.println(Thread.currentThread().getName() + " " + i); if (i == 30) { Thread thread = new Thread(ft); //FutureTask对象作为Thread对象的target创建新的线程 thread.start(); //线程进入到就绪状态 } } System.out.println("主线程for循环执行完毕.."); try { int sum = ft.get(); //取得新创建的新线程中的call()方法返回的结果 System.out.println("sum = " + sum); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } } } class MyCallable implements Callable&lt;Integer> { private int i = 0; // 与run()方法不同的是，call()方法具有返回值 @Override public Integer call() { int sum = 0; for (; i &lt; 100; i++) { System.out.println(Thread.currentThread().getName() + " " + i); sum += i; } return sum; } } 首先，我们发现，在实现Callable接口中，此时不再是run()方法了，而是call()方法，此call()方法作为线程执行体，同时还具有返回值！在创建新的线程时，是通过FutureTask来包装MyCallable对象，同时作为了Thread对象的target。那么看下FutureTask类的定义： public class FutureTask&lt;V> implements RunnableFuture&lt;V> { //.... } public interface RunnableFuture&lt;V> extends Runnable, Future&lt;V> { void run(); } 于是，我们发现FutureTask类实际上是同时实现了Runnable和Future接口，由此才使得其具有Future和Runnable双重特性。通过Runnable特性，可以作为Thread对象的target，而Future特性，使得其可以取得新创建线程中的call()方法的返回值。 执行下此程序，我们发现sum = 4950永远都是最后输出的。而“主线程for循环执行完毕..”则很可能是在子线程循环中间输出。由CPU的线程调度机制，我们知道，“主线程for循环执行完毕..”的输出时机是没有任何问题的，那么为什么sum =4950会永远最后输出呢？ 原因在于通过ft.get()方法获取子线程call()方法的返回值时，当子线程此方法还未执行完毕，ft.get()方法会一直阻塞，直到call()方法执行完毕才能取到返回值。 三部走下来是不是感觉他们似乎是包装在包装，增强在增强，我怀疑这是动态增强，不过源码我还没有深入，以后会深入的啦 以上编写多线程摘自：我是一个链接 线程状态放大招。。。 线程有五个状态： 新建状态（New）：当线程对象对创建后，即进入了新建状态，如：Thread t = new MyThread(); 就绪状态（Runnable）：当调用线程对象的start()方法（t.start();），线程即进入就绪状态。处于就绪状态的线程，只是说明此线程已经做好了准备，随时等待CPU调度执行，并不是说执行了t.start()此线程立即就会执行； 运行状态（Running）：当CPU开始调度处于就绪状态的线程时，此时线程才得以真正执行，即进入到运行状态。注：就绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中； 阻塞状态（Blocked）：处于运行状态中的线程由于某种原因，暂时放弃对CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才 有机会再次被CPU调用以进入到运行状态。根据阻塞产生的原因不同，阻塞状态又可以分为三种： 等待阻塞：运行状态中的线程执行wait()方法，使本线程进入到等待阻塞状态，使该线程处于等待池(wait blocked pool),直到notify()/notifyAll()，线程被唤醒被放到锁定池(lock blocked pool )，释放同步锁使线程回到可运行状态（Runnable）； 同步阻塞 – 线程在获取synchronized同步锁失败(因为锁被其它线程所占用)，它会进入同步阻塞状态（lock blocked pool）； 其他阻塞 – 通过调用线程的sleep()或join()或发出了I/O请求时，线程会进入到阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。注：此时锁还在他身上。 死亡状态（Dead）：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。 特别是， 可以调用线程的stop方法杀死一个线程。该方法抛出ThreadDeath错误对象,由此杀死线程。但是，stop 方法已过时， 不要在自己的代码中调用这个方法。 特别的：在runnable状态的线程是处于被调度的线程，此时的调度顺序是不一定的。Thread类中的yield方法可以让一个running状态的线程转入runnable。注：此时同样可以立刻被运行，如果此时线程没有阻塞、且他的优先级最高或并列最高 中断程序使用interrupt可以中断程序，但他不是真正的中断运行中的程序，只能改变中断状态。我们可以使用stop方法中断线程，但这是不安全。让我吃饭吃到一半我不得和你拼命？？？ 没有可以强制线程终止的方法。然而， interrupt 方法可以用来请求终止线程。当对一个线程调用interrupt 方法时，线程的中断状态将被置位。这是每一个线程都具有的boolean 标志。每个线程都应该不时地检査这个标志， 以判断线程是否被中断。 所以我们使用的时候会检测代码是否中断。 while(!Thread.currentThread().isInterrupted){ 巴拉巴拉啊啦...... } 如果线程被阻塞， 就无法检测中断状态。这是产生InterruptedExceptioii 异常的地方。 当在一个被阻塞的线程（调用sleep 或wait ) 上调用interrupt 方法时， 阻塞调用将会被Interrupted Exception 异常中断。 中断一个线程不过是引起它的注意。被中断的线程可以决定如何响应中断。某些线程是如此重要以至于应该处理完异常后， 继续执行， 而不理会中断。但是，更普遍的情况是，线程将简单地将中断作为一个终止的请求 不要在try catch中线程异常处理 可能会有一些坑，有哪些坑我就不知道了，前辈的苦药还是要吃的 void mySubTask() throws InterruptedException{ sleep(delay) ; } 线程属性线程优先级 线程的优先级用1-10，一般使用三个值： 最低优先级 1：Thread.MIN_PRIORITY 最高优先级 10：Thread.MAX_PRIORITY 普通优先级 5：Thread.NORM_PRIORITY 可以使用setPriority方法设置优先级 使用Thread.currentThread().getPriority()获取线程优先级 Java 默认的线程优先级是父线程的优先级，而非普通优先级Thread.NORM_PRIORITY，因为主线程默认优先级是普通优先级Thread.NORM_PRIORITY，所以如果不主动设置线程优先级，则新创建的线程的优先级就是普通优先级Thread.NORM_PRIORITY 最大优先级 一般在使用线程组的时候设置线程组的优先级。 系统线程组默认最大优先级Thread.NORM_PRIORITY 如果在创建线程组之前已经有线程且线程级别比线程组最大优先级高，此时不会削减此线程的优先级，依旧使用此线程的优先级，只有在修改该线程优先级时此线程组的最大优先级才会起作用。 在拥有线程组之后创建的子线程，最大优先级为线程组的优先级。修改也无法超过。 使用线程的时候尽量少设置线程优先级，可能会有乱七八糟的bug。线程的优先级是基于操作系统的，优先级高只能说明他会优先被操作系统分配资源运行，其他线程同样有机会运行。setPriority只是局部的使用，应该和线程组、父线程组合使用。 一般Thread.吧利巴鲁表示main线程。 守护线程 线程分为前台线程和后台线程（守护线程） 后台线程为前台线程提供服务，在前台线程运行完之后，后台线程才会dead 使用setDaemon()方法将线程设置为后台线程 main线程为前台线程 未捕捉线程异常处理器必须属于一个实现Thread.UncaughtExceptionHandler接口的类。这个接口只有—个方法。 public interface UncaughtExceptionHandler { /** * Method invoked when the given thread terminates due to the * given uncaught exception. * &lt;p>Any exception thrown by this method will be ignored by the * Java Virtual Machine. * @param t the thread * @param e the exception */ void uncaughtException(Thread t, Throwable e); } 可以用setUncaughtExceptionHandler 方法为任何线程安装一个处理器。 也可以用Thread类的静态方法setDefaultUncaughtExceptionHandler 为所有线程安装一个默认的处理器。 // null unless explicitly set private volatile UncaughtExceptionHandler uncaughtExceptionHandler; // null unless explicitly set private static volatile UncaughtExceptionHandler defaultUncaughtExceptionHandler; 如果不安装默认的处理器， 默认的处理器为空。但是， 如果不为独立的线程安装处理器，此时的处理器就是该线程的ThreadGroup 对象。ThreadGroup类实现Thread.UncaughtExceptionHandler接口。它的uncaughtException方法做如下操作（下面的内容不是很了解） 1 ) 如果该线程组有父线程组， 那么父线程组的uncaughtException方法被调用。2 ) 否则， 如果Thread.getDefaultExceptionHandler 方法返回一个非空的处理器， 则调用该处理器。3 ) 否则， 如果Throwable是ThreadDeath 的一个实例， 什么都不做。4 ) 否则， 线程的名字以及Throwable 的栈轨迹被输出到System.err 上。 public void uncaughtException(Thread t, Throwable e) { if (parent != null) {//如果该线程组有父线程组， 那么父线程组的`uncaughtException `方法被调用。 parent.uncaughtException(t, e); } else {//如果`Thread.getDefaultExceptionHandler` 方法返回一个非空的处理器， 则调用该处理器 Thread.UncaughtExceptionHandler ueh = Thread.getDefaultUncaughtExceptionHandler(); if (ueh != null) {//如果`Throwable `是`ThreadDeath` 的一个实例， 什么都不做。 ueh.uncaughtException(t, e); } else if (!(e instanceof ThreadDeath)) {//线程的名字以及`Throwable` 的栈轨迹被输出到`System.err` 上。 System.err.print("Exception in thread \"" + t.getName() + "\" "); e.printStackTrace(System.err); } } } 如果没有设置线程组，将会使用Main线程的异常处理，在Thread.init()中有处理，上源码，ThreadGroup g if (g == null) { /* Determine if it's an applet or not */ /* If there is a security manager, ask the security manager what to do. */ if (security != null) { g = security.getThreadGroup(); } /* If the security doesn't have a strong opinion of the matter use the parent thread group. */ if (g == null) { g = parent.getThreadGroup(); } } 线程同步锁对象Java SE 5.0 引入了ReentrantLock类，该类实现Lock接口方法。Lock方式是JDK层面的提供给开发人员的接口，因此开发人员在使用它来解决并发问题时，需要手动获取锁和释放锁。Lock接口源码 public interface Lock { void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition(); } 主要使用方法： Lock():加锁,如果当前锁被其他线程获取，该线程将进入等待队列，直到使用当前锁的线程释放当前锁。使用Lock必须在try…catch…块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生 unLock()：解锁 其他方法： lockInterruptibly():当通过这个方法去获取锁时，如果线程 正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态 tryLock:加锁，有返回值。当前锁被其他线程占用的时候，会立刻返回false，不会等待，其重载方法会等待一段时间，若没有空闲锁，返回false 注意，当一个线程获取了锁之后，是不会被interrupt()方法中断的。因为interrupt()方法只能中断阻塞过程中的线程而不能中断正在运行过程中的线程。因此，当通过lockInterruptibly()方法获取某个锁时，如果不能获取到，那么只有进行等待的情况下，才可以响应中断的。与synchronized相比，当一个线程处于等待某个锁的状态，是无法被中断的，只有一直等待下去。 代码： package bingxing; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; public class Bank { /** * 总金额 */ private final double[] accounts; /** * 锁 */ private Lock backLock; /** * 锁相关的条件对象 */ private Condition sufficientFunds; /** * 初始化 * @param n * @param initialBalance */ public Bank(int n, double initialBalance){ accounts=new double[n]; for(int i=0;i&lt;accounts.length;i++){ accounts[i]=initialBalance; } backLock=new ReentrantLock();//构建一个可重入保护区的锁 sufficientFunds = backLock.newCondition();//返回一个与该锁相关的条件对象 } /** * 获取总金额，使用锁防止查询的同时存在修改情况 * @return */ public double getTotalBalance(){ backLock.lock(); try{ double sum=0; for (double a : accounts) { sum += a; } return sum; }finally { backLock.unlock(); } } /** * 转账 使用锁，防止多个对象对同一账户操作 * 使用条件对象，防止出现总金额少于转账金额 设置条件对象 当账户金额多余转账金额，触发接下来的操作 * @param from * @param to * @param amount * @throws InterruptedException */ public void transfer(int from,int to,double amount) throws InterruptedException{ //锁 backLock.lock(); try{ //执行业务操作 while(accounts[from]&lt;amount){ //总数少于转出的数量 设置条件保存对象 释放锁给其他线程，等待其他线程条件激活 sufficientFunds.await();//将该条件放到线程等待集中 } System.out.print(Thread.currentThread());//输出当前线程 //执行操作 accounts[from] -= amount; System.out.printf("%10.2f from %d to %d ",amount,from,to); accounts[to] +=amount; System.out.printf("Total Balance: %10.2f%n",getTotalBalance()); sufficientFunds.signalAll();//解除该线程等待集中的所有堵塞线程 }finally { //解锁 backLock.unlock(); } } /** * 计算账户的个数 * @return the number of accounts */ public int size(){ return accounts.length; } } package bingxing; public class SynchBankTest { /** * 设置账户数量 */ public static final int NACCOUNTS = 100; /** * 设置账户金额 */ public static final double INITIAL_BALANCE = 1000; public static void main(String[] args) { Bank b=new Bank(NACCOUNTS,INITIAL_BALANCE); int i; for(i=0;i&lt;NACCOUNTS;i++){ TransferRunnable r=new TransferRunnable(b,i,INITIAL_BALANCE); Thread t=new Thread(r); t.start(); } } } package bingxing; public class TransferRunnable implements Runnable { private Bank bank; private int fromAccount; private double maxAmount; private int DELAY=10; public TransferRunnable(Bank bank, int fromAccount, double maxAmount) { this.bank = bank; this.fromAccount = fromAccount; this.maxAmount = maxAmount; } @Override public void run() { try{ while (true){ int toAccount = (int)(bank.size()*Math.random()); double amount = maxAmount*Math.random(); bank.transfer(fromAccount,toAccount,amount); Thread.sleep((int)(DELAY*Math.random())); } }catch (InterruptedException e){ } } } 补充： ReentrantLock，即可重入锁。ReentrantLock是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法。 使用锁时应该将锁放在全局变量，如果放在局部变量，那么每个调用的对象都会拥有自己锁，不能实现锁共享 ReentrantLock() //构建一个可以被用来保护临界区的可重入锁。 ReentrantLock(boo1ean fair ) //构建一个带有公平策略的锁。一个公平锁偏爱等待时间最长的线程。但是，这一公平的保证将大大降低性能。所以， 默认情况下， 锁没有被强制为公平的。 条件对象 通常， 线程进人临界区，却发现在某一条件满足之后它才能执行。要使用一个条件对象来管理那些已经获得了一个锁但是却不能做有用工作的线程。我们使用条件对象（条件变量conditional variable） 在书中如果A用户需要向B用户转账，但是A用户没有足够多的金额，这时候该怎么办呢？ 此时A用户需要等待其他用户给他转账，直到他的总金额满足转账金额，此时A一直霸占着锁，其他用户无法获取锁，这就带来问题，于是使用newCondition()方法创建一个条件对象，当该用户由于总金额不足，调用await()方法时（await()方法没办法自己激活自己）。会将锁交给其他线程，自己进入等待集（阻塞）中，直到其他线程激活等待的线程。 while(accounts[from]&lt;amount){ //总数少于转出的数量 设置条件保存对象 释放锁给其他线程，等待其他线程条件激活 sufficientFunds.await();//将该条件放到线程等待集中 } signal():随机解除等待集中某个线程的阻塞情况。有可能会出现死锁的情况 signalAll():解除等待线程的阻塞，以便这些线程可以在当前线程退出同步方法之后，通过竞争实现对对象的访问。 一个锁对象可以有多个相关大的条件对象 当一个线程拥有某个条件的锁时， 它仅仅可以在该条件上调用await、signalAll 或signal 方法 等待获得锁的线程和调用await 方法的线程存在本质上的不同。一旦一个线程调用await方法， 它进人该条件的等待集。当锁可用时，该线程不能马上解除阻塞。相反，它处于阻塞状态，直到另一个线程调用同一条件上的signalAll 方法时为止。 总结一下（书里面滴）重点 锁用来保护代码片段， 任何时刻只能有一个线程执行被保护的代码。 锁可以管理试图进入被保护代码段的线程。 锁可以拥有一个或多个相关的条件对象。 每个条件对象管理那些已经进入被保护的代码段但还不能运行的线程。 栗子代码在锁对象哪节里 Condition newCondition() //返回一个与该锁相关的条件对象。 void await( ) //将该线程放到条件的等待集中。 void signalA11( ) //解除该条件的等待集中的所有线程的阻塞状态。 void signal ( ) //从该条件的等待集中随机地选择一个线程， 解除其阻塞状态。 synchronized关键字 Java中的每一个对象都有一个内部锁。如果一个方法用synchronized 关键字声明，那么对象的锁将保护整个方法。也就是说，要调用该方法， 线程必须获得内部的对象锁。 内部对象锁只有一个相关条件。wait方法添加一个线程到等待集中，notifyll /notify方法解除等待线程的阻塞状态。换句话说，调用wait或notityAll等价于 intrinsicCondition.await(); intrinsicCondition.signalAll() ; 内部锁和条件局限性 不能中断一个正在试图获得锁的线程。 试图获得锁时不能设定超时。 每个锁仅有单一的条件， 可能是不够的 使用方法(摘自书中)： 第一种作用于方法： class Bank { private double accounts; public synchronized void transfer(int from，int to, int amount) throws InterruptedException { while (accounts[from] &lt; amount) wait(); // wait on intrinsic object lock's single condition accounts[from] -= amount ; accounts[to] += amount ; notifyAll()；// notify all threads waiting on the condition } public synchronized double getTotalBalanceO { . . . } } 第二种 作用于代码块，如下，在多线程环境下，synchronized块中的方法获取了lock实例的monitor，如果实例相同，那么只有一个线程能执行该块内容： public class Thread1 implements Runnable { Object lock; public void run() { synchronized(lock){ ..do something } } } 重点：静态方法声明synchronized 和普通方法声明 java中锁的概念。一个是实例锁（锁在某一个实例对象上，如果该类是单例，那么该锁也具有全局锁的概念），一个是全局锁（该锁针对的是类，无论实例多少个对象，那么线程都共享该锁）。实例锁对应的就是synchronized关键字，而类锁（全局锁）对应的就是static synchronized（或者是锁在该类的class或者classloader对象上）普通方法声明是指锁定那个方法，其他线程不能使用。而静态方法声明会锁定那个类对象，就是含有那个锁定方法的类将会被锁定 不同对象，他们的锁是不一样的 同步阻塞这一部分用的较少，理解不是很透彻 每一个Java 对象有一个锁。线程可以通过调用同步方法获得锁。还有另一种机制可以获得锁，通过进入一个同步阻塞 public class Bank { private doublet] accounts; private Object lock = new Object。; public void transfer(int from, int to, int amount) { synchronized (lock) // an ad-hoc lock { accounts[from] -= amount; accounts[to] += amount; } System.out.print1n(.. } } 他的目的就是调用传入对象的锁，每个对象的操作都是原子性的。但是他的粒度太小，导致无法保证原子性操作。比如我们传入的是这个对象，这个对象的操作是原子性的，是安全的，但是对这个对象的操作不是原子性的，是无法保证线程安全的。 离子： 监视器​ 监视器是一种同步结构，它允许线程同时互斥（使用锁）和协作，即使用等待集（wait-set）使线程等待某些条件为真的能力 ​ 使用比较形象的说明，监视器就像一个包含一个特殊房间（对象实例）的建筑物，每次只能占用一个线程。这个房间通常包含一些需要防止并发访问的数据。从一个线程进入这个房间到它离开的时间，它可以独占访问房间中的任何数据。进入监控的建筑被称为“进入监控监视器。”进入建筑内部特殊的房间叫做“获取监视器”。房间占领被称为“拥有监视器”，离开房间被称为“释放监视器。”让整个建筑被称为“退出监视器。” ​ 当一个线程访问受保护的数据（进入特殊的房间）时，它首先在建筑物接收（entry-set）中排队。如果没有其他线程在等待（拥有监视器），线程获取锁并继续执行受保护的代码。当线程完成执行时，它释放锁并退出大楼（退出监视器）。 ​ 如果当一个线程到达并且另一个线程已经拥有监视器时，它必须在接收队列中等待（entry-set）。当当前所有者退出监视器时，新到达的线程必须与在入口集中等待的其他线程竞争。只有一个线程能赢得竞争并拥有锁。 ​ 正如上图所示，在该栋房子中，一共会有三个房间。如果一个客户(线程)想要占领这个特殊的房间，它必须首先进入到Entry Set 中进行等待。调度程序将会基于某种策略(比如，FIFO),从Entry Set 中选择某一个客户。如果这个客户(线程)因为某些事件或原因被挂起了，该客户进离开 特殊房间 而进入 等待房间Wait Room，以后，调度程序可能会重新选择它，把它从 等待房间 放入到 特殊房间中。 ​ synchronized就是基于这个实现的。 volatile域首先理解一下多线程内存模型 ​ Java 内存模型来屏蔽掉各种硬件和操作系统的内存差异，达到跨平台的内存访问效果。JLS(Java语言规范)定义了一个统一的内存管理模型JMM(Java Memory Model) Java内存模型规定了所有的变量都存储在主内存中，此处的主内存仅仅是虚拟机内存的一部分，而虚拟机内存也仅仅是计算机物理内存的一部分（为虚拟机进程分配的那一部分）。 Java内存模型分为主内存，和工作内存。主内存是所有的线程所共享的，工作内存是每个线程自己有一个，不是共享的。 每条线程还有自己的工作内存，线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝。线程对变量的所有操作（读取、赋值），都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者之间的交互关系如下图： ​ JLS定义了线程对主存的操作指令：lock，unlock，read，load，use，assign，store，write。这些行为是不可分解的原子操作，在使用上相互依赖，read-load从主内存复制变量到当前工作内存，use-assign执行代码改变共享变量值，store-write用工作内存数据刷新主存相关内容。 lock：把主内存变量标识为一条线程独占，此时不允许其他线程对此变量进行读写。 unlock：解锁一个主内存变量。 read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。 write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。 摘自链接 那么volatile的作用就是， 当一个线程修改了一个变量后，volatile立刻将该修改值写入共享内存中，同时通知其他线程该变量的变化。 禁止进行指令重排序 volatile不能保证原子性，但是可以保定一定的有序性，可以保证有效性 详细参考该链接 写的特别棒 final变量安全地访问一个共享域， 即这个域声明为final时 final Map&lt;String, Double〉accounts = new HashKap&lt;>()； ​ 其他线程会在构造函数完成构造之后才看到这个accounts 变量。​ 如果不使用final，就不能保证其他线程看到的是accounts 更新后的值，它们可能都只是看到null , 而不是新构造的HashMap。​ 当然，对这个映射表的操作并不是线程安全的。如果多个线程在读写这个映射表，仍然需要进行同步。 原子性 假设对共享变量除了赋值之外并不完成其他操作， 那么可以将这些共享变量声明为volatile() 因为volatile()不能保证原子性 java.util.concurrent.atomic 包中有很多类使用了很高效的机器级指令（而不是使用锁） 来保证其他操作的原子性 ep：Atomiclnteger类提供了方法incrementAndGet和decrementAndGet, 它们分别以原子方式将一个整数自增或自减 public static AtomicLong nextNumber = new AtomicLongO ; // In some thread... long id = nextNumber .increinentAndGet(): 如果想完成更复杂的更新，必须使用compareAndSet方法 ep：假设希望跟踪不同线程观察的最大值 do { oldValue = largest.get() ; newValue = Math , max(oldValue, observed) ; } while (llargest.compareAndSet(oldValue, newValue)) ; ​ 如果另一个线程也在更新largest，就可能阻止这个线程更新。这样一来，compareAndSet会返回false, 而不会设置新值。在这种情况下， 循环会更次尝试，读取更新后的值，并尝试修改。最终， 它会成功地用新值替换原来的值。这听上去有些麻烦， 不过compareAndSet方法会映射到一个处理器操作， 比使用锁速度更快 类Atomiclnteger、AtomicIntegerArray、AtomicIntegerFieldUpdater、AtomicLongArray、AtomicLongFieldUpdater、AtomicReference、AtomicReferenceArray 和AtomicReference-FieldUpdater也提供了这些方法 上面是针对数量较少的操作，但是如果我们由大连线程访问相同的原子值。性能会下降因为乐观更新需要太多次重试，使用LongAdder 和LongAccumulator类来解决这个问题。LongAdder包括多个变量（加数)，其总和为当前值。可以有多个线程更新不同的加数，线程个数增加时会自动提供新的加数。通常情况下， 只有当所有工作都完成之后才需要总和的值， 对于这种情况，这种方法会很高效。详细的使用自行谷歌 死锁 Java 编程语言中没有任何东西可以避免或打破这种死锁现象。必须仔细设计程序， 以确保不会出现死锁。 注意前面说的signal和signalAll方法区别导致死锁 线程局部变量 使用ThreadLocal辅助类为各个线程提供各自的实例 通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。而使用ThreadLocal创建的变量只能被当前线程访问，其他线程则无法访问和修改。 支持泛型 T get() //得到这个线程的当前值。如果是首次调用get, 会调用initialize 来得到这个值。 protected initialize() //应覆盖这个方法来提供一个初始值。默认情况下，这个方法返回null。 void set(T t) //为这个线程设置一个新值。 void remove() //删除对应这个线程的值。 锁测试和超时boolean tryLock() //尝试获得锁而没有发生阻塞；如果成功返回真。这个方法会抢夺可用的锁， 即使该锁有公平加锁策略， 即便其他线程已经等待很久也是如此。 boolean tryLock(long time, TimeUnit unit) //尝试获得锁，阻塞时间不会超过给定的值；如果成功返回true。 void lockInterruptibly() //获得锁， 但是会不确定地发生阻塞。如果线程被中断， 抛出一个InterruptedException异常。 boolean await( 1ong time , TimeUnit unit ) //进人该条件的等待集， 直到线程从等待集中移出或等待了指定的时间之后才解除阻塞。如果因为等待时间到了而返回就返回false , 否则返回true。 void awaitUninterruptibly( ) //进人该条件的等待集， 直到线程从等待集移出才解除阻塞。如果线程被中断， 该方法不会抛出InterruptedException 异常。 其实就是在锁对象里说的 读/写锁​ 如果很多线程从一个数据结构读取数据而很少线程修改其中数据的话，使用ReentrantReadWriteLock类。此时允许读者线程共享访问，写线程依旧是互斥的 下面是使用读/ 写锁的必要步骤：1 ) 构造一个ReentrantReadWriteLock 对象： private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); 2 ) 抽取读锁和写锁： private Lock readLock = rwl . readLock() ; private Lock writeLock = rwl .writeLock(); 3 ) 对所有的获取方法加读锁： public double getTotalBalanceO { readLock.lock()； try { . . . } finally { readLock.unlock() ; } } 4 ) 对所有的修改方法加写锁： public void transfer(. . .) { writeLock.lockO; try { . . . } finally { writeLock.unlock(); } } Lock readLock() //得到一个可以被多个读操作共用的读锁， 但会排斥所有写操作。 Lock writeLock() //得到一个写锁， 排斥所有其他的读操作和写操作。 阻塞队列 使用队列，可以安全地从一个线程向另一个线程传递数据 当我们想从向队列添加元素而队列已满， 或是想从队列移出元素而队列为空的时候， 阻塞队列（ blocking queue ) 导致线程阻塞 java.util.concurrent 包中有几个阻塞队列变种 LinkedBlockingQueue的容量是没有上边界的，但是，也可以选择指定最大容量。 LinkedBlockingDeque是一个双端的版本。 ArrayBlockingQueue 在构造时需要指定容量，并且有一个可选的参数来指定是否需要公平性。若设置了公平参数， 则那么等待了最长时间的线程会优先得到处理。通常，公平性会降低性能， 只有在确实非常需要时才使用它。PriorityBlockingQueue是一个带优先级的队列， 而不是先进先出队列。元素按照它们的优先级顺序被移出。该队列是没有容量上限， 但是，如果队列是空的， 取元素的操作会阻塞。 DelayQueue包含实现Delayed 接口的对象： interface Delayed extends Comparable&lt;Delayed> { long getDel ay(TimeUnit unit); } ​ getDelay 方法返回对象的残留延迟。负值表示延迟已经结束。元素只有在延迟用完的情况下才能从DelayQueue 移除。还必须实现compareTo 方法。DelayQueue 使用该方法对元素进行排序 TranSferQueUe接口，允许生产者线程等待， 直到消费者准备就绪可以接收一个元素 java.util.concurrent.ArrayBlockingQueue&lt;E> 5.0 ArrayBlockingQueue( int capacity) ArrayBlockingQueue( int capacity, boolean fair ) //构造一个带有指定的容量和公平性设置的阻塞队列。该队列用循环数组实现。 java.util.concurrent.LinkedBlockingDeque&lt;E> 6 LinkedBlockingQueue( ) LinkedBlockingDeque( ) //构造一个无上限的阻塞队列或双向队列，用链表实现。 LinkedBlockingQueue( int capacity ) LinkedBlockingDeque( int capacity ) //根据指定容量构建一个有限的阻塞队列或双向队列，用链表实现。 java.util.concurrent.DelayQueue&lt;E extends Delayed〉5.0 DelayQueue( ) //构造一个包含Delayed 元素的无界的阻塞时间有限的阻塞队列。只有那些延迟已经超过时间的元素可以从队列中移出。 java.util.concurrent.Delayed 5.0 long getDelay(Timellnit unit ) //得到该对象的延迟，用给定的时间单位进行度量。 java.util.concurrent.PriorityBlockingQueue&lt;E> 5.0 PriorityBlockingQueue( ) PriorityBlockingQueiie( int initialCapaci ty) PriorityBlockingQueue( int initialCapacity, Comparator ? super E> comparator ) /*构造一个无边界阻塞优先队列，用堆实现。 参数： initialCapacity 优先队列的初始容量。默认值是11。comparator 用来对元素进行比较的比较器， 如果没有指定， 则元素必须实现Comparable 接口。*/ 线程安全的集合​ 一个线程可能要开始向表中插入一个新元素。假定在调整散列表各个桶之间的链接关系的过程中， 被剥夺了控制权。如果另一个线程也开始遍历同一个链表， 可能使用无效的链接并造成混乱， 会抛出异常或者陷人死循环。 ​ 阻塞队列就是线程安全的集合 高效的映射、集和队列​ java.util.concurrent包提供了映射、有序集和队列的高效实现：ConcurrentHashMap、 ConcurrentSkipListMap 、 ConcurrentSkipListSet 和ConcurrentLinkedQueue ConcurrentLinkedQueue&lt; E>() //构造一个可以被多线程安全访问的无边界非阻塞的队列。 ConcurrentSkipListSet&lt;E>() ConcurrentSkipListSet&lt;E>(Comparator&lt;? super E> comp) //构造一个可以被多线程安全访问的有序集。第一个构造器要求元素实现Comparable接口。 ConcurrentHashMapCK, V>() ConcurrentHashMap&lt;K, V>(1nt 1n1t1 alCapacity) ConcurrentHashMapCK, V>(int initialCapacity, float 1oadFactor, 1nt concurrencyLevel) /*构造一个可以被多线程安全访问的散列映射表。 参数: initialCapacity 集合的初始容量。默认值为16。 loadFactor 控制调整： 如果每一个桶的平均负载超过这个因子，表的大小会被重新调整。默认值为0.75。 concurrencyLevel 并发写者线程的估计数目。*/ ConcurrentSkipListMap&lt;K, V>() ConcurrentSkipListSet&lt;K, V>(Comparator&lt;? super K> comp) //构造一个可以被多线程安全访问的有序的映像表。第一个构造器要求键实现Comparable 接口 和一般的集合的size方法不同，size方法不会再常量时间内操作，确定集合的当前大小需要遍历。容易出错 映射条目的原子更新多线程统计总数的问题，可能某个线程在统计某个词时被中断，其他线程修改后续内容了，导致统计结果出错。 使用ConcurrentHashMap实现原子更新。ConcurrentHashMap&lt;String，AtomicLong&gt;或者ConcurrentHashMap&lt;String，LongAdder&gt; map.putlfAbsent(word, new LongAdderO)； map.get(word) .increment(); 调用compute 方法时可以提供一个键和一个计算新值的函数。这个函数接收键和相关联的值（如果没有值，则为null), 它会计算新值,离子 map.compute(word, (k, v) -> v = null ? 1: v + 1); LongAdder 构造器只在确实需要一个新的计数器时才会调用。首次增加一个键时通常需要做些特殊的处理。这个方法有一个参数表示键不存在时使用的初始值。否则， 就会调用你提供的函数来结合原值与初始值 map.merge(word, 1L, (existi ngValue, newValue) -> existingValue + newValue) ; 对并发散列映射的批操作不懂 并发集视图 使用ConcurrentHashMap实现，并没有ConcurrentHashSet类。这会得到一个映射而不是集， 而且不能应用Set 接口的操作。静态newKeySet方法会生成一个Set&lt;K&gt;, 这实际上是ConcurrentHashMap&lt;K, Boolean〉的一个包装器。（所有映射值都为Boolean.TRUE, 不过因为只是要把它用作一个集， 所以并不关心具体的值。） Set&lt;String> words = ConcurrentHashMap.&lt;String>newKeySet() ; 如果原来有一个映射，keySet方法可以生成这个映射的键集。这个集是可变的。如果删除这个集的元素，这个键（以及相应的值）会从映射中删除 其实就是用Map表示Set，只用index，不用value(映射值为true) 写数组的拷贝 CopyOnWriteArrayList 和CopyOnWriteArraySet 是线程安全的集合， 其中所有的修改线程对底层数组进行复制。如果在集合上进行迭代的线程数超过修改线程数， 这样的安排是很有用的。当构建一个迭代器的时候， 它包含一个对当前数组的引用。如果数组后来被修改了，迭代器仍然引用旧数组， 但是，集合的数组已经被替换了。因而，旧的迭代器拥有一致的（可能过时的）视图，访问它无须任何同步开销。 其实就是多线程的内存模型 较早的线程安全集合Vector 和Hashtable 类就提供了线程安全的动态数组和散列表的实现。现在这些类被弃用了， 取而代之的是AnayList 和HashMap 类。这些类不是线程安全的，而集合库中提供了不同的机制。任何集合类都可以通过使用同步包装器（ synchronization wrapper) 变成线程安全的： List&lt;E> synchArrayList = Col lections ,synchronizedList (new ArrayList&lt;E>()) ; Map&lt;K , V> synchHashMap = Col1ections.synchronizedMap(new HashMap&lt;K , V>())； 最好使用java.Util.COnciirrent 包中定义的集合 并行数组算法静态Arrays.parallelSort 方法可以对一个基本类型值或对象的数组排序 对对象排序时，可以提供一个Comparator Arrays,parallelSort(words, Comparator.comparing(String::length)); 对于所有方法都可以提供一个范围的边界 values,parallelSort(values,length / 2, values,length) ; // Sort the upper half Callable和FutureRunnable封装一个异步运行的任务，可以把它想象成为一个没有参数和返回值的异步方法。Callable与Runnable类似， 但是有返回值。Callable接口是一个参数化的类型， 只有一个方法call public interface Callable&lt;V> { /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception; } Future 保存异步计算的结果。可以启动一个计算，将Future 对象交给某个线程，然后忘掉它。Future 对象的所有者在结果计算好之后就可以获得它。其实就是在其它线程完成计算后，他才会启动计算，并将计算结果返回。 public interface Future&lt;V> { boolean cancel(boolean mayInterruptIfRunning);//撤销一个正在执行的任务，中断该线程（打上中断标记）如果计算还没有开始，它被取消且不再开始。如果计算处于运行之中，那么如果maylnterrupt 参数为true, 它就被中断。 boolean isCancelled();//判断是否撤销 boolean isDone();//表示任务是否已经完成 如果任务结束，无论是正常结束、中途取消或发生异常， 都返回true。 V get() throws InterruptedException, ExecutionException;//获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;//获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 } FutureTask 类图 计算匹配的文件数目 package future; import java.io.File; import java.io.IOException; import java.util.ArrayList; import java.util.List; import java.util.Scanner; import java.util.concurrent.Callable; import java.util.concurrent.ExecutionException; import java.util.concurrent.Future; import java.util.concurrent.FutureTask; public class FutureTest { public static void main(String[] args) { try (Scanner in=new Scanner(System.in)) { System.out.print("Enter base directory (e.g. /usr/local/jdk1.6.0/src): "); String directory = in.nextLine(); System.out.print("Enter keyword (e.g. volatile): "); String keyWord = in.nextLine(); MatchCounter counter=new MatchCounter(new File(directory),keyWord); /* 构造一个既是Future又是Runnable对象 */ FutureTask&lt;Integer> task=new FutureTask&lt;>(counter); Thread t=new Thread(task); t.start(); try { System.out.println(task.get()+" matching files"); }catch (ExecutionException e){ e.printStackTrace(); } }catch (InterruptedException e){ } } } /** * 计算包含keyword的数量 */ class MatchCounter implements Callable&lt;Integer>{ private File directory; private String keyWord; public MatchCounter(File directory, String keyWord) { this.directory = directory; this.keyWord = keyWord; } /** * 运行一个将产生结果的任务 * @return * @throws Exception */ @Override public Integer call() throws Exception { int count=0; try{ File[] files = directory.listFiles(); List&lt;Future&lt;Integer>> results=new ArrayList&lt;>(); for (File file : files) { if (file.isDirectory()) { MatchCounter counter=new MatchCounter(file , keyWord); FutureTask&lt;Integer> task=new FutureTask&lt;>(counter); results.add(task); Thread t = new Thread(task); t.start(); }else { if (search(file)) count++; } for (Future&lt;Integer> result : results) { try { count += result.get(); }catch (ExecutionException e){ e.printStackTrace(); } } } }catch (InterruptedException e){ } return count; } public boolean search(File file){ try { try (Scanner in=new Scanner(file,"UTF-8")){ boolean found=false; while (!found&amp;&amp;in.hasNextLine()){ String line=in.nextLine(); if(line.contains(keyWord)) found=true; } return found; } }catch (IOException e){ return false; } } } 执行器执行器（ Executor) 类有许多静态工厂方法用来构建线程池 线程池newCachedThreadPool方法构建了一个线程池， 对于每个任务， 如果有空闲线程可用， 立即让它执行任务， 如果没有可用的空闲线程， 则创建一个新线程。 newFixedThreadPool 方法构建一个具有固定大小的线程池。如果提交的任务数多于空闲的线程数， 那么把得不到服务的任务放置到队列中。当其他任务完成以后再运行它们。 newSingleThreadExecutor 是一个退化了的大小为1 的线程池： 由一个线程执行提交的任务， 一个接着一个。 这3 个方法返回实现了ExecutorService接口的ThreadPoolExecutor类的对象。 使用以下方法将一个Runnable对象或Callable 对象提交给ExecutorService: &lt;T> Future&lt;T> submit(Callable&lt;T> task); //提交一个Callable, 并且返回的Future 对象将在计算结果准备好的时候得到它。 &lt;T> Future&lt;T> submit(Runnable task, T result); //提交一个Runnable， 并且Future 的get 方法在完成的时候返回指定的result 对象。 Future&lt;?> submit(Runnable task); //调用isDone、cancel 或isCancelled。但是， get 方法在完成的时候只是简单地返回null。 使用过程： 当用完一个线程池的时候， 调用shutdown。该方法启动该池的关闭序列。被关闭的执行器不再接受新的任务。当所有任务都完成以后，线程池中的线程死亡。另一种方法是调用shutdownNow。该池取消尚未开始的所有任务并试图中断正在运行的线程。 流程： 调用Executors类中静态的方法newCachedThreadPool或newFixedThreadPool。 调用submit提交Runnable 或Callable对象。 调用involve等方法执行任务 如果想要取消一个任务， 或如果提交Callable 对象， 那就要保存好返回的Future对象。 当不再提交任何任务时，调用shutdown。 package ThreadPoolTest; import java.io.File; import java.io.IOException; import java.util.ArrayList; import java.util.List; import java.util.Scanner; import java.util.concurrent.*; public class ThreadPoolTest { public static void main(String[] args) { try (Scanner in=new Scanner(System.in)) { System.out.print("Enter base directory (e.g. /usr/local/jdk1.6.0/src): "); String directory = in.nextLine(); System.out.print("Enter keyword (e.g. volatile): "); String keyWord = in.nextLine(); //创建线程池对象 ExecutorService pool= Executors.newCachedThreadPool();//线程池对象 //操作流 MatchCounter counter=new MatchCounter(new File(directory),keyWord,pool); Future&lt;Integer> result=pool.submit(counter); try { System.out.println(result.get()+" matching files"); }catch (ExecutionException e){ e.printStackTrace(); }catch (InterruptedException e){ } pool.shutdown(); int largestPoolSize = ((ThreadPoolExecutor) pool).getLargestPoolSize(); System.out.println("largest pool size="+ largestPoolSize); } } } //实现Callable接口 call方法有返回值 class MatchCounter implements Callable&lt;Integer> { private File directory; private String keyWord; private ExecutorService pool; private int count; public MatchCounter(File directory, String keyWord, ExecutorService pool) { this.directory = directory; this.keyWord = keyWord; this.pool = pool; } @Override public Integer call() throws Exception { count=0; try { File[] files=directory.listFiles(); List&lt;Future&lt;Integer>> results=new ArrayList&lt;>(); for (File file : files) { if(file.isDirectory()){ MatchCounter counter=new MatchCounter(file,keyWord,pool); Future&lt;Integer> result=pool.submit(counter); results.add(result); }else { if(search(file))//查询的内容加加 count++; } for (Future&lt;Integer> result:results){//总共文件内的加加 try{ count+=result.get(); }catch (ExecutionException e){ e.printStackTrace(); } } } }catch (InterruptedException e){ e.printStackTrace(); } return count; } public boolean search(File file){ try{ try(Scanner in=new Scanner(file,"UTF-8")){ boolean found=false; while (!found&amp;&amp;in.hasNextLine()){ String line=in.nextLine(); if (line.contains(keyWord)) found=true; } return found; } }catch (IOException e){ return false; } } } 预定执行​ ScheduledExecutorService 接口具有为预定执行（ Scheduled Execution ) 或重复执行任务而设计的方法。它是一种允许使用线程池机制的java.util.Timer的泛化。Executors 类的newScheduledThreadPool和newSingleThreadScheduledExecutor方法将返回实现了ScheduledExecutorService 接口的对象。 ​ 可以预定Runnable 或Callable在初始的延迟之后只运行一次。也可以预定一个Runnable对象周期性地运行 控制任务组T invokeAny( Co11ection&lt;Cal 1able&lt;T>> tasks ) T invokeAny(Col 1ection&lt;Cal 1able&lt;T>> tasks , long timeout , TimeUnit unit ) //执行给定的任务， 返回其中一个任务的结果。第二个方法若发生超时， 抛出一个Timeout Exception 异常。 List&lt;Future&lt;T>> invokeAll (Col 1ection&lt;Cal 1 able&lt;T> > tasks ) List&lt;Future&lt;T>> invokeAll( Col 1 ection&lt;Cal 1 abl e&lt;T > > tasks , long timeout , TimeUnit unit ) //执行给定的任务， 返回所有任务的结果。第二个方法若发生超时， 拋出一个TimecmtException 异常。 ExecutorCompletionService(Executor e ) //构建一个执行器完成服务来收集给定执行器的结果。 Future&lt; V> submit(Cal 1 able&lt; V > task ) Future&lt; V > submit( Runnable task , V result ) //提交一个任务给底层的执行器。 Future&lt; V > take( ) //移除下一个已完成的结果， 如果没有任何已完成的结果可用则阻塞。 Future&lt; V > poll( ) Future&lt; V > poll( 1 ong time , TimeUnit unit ) //移除下一个已完成的结果， 如果没有任何已完成结果可用则返回null。第二个方法将等待给定的时间。 Fork-Join框架将一个大任务分为多个任务，分别执行。提高效率 可完成Future不懂 同步器管理线程 信号量倒计时门栓CountDownLatch一个倒计时门栓（ CountDownLatch) 让一个线程集等待直到计数变为0。倒计时门栓是一次性的。一旦计数为0, 就不能再重用了。 就是赛跑时，预备起跑。口令到了，大家才能跑 障栅CyclicBarrier​ 考虑大量线程运行在一次计算的不同部分的情形。当所有部分都准备好时，需要把结果组合在一起。当一个线程完成了它的那部分任务后， 我们让它运行到障栅处。一旦所有的线程都到达了这个障栅，障栅就撤销， 线程就可以继续运行。 交换器Exchanger​ 当两个线程在同一个数据缓冲区的两个实例上工作的时候， 就可以使用交换器( Exchanger) 典型的情况是， 一个线程向缓冲区填人数据， 另一个线程消耗这些数据。当它们都完成以后，相互交换缓冲区。 同步队列SynchronousQueue​ 同步队列是一种将生产者与消费者线程配对的机制。当一个线程调用SynchronousQueue的put 方法时， 它会阻塞直到另一个线程调用take 方法为止， 反之亦然。与Exchanger 的情况不同， 数据仅仅沿一个方向传递，从生产者到消费者。​ 即使SynchronousQueue 类实现了BlockingQueue 接口， 概念上讲， 它依然不是一个队列。它没有包含任何元素，它的size 方法总是返回0。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>java核心卷1</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis基类生成]]></title>
    <url>%2F2019%2F03%2F21%2Fmybatis-ji-lei-sheng-cheng%2F</url>
    <content type="text"><![CDATA[Mybatis基类生成，减少开发代码量 这里只是记录个人总结，详细请移步这里 今天跟着视频写淘淘商城的时候，发现有部分基类Mapper 基类Service 没有视频讲解，网上查了一下，有些了解，还需深入理解 BaseMapper import java.util.List; import org.apache.ibatis.annotations.Param; public interface BaseMapper&lt;T,Example,ID> { /** * 条件查询数量 * @param example * @return */ int countByExample(Example example); /** * 条件删除 * @param example * @return */ int deleteByExample(Example example); /** * 主键删除 * @param id * @return */ int deleteByPrimaryKey(ID id); /** * insert selectiveinsert区别 * selective 选择性 * selectiveInsert选择性保留数据 * insertSelective执行时只插入对应设置的字段，（主键是自动添加，默认为空） * insert 不管你设置多少字段，全部插入个便 */ /** * 插入 * @param record * @return */ int insert(T record); /** * 插入 * @param record * @return */ int insertSelective(T record); /** * 条件查询数据 * @param example * @return */ List&lt;T> selectByExample(Example example); /** * 依靠逐渐查询 * @param id * @return */ T selectByPrimaryKey(ID id); /** * 条件修改 设置多少字段，修改多少字段 * @param record * @param example * @return */ int updateByExampleSelective(@Param("record") T record, @Param("example") Example example); /** * 同上，全部修改 * @param record * @param example * @return */ int updateByExample(@Param("record") T record, @Param("example") Example example); /** * 依靠主键修改 * @param record * @return */ int updateByPrimaryKeySelective(T record); /** * 依靠主键修改 * @param record * @return */ int updateByPrimaryKey(T record); } 知识点： 泛型是可以多种的，只要表示不同即可 insert 和selectiveInsert区别 两者的区别在于如果选择insert 那么所有的字段都会添加一遍即使没有值 但是如果使用inserSelective就会只给有值的字段赋值（会对传进来的值做非空判断） BaseExample 这里可以添加扩展功能，比如排序、分页等。。。 /** * 基类 * 修改扩展功能 * @author liwei * */ public abstract class BaseExample { //protected PageInfo pageInfo; } BaseService 命名规则和BaseMapper一致 import java.util.List; import com.taotao.pojo.BaseExample; import org.apache.ibatis.annotations.Param; public interface BaseService&lt;T, Example extends BaseExample, ID> { /** * 条件查询数量 * @param example * @return */ int countByExample(Example example); /** * 条件删除 * @param example * @return */ int deleteByExample(Example example); /** * 主键删除 * @param id * @return */ int deleteByPrimaryKey(ID id); /** * insert selectiveinsert区别 * selective 选择性 * selectiveInsert选择性保留数据 * insertSelective执行时只插入对应设置的字段，（主键是自动添加，默认为空） * insert 不管你设置多少字段，全部插入个便 */ /** * 插入 * @param record * @return */ int insert(T record); /** * 插入 * @param record * @return */ int insertSelective(T record); /** * 条件查询数据 * @param example * @return */ List&lt;T> selectByExample(Example example); /** * 依靠逐渐查询 * @param id * @return */ T selectByPrimaryKey(ID id); /** * 条件修改 设置多少字段，修改多少字段 * @param record * @param example * @return */ int updateByExampleSelective(@Param("record") T record, @Param("example") Example example); /** * 同上，全部修改 * @param record * @param example * @return */ int updateByExample(@Param("record") T record, @Param("example") Example example); /** * 依靠主键修改 * @param record * @return */ int updateByPrimaryKeySelective(T record); /** * 依靠主键修改 * @param record * @return */ int updateByPrimaryKey(T record); } BaseServiceImpl import java.util.List; import com.taotao.mapper.BaseMapper; import com.taotao.pojo.BaseExample; import com.taotao.service.BaseService; public class BaseServiceImpl&lt;T, Example extends BaseExample,ID> implements BaseService&lt;T, Example, ID> { private BaseMapper&lt;T,Example,ID> mapper; /** * 为什么不用注入的方式？ * @param mapper */ public void setMapper(BaseMapper&lt;T, Example, ID> mapper) { this.mapper = mapper; } @Override public int countByExample(Example example) { return mapper.countByExample(example); } @Override public int deleteByExample(Example example) { return mapper.deleteByExample(example); } @Override public int deleteByPrimaryKey(ID id) { return mapper.deleteByPrimaryKey(id); } @Override public int insert(T record) { return mapper.insert(record); } @Override public int insertSelective(T record) { return mapper.insertSelective(record); } @Override public List&lt;T> selectByExample(Example example) { return mapper.selectByExample(example); } @Override public T selectByPrimaryKey(ID id) { return mapper.selectByPrimaryKey(id); } @Override public int updateByExampleSelective(T record, Example example) { return mapper.updateByExampleSelective(record, example); } @Override public int updateByExample(T record, Example example) { return mapper.updateByExample(record, example); } @Override public int updateByPrimaryKeySelective(T record) { return mapper.updateByPrimaryKeySelective(record); } @Override public int updateByPrimaryKey(T record) { return mapper.updateByPrimaryKey(record); } } 后面的对官方的generator扩展部分不懂，先摘下来 ​ 现在,可以开始对官方generator进行扩展,并对对应的mapper.xml进行相应变动.生成期望中的代码. generator本身预留了插件扩展功能.所以主要通过继承PluginAdapter来完成我们想要的东西.​ 另外,generator本身的生成注释不是很符合我们的习惯.我们期望的是,可通过db表和字段信息来生成对应的注释,在这里进行扩展生成我们想要的注释信息. CommentGenerator 不包含实体类的注释描述生成. /** * Comment Generator * @ClassName CommentGenerator * @Description * @author Marvis */ public class CommentGenerator extends DefaultCommentGenerator { private Properties properties; private boolean suppressDate; private boolean suppressAllComments; public CommentGenerator() { this.properties = new Properties(); this.suppressDate = false; this.suppressAllComments = false; } public void addJavaFileComment(CompilationUnit compilationUnit) { compilationUnit.addFileCommentLine("/*** copyright (c) 2017 Marvis ***/"); } /** * XML file Comment */ public void addComment(XmlElement xmlElement) { if (this.suppressAllComments) { return; } } public void addRootComment(XmlElement rootElement) { } public void addConfigurationProperties(Properties properties) { this.properties.putAll(properties); this.suppressDate = StringUtility.isTrue(properties.getProperty("suppressDate")); this.suppressAllComments = StringUtility.isTrue(properties.getProperty("suppressAllComments")); } protected void addJavadocTag(JavaElement javaElement, boolean markAsDoNotDelete) { StringBuilder sb = new StringBuilder(); sb.append(" * "); sb.append("@date"); // if (markAsDoNotDelete) { // sb.append(" do_not_delete_during_merge"); // } String s = getDateString(); if (s != null) { sb.append(' '); sb.append(s); } javaElement.addJavaDocLine(sb.toString()); } protected String getDateString() { if (this.suppressDate) { return null; } return new Date().toString(); } /** * Comment of Example inner class(GeneratedCriteria ,Criterion) */ public void addClassComment(InnerClass innerClass, IntrospectedTable introspectedTable) { if (this.suppressAllComments) { return; } innerClass.addJavaDocLine("/**"); innerClass.addJavaDocLine(" * " + introspectedTable.getFullyQualifiedTable().getDomainObjectName()+ "&lt;p/>"); innerClass.addJavaDocLine(" * " + introspectedTable.getFullyQualifiedTable().toString()); addJavadocTag(innerClass, false); innerClass.addJavaDocLine(" */"); } public void addEnumComment(InnerEnum innerEnum, IntrospectedTable introspectedTable) { if (this.suppressAllComments) { return; } StringBuilder sb = new StringBuilder(); innerEnum.addJavaDocLine("/**"); innerEnum.addJavaDocLine(" * " + introspectedTable.getFullyQualifiedTable().getAlias()+ "&lt;p/>"); innerEnum.addJavaDocLine(" * " + introspectedTable.getFullyQualifiedTable()); innerEnum.addJavaDocLine(sb.toString()); addJavadocTag(innerEnum, false); innerEnum.addJavaDocLine(" */"); } /** * entity filed Comment */ public void addFieldComment(Field field, IntrospectedTable introspectedTable, IntrospectedColumn introspectedColumn) { if (this.suppressAllComments) { return; } // if(introspectedColumn.getRemarks() != null &amp;&amp; !introspectedColumn.getRemarks().trim().equals("")) field.addJavaDocLine("/**"); field.addJavaDocLine(" * " + introspectedColumn.getRemarks()); field.addJavaDocLine(" * @author Marvis" ); field.addJavaDocLine(" * @date " + getDateString() ); field.addJavaDocLine(" * @return"); field.addJavaDocLine(" */"); } /** * Comment of EXample filed */ public void addFieldComment(Field field, IntrospectedTable introspectedTable) { if (this.suppressAllComments) { return; } field.addJavaDocLine("/**"); addJavadocTag(field, false); field.addJavaDocLine(" */"); } /** * Comment of Example method */ public void addGeneralMethodComment(Method method, IntrospectedTable introspectedTable) { if (this.suppressAllComments) { return; } // method.addJavaDocLine("/**"); // addJavadocTag(method, false); // method.addJavaDocLine(" */"); } /** * * entity Getter Comment */ public void addGetterComment(Method method, IntrospectedTable introspectedTable, IntrospectedColumn introspectedColumn) { if (this.suppressAllComments) { return; } method.addJavaDocLine("/**"); method.addJavaDocLine(" * @return " + introspectedTable.getFullyQualifiedTable().getAlias() + " : " + introspectedColumn.getRemarks()); // addJavadocTag(method, false); method.addJavaDocLine(" */"); } public void addSetterComment(Method method, IntrospectedTable introspectedTable, IntrospectedColumn introspectedColumn) { if (this.suppressAllComments) { return; } StringBuilder sb = new StringBuilder(); method.addJavaDocLine("/**"); Parameter parm = (Parameter) method.getParameters().get(0); sb.append(" * @param "); sb.append(parm.getName()); sb.append(" : "); sb.append(introspectedColumn.getRemarks()); method.addJavaDocLine(sb.toString()); // addJavadocTag(method, false); method.addJavaDocLine(" */"); } /** * Comment of Example inner class(Criteria) */ public void addClassComment(InnerClass innerClass, IntrospectedTable introspectedTable, boolean markAsDoNotDelete) { if (this.suppressAllComments) { return; } innerClass.addJavaDocLine("/**"); innerClass.addJavaDocLine(" * " + introspectedTable.getFullyQualifiedTable().getAlias()+ "&lt;p/>"); innerClass.addJavaDocLine(" * " + introspectedTable.getFullyQualifiedTable().toString()); addJavadocTag(innerClass, markAsDoNotDelete); innerClass.addJavaDocLine(" */"); } } EntityCommentPlugin public class EntityCommentPlugin extends PluginAdapter { @Override public boolean modelBaseRecordClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { addModelClassComment(topLevelClass, introspectedTable); return super.modelBaseRecordClassGenerated(topLevelClass, introspectedTable); } @Override public boolean modelRecordWithBLOBsClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { addModelClassComment(topLevelClass, introspectedTable); return super.modelRecordWithBLOBsClassGenerated(topLevelClass, introspectedTable); } protected void addModelClassComment(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { FullyQualifiedTable table = introspectedTable.getFullyQualifiedTable(); String tableComment = getTableComment(table); topLevelClass.addJavaDocLine("/**"); if(StringUtility.stringHasValue(tableComment)) topLevelClass.addJavaDocLine(" * " + tableComment + "&lt;p/>"); topLevelClass.addJavaDocLine(" * " + table.toString() + "&lt;p/>"); topLevelClass.addJavaDocLine(" * @date " + new Date().toString()); topLevelClass.addJavaDocLine(" *"); topLevelClass.addJavaDocLine(" */"); } /** * @author Marvis * @date Jul 13, 2017 4:39:52 PM * @param table */ private String getTableComment(FullyQualifiedTable table) { String tableComment = ""; Connection connection = null; Statement statement = null; ResultSet rs = null; try { connection = ConnectionFactory.getInstance().getConnection(context.getJdbcConnectionConfiguration()); statement = connection.createStatement(); rs = statement.executeQuery("SHOW CREATE TABLE " + table.getIntrospectedTableName()); if (rs != null &amp;&amp; rs.next()) { String createDDL = rs.getString(2); int index = createDDL.indexOf("COMMENT='"); if (index &lt; 0) { tableComment = ""; } else { tableComment = createDDL.substring(index + 9); tableComment = tableComment.substring(0, tableComment.length() - 1); } } } catch (SQLException e) { } finally { closeConnection(connection, statement, rs); } return tableComment; } /** * * @author Marvis * @date Jul 13, 2017 4:45:26 PM * @param connection * @param statement * @param rs */ private void closeConnection(Connection connection, Statement statement, ResultSet rs) { try { if (null != rs) rs.close(); } catch (SQLException e) { e.printStackTrace(); } finally { try { if (statement != null) statement.close(); } catch (Exception e) { e.printStackTrace(); } finally { try { if (connection != null) connection.close(); } catch (SQLException e) { e.printStackTrace(); } } } } /** * This plugin is always valid - no properties are required */ @Override public boolean validate(List&lt;String> warnings) { return true; } } } ClientDaoPlugin /** * javaClient("XMLMAPPER") extended * @ClassName ClientDaoPlugin * @Description * @author Marvis */ public class ClientDaoPlugin extends EntityCommentPlugin { @Override public boolean clientGenerated(Interface interfaze, TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { JavaTypeResolver javaTypeResolver = new JavaTypeResolverDefaultImpl(); FullyQualifiedJavaType calculateJavaType = javaTypeResolver.calculateJavaType(introspectedTable.getPrimaryKeyColumns().get(0)); FullyQualifiedJavaType superInterfaceType = new FullyQualifiedJavaType("BaseMapper&lt;" + introspectedTable.getBaseRecordType() + "," + introspectedTable.getExampleType() + "," + calculateJavaType.getShortName()+ ">"); FullyQualifiedJavaType baseMapperInstance = FullyQualifiedJavaTypeProxyFactory.getBaseMapperInstance(); interfaze.addSuperInterface(superInterfaceType); interfaze.addImportedType(baseMapperInstance); // interfaze.getAnnotations().clear(); List&lt;Method> methods = interfaze.getMethods(); List&lt;Method> changeMethods = new ArrayList&lt;Method>(); for (Method method : methods) { if(method.getName().endsWith("BLOBs")) changeMethods.add(method); } interfaze.getMethods().clear(); for (Method changeMethod : changeMethods) { interfaze.addMethod(changeMethod); } return super.clientGenerated(interfaze, topLevelClass, introspectedTable); } } PaginationPlugin public class PaginationPlugin extends ClientDaoPlugin { @Override public boolean modelExampleClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { // add field, getter, setter for limit clause // addLimit(topLevelClass, introspectedTable, "pageInfo"); // addLimitString(topLevelClass, introspectedTable, "groupByClause"); // topLevelClass.addImportedType(FullyQualifiedJavaTypeProxy.getPageInfoInstanceInstance()); FullyQualifiedJavaType baseExampleType = FullyQualifiedJavaTypeProxyFactory.getBaseExampleInstance(); topLevelClass.setSuperClass(baseExampleType); topLevelClass.addImportedType(baseExampleType); return super.modelExampleClassGenerated(topLevelClass, introspectedTable); } @Override public boolean sqlMapSelectByExampleWithBLOBsElementGenerated(XmlElement element, IntrospectedTable introspectedTable) { XmlElement isNotNullElement1 = new XmlElement("if"); isNotNullElement1.addAttribute(new Attribute("test", "groupByClause != null")); isNotNullElement1.addElement(new TextElement("group by ${groupByClause}")); element.addElement(5, isNotNullElement1); XmlElement isNotNullElement = new XmlElement("if"); isNotNullElement.addAttribute(new Attribute("test", "pageInfo != null")); isNotNullElement.addElement(new TextElement("limit #{pageInfo.pageBegin} , #{pageInfo.pageSize}")); element.addElement(isNotNullElement); return super.sqlMapUpdateByExampleWithBLOBsElementGenerated(element, introspectedTable); } @Override public boolean sqlMapSelectByExampleWithoutBLOBsElementGenerated(XmlElement element, IntrospectedTable introspectedTable) { // XmlElement isParameterPresenteElemen = (XmlElement) element // .getElements().get(element.getElements().size() - 1); XmlElement isNotNullElement1 = new XmlElement("if"); isNotNullElement1.addAttribute(new Attribute("test", "groupByClause != null")); // isNotNullElement.addAttribute(new Attribute("compareValue", "0")); isNotNullElement1.addElement(new TextElement("group by ${groupByClause}")); // isParameterPresenteElemen.addElement(isNotNullElement); element.addElement(5, isNotNullElement1); // XmlElement isParameterPresenteElemen = (XmlElement) element // .getElements().get(element.getElements().size() - 1); XmlElement isNotNullElement = new XmlElement("if"); isNotNullElement.addAttribute(new Attribute("test", "pageInfo != null")); // isNotNullElement.addAttribute(new Attribute("compareValue", "0")); isNotNullElement.addElement(new TextElement("limit #{pageInfo.pageBegin} , #{pageInfo.pageSize}")); // isParameterPresenteElemen.addElement(isNotNullElement); element.addElement(isNotNullElement); return super.sqlMapUpdateByExampleWithoutBLOBsElementGenerated(element, introspectedTable); } @Override public boolean sqlMapCountByExampleElementGenerated(XmlElement element, IntrospectedTable introspectedTable) { XmlElement answer = new XmlElement("select"); String fqjt = introspectedTable.getExampleType(); answer.addAttribute(new Attribute("id", introspectedTable.getCountByExampleStatementId())); answer.addAttribute(new Attribute("parameterType", fqjt)); answer.addAttribute(new Attribute("resultType", "java.lang.Integer")); this.context.getCommentGenerator().addComment(answer); StringBuilder sb = new StringBuilder(); sb.append("select count(1) from "); sb.append(introspectedTable.getAliasedFullyQualifiedTableNameAtRuntime()); XmlElement ifElement = new XmlElement("if"); ifElement.addAttribute(new Attribute("test", "_parameter != null")); XmlElement includeElement = new XmlElement("include"); includeElement.addAttribute(new Attribute("refid", introspectedTable.getExampleWhereClauseId())); ifElement.addElement(includeElement); element.getElements().clear(); element.getElements().add(new TextElement(sb.toString())); element.getElements().add(ifElement); return super.sqlMapUpdateByExampleWithoutBLOBsElementGenerated(element, introspectedTable); } @SuppressWarnings("unused") private void addLimit(TopLevelClass topLevelClass, IntrospectedTable introspectedTable, String name) { CommentGenerator commentGenerator = context.getCommentGenerator(); FullyQualifiedJavaType pageInfoInstance = FullyQualifiedJavaTypeProxyFactory.getPageInfoInstanceInstance(); // Field field = new Field(); // field.setVisibility(JavaVisibility.PROTECTED); // field.setType(FullyQualifiedJavaType.getIntInstance()); // PrimitiveTypeWrapper integerInstance = // PrimitiveTypeWrapper.getIntegerInstance(); // field.setType(pageInfoInstance); // field.setName(name); // // field.setInitializationString("-1"); // commentGenerator.addFieldComment(field, introspectedTable); // topLevelClass.addField(field); char c = name.charAt(0); String camel = Character.toUpperCase(c) + name.substring(1); Method method = new Method(); method.setVisibility(JavaVisibility.PUBLIC); method.setName("set" + camel); method.addParameter(new Parameter(pageInfoInstance, name)); method.addBodyLine("this." + name + "=" + name + ";"); commentGenerator.addGeneralMethodComment(method, introspectedTable); topLevelClass.addMethod(method); method = new Method(); method.setVisibility(JavaVisibility.PUBLIC); method.setReturnType(pageInfoInstance); method.setName("get" + camel); method.addBodyLine("return " + name + ";"); commentGenerator.addGeneralMethodComment(method, introspectedTable); topLevelClass.addMethod(method); } @SuppressWarnings("unused") private void addLimitString(TopLevelClass topLevelClass, IntrospectedTable introspectedTable, String name) { CommentGenerator commentGenerator = context.getCommentGenerator(); FullyQualifiedJavaType stringInstance = FullyQualifiedJavaType.getStringInstance(); // Field field = new Field(); // field.setVisibility(JavaVisibility.PROTECTED); // field.setType(FullyQualifiedJavaType.getIntInstance()); // PrimitiveTypeWrapper integerInstance = // PrimitiveTypeWrapper.getIntegerInstance(); // field.setType(stringInstance); // field.setName(name); // // field.setInitializationString("-1"); // commentGenerator.addFieldComment(field, introspectedTable); // topLevelClass.addField(field); char c = name.charAt(0); String camel = Character.toUpperCase(c) + name.substring(1); Method method = new Method(); method.setVisibility(JavaVisibility.PUBLIC); method.setName("set" + camel); method.addParameter(new Parameter(stringInstance, name)); method.addBodyLine("this." + name + "=" + name + ";"); commentGenerator.addGeneralMethodComment(method, introspectedTable); topLevelClass.addMethod(method); method = new Method(); method.setVisibility(JavaVisibility.PUBLIC); method.setReturnType(stringInstance); method.setName("get" + camel); method.addBodyLine("return " + name + ";"); commentGenerator.addGeneralMethodComment(method, introspectedTable); topLevelClass.addMethod(method); introspectedTable.getFullyQualifiedTable(); } } SerializablePlugin: public class SerializablePlugin extends PluginAdapter { private FullyQualifiedJavaType serializable; private FullyQualifiedJavaType gwtSerializable; private boolean addGWTInterface; private boolean suppressJavaInterface; public SerializablePlugin() { this.serializable = new FullyQualifiedJavaType("java.io.Serializable"); this.gwtSerializable = new FullyQualifiedJavaType("com.google.gwt.user.client.rpc.IsSerializable"); } public boolean validate(List&lt;String> warnings) { return true; } public void setProperties(Properties properties) { super.setProperties(properties); this.addGWTInterface = Boolean.valueOf(properties.getProperty("addGWTInterface")).booleanValue(); this.suppressJavaInterface = Boolean.valueOf(properties.getProperty("suppressJavaInterface")).booleanValue(); } public boolean modelBaseRecordClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { makeSerializable(topLevelClass, introspectedTable); return true; } public boolean modelPrimaryKeyClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { makeSerializable(topLevelClass, introspectedTable); return true; } public boolean modelRecordWithBLOBsClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { makeSerializable(topLevelClass, introspectedTable); return true; } protected void makeSerializable(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) { if (this.addGWTInterface) { topLevelClass.addImportedType(this.gwtSerializable); topLevelClass.addSuperInterface(this.gwtSerializable); } if (!(this.suppressJavaInterface)) { topLevelClass.addImportedType(this.serializable); topLevelClass.addSuperInterface(this.serializable); topLevelClass.addAnnotation("@SuppressWarnings(\"serial\")"); } } } FullyQualifiedJavaTypeProxyFactory: public class FullyQualifiedJavaTypeProxyFactory extends FullyQualifiedJavaType{ private static FullyQualifiedJavaType pageInfoInstance = null; private static FullyQualifiedJavaType baseExampleInstance = null; private static FullyQualifiedJavaType baseMapperInstance = null; private static FullyQualifiedJavaType baseServiceInstance = null; private static FullyQualifiedJavaType baseServiceImplInstance = null; public FullyQualifiedJavaTypeProxyFactory(String fullTypeSpecification) { super(fullTypeSpecification); } public static final FullyQualifiedJavaType getPageInfoInstanceInstance() { if (pageInfoInstance == null) { pageInfoInstance = new FullyQualifiedJavaType("cn.xxx.core.base.model.PageInfo"); } return pageInfoInstance; } public static final FullyQualifiedJavaType getBaseExampleInstance() { if (baseExampleInstance == null) { baseExampleInstance = new FullyQualifiedJavaType("cn.xxx.core.base.model.BaseExample"); } return baseExampleInstance; } public static final FullyQualifiedJavaType getBaseMapperInstance() { if (baseMapperInstance == null) { baseMapperInstance = new FullyQualifiedJavaType("cn.xxx.core.base.dao.BaseMapper"); } return baseMapperInstance; } public static final FullyQualifiedJavaType getBaseServiceInstance() { if (baseServiceInstance == null) { baseServiceInstance = new FullyQualifiedJavaType("cn.xxx.core.base.service.BaseService"); } return baseServiceInstance; } public static final FullyQualifiedJavaType getBaseServiceImplInstance() { if (baseServiceImplInstance == null) { baseServiceImplInstance = new FullyQualifiedJavaType("cn.xxx.core.base.service.impl.BaseServiceImpl"); } return baseServiceImplInstance; } } generatorConfig.xml &lt;?xml version="1.0" encoding="UTF-8"?> &lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"> &lt;generatorConfiguration> &lt;context id="ables" targetRuntime="MyBatis3"> &lt;plugin type="run.override.ServiceHierarchyPlugin" /> &lt;plugin type="run.override.PaginationPlugin" /> &lt;plugin type="run.override.SerializablePlugin" /> &lt;plugin type="org.mybatis.generator.plugins.ToStringPlugin" /> &lt;commentGenerator type="run.override.CommentGenerator"> &lt;property name="suppressAllComments" value="false" /> &lt;property name="suppressDate" value="false" /> &lt;/commentGenerator> &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://xx.xx.xx.xx:3306/crowdsourcing?characterEncoding=utf8" userId="xxx" password="xxx"> &lt;/jdbcConnection> &lt;javaTypeResolver> &lt;property name="forceBigDecimals" value="false" /> &lt;/javaTypeResolver> &lt;javaModelGenerator targetPackage="cn.xxx.xxx.task.module.model" targetProject=".\src"> &lt;property name="enableSubPackages" value="false" /> &lt;property name="trimStrings" value="true" /> &lt;/javaModelGenerator> &lt;sqlMapGenerator targetPackage="mapper.cn.xxx.xxx.task.module.dao" targetProject=".\src"> &lt;property name="enableSubPackages" value="false" /> &lt;/sqlMapGenerator> &lt;javaClientGenerator type="XMLMAPPER" targetPackage="cn.xxx.xxx.task.module.dao" targetProject=".\src"> &lt;property name="enableSubPackages" value="false" /> &lt;/javaClientGenerator> &lt;!-- 指定数据库表 --> &lt;!-- tableName:用于自动生成代码的数据库表；domainObjectName:对应于数据库表的javaBean类名 --> &lt;table tableName="a_task_quest_sub" domainObjectName="TaskQuestSub" alias="taskQuestSub"> &lt;generatedKey column="id" sqlStatement="MySql" identity="true" /> &lt;/table> &lt;/context> &lt;/generatorConfiguration> service层代码生成 ServiceHierarchyPlugin public class ServiceHierarchyPlugin extends PluginAdapter { @Override public List&lt;GeneratedJavaFile> contextGenerateAdditionalJavaFiles(IntrospectedTable introspectedTable) { CompilationUnit addServiceInterface = addServiceInterface(introspectedTable); CompilationUnit addServiceImplClazz = addServiceImplClazz(introspectedTable); JavaModelGeneratorConfiguration javaModelGeneratorConfiguration = this.context.getJavaModelGeneratorConfiguration(); String targetProject = javaModelGeneratorConfiguration.getTargetProject(); GeneratedJavaFile gjfServiceInterface = new GeneratedJavaFile(addServiceInterface, targetProject, this.context.getProperty("javaFileEncoding"), this.context.getJavaFormatter()); GeneratedJavaFile gjfServiceImplClazz = new GeneratedJavaFile(addServiceImplClazz, targetProject, this.context.getProperty("javaFileEncoding"), this.context.getJavaFormatter()); List&lt;GeneratedJavaFile> list= new ArrayList&lt;>(); list.add(gjfServiceInterface); list.add(gjfServiceImplClazz); return list; } protected CompilationUnit addServiceInterface(IntrospectedTable introspectedTable) { String entityClazzName = introspectedTable.getBaseRecordType(); String javaModelTargetPackage = entityClazzName.substring(0,entityClazzName.lastIndexOf(".")); String serviceSuperPackageName = javaModelTargetPackage.substring(0, javaModelTargetPackage.lastIndexOf(".")); String entityExampleClazzName = introspectedTable.getExampleType(); String domainObjectName = introspectedTable.getFullyQualifiedTable().getDomainObjectName(); JavaTypeResolver javaTypeResolver = new JavaTypeResolverDefaultImpl(); FullyQualifiedJavaType calculateJavaType = javaTypeResolver .calculateJavaType(introspectedTable.getPrimaryKeyColumns().get(0)); FullyQualifiedJavaType superInterfaceType = new FullyQualifiedJavaType( "BaseService&lt;" + entityClazzName + "," + entityExampleClazzName + "," + calculateJavaType.getShortName() + ">"); Interface serviceInterface = new Interface(serviceSuperPackageName + ".service." + domainObjectName + "Service"); serviceInterface.addSuperInterface(superInterfaceType); serviceInterface.setVisibility(JavaVisibility.PUBLIC); FullyQualifiedJavaType baseServiceInstance = FullyQualifiedJavaTypeProxyFactory.getBaseServiceInstance(); FullyQualifiedJavaType modelJavaType = new FullyQualifiedJavaType(entityClazzName); FullyQualifiedJavaType exampleJavaType = new FullyQualifiedJavaType(entityExampleClazzName); serviceInterface.addImportedType(baseServiceInstance); serviceInterface.addImportedType(modelJavaType); serviceInterface.addImportedType(exampleJavaType); return serviceInterface; } protected CompilationUnit addServiceImplClazz(IntrospectedTable introspectedTable) { String entityClazzName = introspectedTable.getBaseRecordType(); String javaModelTargetPackage = entityClazzName.substring(0,entityClazzName.lastIndexOf(".")); String serviceSuperPackageName = javaModelTargetPackage.substring(0, javaModelTargetPackage.lastIndexOf(".")); String entityExampleClazzName = introspectedTable.getExampleType(); String JavaMapperTypeName = introspectedTable.getMyBatis3JavaMapperType(); String domainObjectName = introspectedTable.getFullyQualifiedTable().getDomainObjectName(); JavaTypeResolver javaTypeResolver = new JavaTypeResolverDefaultImpl(); FullyQualifiedJavaType calculateJavaType = javaTypeResolver .calculateJavaType(introspectedTable.getPrimaryKeyColumns().get(0)); FullyQualifiedJavaType superClazzType = new FullyQualifiedJavaType( "BaseServiceImpl&lt;" + introspectedTable.getBaseRecordType() + "," + introspectedTable.getExampleType() + "," + calculateJavaType.getShortName() + ">"); FullyQualifiedJavaType implInterfaceType = new FullyQualifiedJavaType(serviceSuperPackageName + ".service." + domainObjectName + "Service"); TopLevelClass serviceImplClazz = new TopLevelClass(serviceSuperPackageName + ".service.impl." + domainObjectName + "ServiceImpl"); serviceImplClazz.addSuperInterface(implInterfaceType); serviceImplClazz.setSuperClass(superClazzType); serviceImplClazz.setVisibility(JavaVisibility.PUBLIC); serviceImplClazz.addAnnotation("@Service"); FullyQualifiedJavaType baseServiceInstance = FullyQualifiedJavaTypeProxyFactory.getBaseServiceImplInstance(); FullyQualifiedJavaType modelJavaType = new FullyQualifiedJavaType(entityClazzName); FullyQualifiedJavaType exampleJavaType = new FullyQualifiedJavaType(entityExampleClazzName); serviceImplClazz.addImportedType(new FullyQualifiedJavaType("org.springframework.beans.factory.annotation.Autowired")); serviceImplClazz.addImportedType(new FullyQualifiedJavaType("org.springframework.stereotype.Service")); serviceImplClazz.addImportedType(baseServiceInstance); serviceImplClazz.addImportedType(modelJavaType); serviceImplClazz.addImportedType(exampleJavaType); serviceImplClazz.addImportedType(implInterfaceType); FullyQualifiedJavaType logType = new FullyQualifiedJavaType("org.apache.commons.logging.Log"); FullyQualifiedJavaType logFactoryType = new FullyQualifiedJavaType("org.apache.commons.logging.LogFactory"); Field logField = new Field(); logField.setVisibility(JavaVisibility.PRIVATE); logField.setStatic(true); logField.setFinal(true); logField.setType(logType); logField.setName("log"); logField.setInitializationString("LogFactory.getLog("+ entityClazzName.substring(entityClazzName.lastIndexOf(".") + 1) + "ServiceImpl.class)"); logField.addAnnotation(""); logField.addAnnotation("@SuppressWarnings(\"unused\")"); serviceImplClazz.addField(logField); serviceImplClazz.addImportedType(logType); serviceImplClazz.addImportedType(logFactoryType); String mapperName = Character.toLowerCase(domainObjectName.charAt(0)) + domainObjectName.substring(1) + "Mapper"; FullyQualifiedJavaType JavaMapperType = new FullyQualifiedJavaType(JavaMapperTypeName); Field mapperField = new Field(); mapperField.setVisibility(JavaVisibility.PUBLIC); mapperField.setType(JavaMapperType);//Mapper.java mapperField.setName(mapperName); mapperField.addAnnotation("@Autowired"); serviceImplClazz.addField(mapperField); serviceImplClazz.addImportedType(JavaMapperType); Method mapperMethod = new Method(); mapperMethod.setVisibility(JavaVisibility.PUBLIC); mapperMethod.setName("setMapper"); mapperMethod.addBodyLine("super.setMapper(" + mapperName+ ");"); mapperMethod.addAnnotation("@Autowired"); serviceImplClazz.addMethod(mapperMethod); return serviceImplClazz; } @Override public boolean validate(List&lt;String> paramList) { return true; } }]]></content>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[刀 葵 童话]]></title>
    <url>%2F2019%2F03%2F15%2Fdao-kui-tong-hua%2F</url>
    <content type="text"><![CDATA[很炸的一首电音 《刀，葵，童话》 ——太一]]></content>
      <tags>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7.6mini版-网络配置]]></title>
    <url>%2F2019%2F03%2F14%2Fcentos7-6mini-ban-wang-luo-pei-zhi%2F</url>
    <content type="text"><![CDATA[踩了一天的坑终于centos7.6无法访问外网的原因了 踩坑两个文件 /etc/sysconofig/network /etc/sysconofig/network 查看ipip addr 默认网卡信息：进入配置文件 cd /etc/sysconfig/network-scripts/ 找到配置文件ifcfg-*** ,这样的文件有两个，另一个是ifcfg-lo(里面的配置的是centos系统自身的网络配置信息，不用管他)。 我的是这个 vi ifcfg-ens33 然后配置里面信息（默认配置信息如下） TYPE=Ethernet # 网卡类型：为以太网 PROXY_METHOD=none # 代理方式：关闭状态 BROWSER_ONLY=no # 只是浏览器：否 BOOTPROTO=dhcp # 网卡的引导协议：DHCP[中文名称: 动态主机配置协议] DEFROUTE=yes # 默认路由：是, 不明白的可以百度关键词 `默认路由` IPV4_FAILURE_FATAL=no # 是不开启IPV4致命错误检测：否 IPV6INIT=yes # IPV6是否自动初始化: 是[不会有任何影响, 现在还没用到IPV6] IPV6_AUTOCONF=yes # IPV6是否自动配置：是[不会有任何影响, 现在还没用到IPV6] IPV6_DEFROUTE=yes # IPV6是否可以为默认路由：是[不会有任何影响, 现在还没用到IPV6] IPV6_FAILURE_FATAL=no # 是不开启IPV6致命错误检测：否 IPV6_ADDR_GEN_MODE=stable-privacy # IPV6地址生成模型：stable-privacy [这只一种生成IPV6的策略] NAME=ens33 # 网卡物理设备名称 UUID=f47bde51-fa78-4f79-b68f-d5dd90cfc698 # 通用唯一识别码, 每一个网卡都会有, 不能重复, 否两台linux只有一台网卡可用 DEVICE=ens33 # 网卡设备名称, 必须和 `NAME` 值一样 ONBOOT=no # 是否开机启动， 要想网卡开机就启动或通过 `systemctl restart network`控制网卡,必须设置为 `yes` 这里有两个个比较重要的概念： BOOTPROTO IP分配方式 ；dhcp为系统分配，static 静态IP ONBOOT 设置开机自启 配置网卡为静态IP设置网卡引导协议为静态 BOOTPROTO=static 设置开机自启 ONBOOT=yes 配置IP/子网掩码/网关/DNS IPADDR=192.168.140.4 #网段内的任意都行 PREFIX=24 #设置子网掩码，也可以用NETMASK=24 24代表255.255.255.0 GATEWAT=192.168.140.2 #设置网关 DNS1=211.67.140.2 #设置DNS DNS2=114.114.114.114 DNS3=8.8.8.8 注：这里都可以变量后面都可以加上数字，和DNS一样，表示有多个DNS解析，但是优先第一个 获取IP/子网掩码/网关/DNS 记住框框里的内容 子网ip就是你的那个网段，可以分配192.168.140.0——192.168.140.255 但是一般不会用0 1 2 255 0是代表哪个网段 1或者2代表着网关，就是虚拟机连接宿主机的那个ip 255是广播ip不能用，其他的你可以随便用于你的系统ip 这样我们就获得centos ip 、子网掩码 还记得我们框框里的东西：那个网管就是我们在网络配置里的网关。 接下来我们获取dns， dns就是对域名的解析，不懂自行baidu。 常用的dns：公用干净的114.114.114.114国内通用，8.8.8.8是google的；这里我添加了宿机局域网的dns（不知道是那根筋错了，加上去了）。 这样我们要的东西就齐了 重启服务有两种命令： service network restart systemctl restart network 两种命令都可以 然后我们ping 8.8.8.8 或者www.baidu.com都可以，看能不能ping外网 我就是在这里栽的，无法ping外网 如果出现无法ping外网 首先查看 cat /etc/resolv.conf 看dns配置信息加载进去没有，没有自己手动添加 nameserver 114.114.114.114 nameserver 8.8.8.8 然后查看 cat /etc/sysconofig/network 看网关信息添加进去没有，没有手动添加 GATEWAY=192.168.140.2 然后就可以愉快的访问外网了，哭兮兮，整了一天，惨不忍睹 扩展知识： 选择网络连接属性 意义 Use bridged networking（使用桥接网络） 使用（连接）VMnet0虚拟交换机，此时虚拟机相当于网络上的一台独立计算机，与主机一样，拥有一个独立的IP地址，效果如图2-56所示 Use network address translation（NAT）（使用NAT网络） 使用（连接）VMnet8虚拟交换机，此时虚拟机可以通过主机单向访问网络上的其他工作站（包括Internet网络），其他工作站不能访问虚拟机 Use Host-Only networking（使用主机网络） 使用（连接）VMnet1虚拟交换机，此时虚拟机只能与虚拟机、主机互连，与网络上的其他工作站不能访问 Do not use a network connection 虚拟机中没有网卡，相当于“单机”使用 桥接： 桥接网络是指本地物理网卡和虚拟网卡通过VMnet0虚拟交换机进行桥接，物理网卡和虚拟网卡在拓扑图上处于同等地位，那么物理网卡和虚拟网卡就相当于处于同一个网段，虚拟交换机就相当于一台现实网络中的交换机,所以两个网卡的IP地址也要设置为同一网段。 所以当我们要在局域网使用虚拟机，对局域网其他pc提供服务时，例如提供ftp，提供ssh，提供http服务，那么就要选择桥接模式。 例如大学宿舍里有一个路由器，宿舍里四个人连接这个路由器，路由器的wanip就不理会了，这个ip是动态获取的，而lanip默认是192.168.1.1,子网掩码是255.255.255.0。而其他四个人是自动获取ip，假设四个人的ip是: A:192.168.1.100/255.255.255.0, B:192.168.1.101/255.255.255.0, C:192.168.1.102/255.255.255.0, D:192.168.1.103/255.255.255.0 那么虚拟机的ip可以设置的ip地址是192.168.1.2-192.168.1.99,192.168.1.104-192.168.1.254(网络地址全0和全1的除外，再除去ABCD四个人的ip地址) 那么虚拟机的ip地址可以设置为192.168.1.98/255.255.255.0,设置了这个ip地址，ABCD这四个人就可以通过192.168.1.98访问虚拟机了，如果虚拟机需要上外网，那么还需要配置虚拟机的路由地址，就是192.168.1.1了，这样，虚拟机就可以上外网了，但是，上网我们一般是通过域名去访问外网的，所以我们还需要为虚拟机配置一个dns服务器，我们可以简单点，把dns服务器地址配置为google的dns服务器:8.8.8.8,到此，虚拟机就可以上网了 NATAT模式中，就是让虚拟机借助NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网。 NAT模式中，虚拟机的网卡和物理网卡的网络，不在同一个网络，虚拟机的网卡，是在vmware提供的一个虚拟网络。 NAT和桥接的比较: (1) NAT模式和桥接模式虚拟机都可以上外网。 (2) 由于NAT的网络在vmware提供的一个虚拟网络里，所以局域网其他主机是无法访问虚拟机的，而宿主机可以访问虚拟机，虚拟机可以访问局域网的所有主机，因为真实的局域网相对于NAT的虚拟网络，就是NAT的虚拟网络的外网，不懂的人可以查查NAT的相关知识。 (3) 桥接模式下，多个虚拟机之间可以互相访问；NAT模式下，多个虚拟机之间也可以相互访问。 如果你建一个虚拟机，只是给自己用，不需要给局域网其他人用，那么可以选择NAT，毕竟NAT模式下的虚拟系统的TCP/IP配置信息是由VMnet8(NAT)虚拟网络的DHCP服务器提供的，只要虚拟机的网路配置是DHCP，那么你不需要进行任何其他的配置，只需要宿主机器能访问互联网即可，就可以让虚拟机联网了。 例如你想建多个虚拟机集群，作为测试使用，而宿主机可能是一个笔记本，ip不固定。这种应用场景，我们需要采用nat模式了，但是我们要考虑一个问题，虚拟机之间是需要互访的，默认采用dhcp，虚拟机的ip每次重启，ip都是不固定的，所以我们需要手工设置虚拟机的ip地址。 但是我们对虚拟机网卡所在的虚拟网络的信息还一无所知，例如虚拟机网络的路由地址，子网掩码，所以我们需要先查下nat虚拟网络的信息。 使用vmware,在Edit-&gt;Virtual Network Editor中配置好虚拟网络信息后看到下图所示，注意VMnet8，VMnet8相当于是本机的一个路由，虚拟机设置NAT后就通过这个路由进行上网的，可以查看其网络地址，路由地址，子网掩码。 选择VMnet8-&gt;NAT设置,可以看到子网ip显示为192.168.233.0，子网掩码是255.255.255.0，那路由地址呢，其实就是网关IP了，都是同个东西，这里是192.168.233.2。 接下来就好办了，在对应的虚拟机设置好ip，子网掩码，路由地址就可以上外网了，至于dns可以设置为8.8.8.8. Host-Only在Host-Only模式下，虚拟网络是一个全封闭的网络，它唯一能够访问的就是主机。其实Host-Only网络和NAT网络很相似，不同的地方就是Host-Only网络没有NAT服务，所以虚拟网络不能连接到Internet。主机和虚拟机之间的通信是通过VMware Network Adepter VMnet1虚拟网卡来实现的。 Host-Only的宗旨就是建立一个与外界隔绝的内部网络，来提高内网的安全性。这个功能或许对普通用户来说没有多大意义，但大型服务商会常常利用这个功能。如果你想为VMnet1网段提供路由功能，那就需要使用RRAS，而不能使用XP或2000的ICS，因为ICS会把内网的IP地址改为192.168.0.1，但虚拟机是不会给VMnet1虚拟网卡分配这个地址的，那么主机和虚拟机之间就不能通信了。 参考链接： 写的不好，优先参考这个链接https://segmentfault.com/a/1190000011954814 http://www.cnblogs.com/ggjucheng/archive/2012/08/19/2646007.html]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java核心卷Ⅰ-泛型]]></title>
    <url>%2F2019%2F03%2F12%2Fjava-he-xin-juan-i-fan-xing%2F</url>
    <content type="text"><![CDATA[本章节主要讲java核心卷Ⅰ泛型 定义简单泛型类public class Pair&lt;T> { private T first; private T second; public Pair(){ first=null; second=null; } //这不算泛型方法 只用用类的泛型 public Pair(T first,T second){ this.first=first; this.second=second; } //同样也不是 public T getFirstO { return first; } public T getSecondO { return second; } public void setFirst (T newValue) { first = newValue; } public void setSecond(T newValue) { second = newValue; } } 泛型方法package faxing; public class Test { //&lt;T>是泛型的声明 第一个T是泛型的返回值 第二个T是泛型的形参 public &lt;T> T Test(T t){ //？通配符，声明class1是Object或者继承于Object的子类类型 Class&lt;? extends Object> class1 = t.getClass(); System.out.println(class1.getClass()); return t; } } 详细关于泛型方法与泛型类的语法参考 https://blog.csdn.net/s10461/article/details/53941091 泛型上下限​ 正如第二个代码所示使用extends表示泛型的上限制，这里extends后面不仅可以是类，也可以是接口。 但是不能一个是接口，一个是类，同时那个类是实现了接口的那种情况。 泛型diamagnetic与虚拟机泛型擦出在JVM中是不存在泛型的概念的，所有的泛型在编译时就会变成普通的类、接口、方法。上代码这是我们编辑代码时所见的，有泛型的概念 public class Pair&lt;T> { private T first; private T second; public Pair(){ first=null; second=null; } //这不算泛型方法 只用用类的泛型 public Pair(T first,T second){ this.first=first; this.second=second; } //同样也不是 public T getFirstO { return first; } public T getSecondO { return second; } public void setFirst (T newValue) { first = newValue; } public void setSecond(T newValue) { second = newValue; } //这里的T不同于类中声明的那个T public &lt;T> T Test(T t){ //？通配符，声明class1是Object或者继承于Object的子类类型 Class&lt;? extends Object> class1 = t.getClass(); System.out.println(class1.getClass()); return t; } } 在编译之后会变成下面代码的样子。其实是在编译时所有的泛型会变成其他类，规则是： 如果在类中指明了他继承的那个类，形式如下： 会编译成以他的继承的类、接口（其实不能说是继承，只是因为用extends更能体现继承的思想）为上限的类型，及那个类及那个类的子类，就是那个家伙或他的子子孙孙（应该优先子孙的）,就是下面这种类型 public class Pair { private Object first; private Object second; public Pair(){ first=null; second=null; } //这不算泛型方法 只用用类的泛型 public Pair(Object first,Object second){ this.first=first; this.second=second; } //同样也不是 public Object getFirstO { return first; } public Object getSecondO { return second; } public void setFirst (Object newValue) { first = newValue; } public void setSecond(Object newValue) { second = newValue; } //这里的T不同于类中声明的那个T public Object Test(Object t){ //？通配符，声明class1是Object或者继承于Object的子类类型 Object class1 = t.getClass(); System.out.println(class1.getClass()); return t; } } * 带来两个问题 1. 继承泛型带来的麻烦，(子类没有覆盖住父类的方法) &lt;https://blog.csdn.net/weixin_37770552/article/details/77692449&gt; 上面那个代码，他在编译时变成了Object类型，包括里面的泛型参数。如果我们想继承他的方法，比如 ```java class SonPair extends Pair&lt;String&gt;{ public void setFirst(String fir){....} } ``` 很明显能看出来的问题，我们准备覆盖setFirst方法，然而父类的那个方法的类型是Object，然而这里是String类型，覆盖失败。 来看看编译器解决这个问题 ```java 编译器 会自动在 SonPair中生成一个桥方法(bridge method ) 强转 public void setFirst(Object fir){ setFirst((String) fir) } ``` 这样也带来一个问题，如果我们想覆盖getFirst方法，看下面代码 ```java class SonPair extends Pair&lt;String&gt;{ public String getFirst(){....} } ``` 和之前生成的代码对比，我们生成的同名不同返回值的两个方法 ```java ①String getFirst() // 自己定义的方法 ②Object getFirst() // 编译器生成的桥方法 ``` 这里给自己补充一个知识点：方法签名=方法名+参数列表。上图： ![](https://i.loli.net/2019/03/12/5c87ba0aa21ee.png) 这样就带来了问题，我们不能写出方法签名相同的代码。 但是jvm会用类型参数和返回值确定一个方法 。所以这里是可行的 2. 泛型类型中的方法冲突 在第一个代码中添加一下方法 ```java public boolean equals(T value){ return (first.equals(value)); } ``` ![](https://i.loli.net/2019/03/12/5c87ba6b8499c.png) Name clash: The method equals(T) of type Pair has the same erasure as equals(Object) of type Object but does not override it 所以我也不知道这里怎么解决。 参考链接： 关于泛型基本语法：&lt;https://blog.csdn.net/s10461/article/details/53941091&gt; 关于类型擦除：&lt;https://blog.csdn.net/weixin_37770552/article/details/77692449&gt; # 通配符类型 全文摘自这里，此处只是备份，怕链接失效，没有这么好的博客 &lt;https://segmentfault.com/a/1190000005337789&gt; ## 数组的协变 在了解通配符之前，先来了解一下数组。Java 中的数组是协变的，什么意思？看下面的例子： ```java class Fruit {} class Apple extends Fruit {} class Jonathan extends Apple {} class Orange extends Fruit {} public class CovariantArrays { public static void main(String[] args) { Fruit[] fruit = new Apple[10]; fruit[0] = new Apple(); // OK fruit[1] = new Jonathan(); // OK // Runtime type is Apple[], not Fruit[] or Orange[]: try { // Compiler allows you to add Fruit: fruit[0] = new Fruit(); // ArrayStoreException } catch(Exception e) { System.out.println(e); } try { // Compiler allows you to add Oranges: fruit[0] = new Orange(); // ArrayStoreException } catch(Exception e) { System.out.println(e); } } } /* Output: java.lang.ArrayStoreException: Fruit java.lang.ArrayStoreException: Orange *///:~​ main 方法中的第一行，创建了一个 Apple 数组并把它赋给 Fruit 数组的引用。这是有意义的，Apple 是 Fruit 的子类，一个 Apple 对象也是一种 Fruit 对象，所以一个 Apple 数组也是一种 Fruit 的数组。这称作数组的协变，Java 把数组设计为协变的，对此是有争议的，有人认为这是一种缺陷。 ​ 尽管 Apple[] 可以 “向上转型” 为 Fruit[]，但数组元素的实际类型还是 Apple，我们只能向数组中放入 Apple或者 Apple 的子类。在上面的代码中，向数组中放入了 Fruit 对象和 Orange 对象。对于编译器来说，这是可以通过编译的，但是在运行时期，JVM 能够知道数组的实际类型是 Apple[]，所以当其它对象加入数组的时候就会抛出异常。 ​ 泛型设计的目的之一是要使这种运行时期的错误在编译期就能发现，看看用泛型容器类来代替数组会发生什么： // Compile Error: incompatible types: ArrayList&lt;Fruit> flist = new ArrayList&lt;Apple>(); ​ 上面的代码根本就无法编译。当涉及到泛型时， 尽管 Apple 是 Fruit 的子类型，但是 ArrayList 不是 ArrayList 的子类型，泛型不支持协变。 使用通配符​ 从上面我们知道，List&lt;Number&gt; list = ArrayList&lt;Integer&gt;&gt;这样的语句是无法通过编译的，尽管 Integer 是 Number 的子类型。那么如果我们确实需要建立这种 “向上转型” 的关系怎么办呢？这就需要通配符来发挥作用了。 上边界限定通配符​ 利用 &lt;? extends Fruit&gt; 形式的通配符，可以实现泛型的向上转型： public class GenericsAndCovariance { public static void main(String[] args) { // Wildcards allow covariance: List&lt;? extends Fruit> flist = new ArrayList&lt;Apple>(); // Compile Error: can’t add any type of object: // flist.add(new Apple()); // flist.add(new Fruit()); // flist.add(new Object()); flist.add(null); // Legal but uninteresting // We know that it returns at least Fruit: Fruit f = flist.get(0); } } ​ 上面的例子中， flist 的类型是 List&lt;? extends Fruit&gt;，我们可以把它读作：一个类型的 List， 这个类型可以是继承了 Fruit 的某种类型。注意，这并不是说这个 List 可以持有 Fruit 的任意类型。通配符代表了一种特定的类型，它表示 “某种特定的类型，但是 flist 没有指定”。这样不太好理解，具体针对这个例子解释就是，flist 引用可以指向某个类型的 List，只要这个类型继承自 Fruit，可以是 Fruit 或者 Apple，比如例子中的 new ArrayList，但是为了向上转型给 flist，flist 并不关心这个具体类型是什么。 ​ 如上所述，通配符 List&lt;? extends Fruit&gt; 表示某种特定类型 ( Fruit 或者其子类 ) 的 List，但是并不关心这个实际的类型到底是什么，反正是 Fruit 的子类型，Fruit 是它的上边界。那么对这样的一个 List 我们能做什么呢？其实如果我们不知道这个 List 到底持有什么类型，怎么可能安全的添加一个对象呢？在上面的代码中，向 flist 中添加任何对象，无论是 Apple 还是 Orange 甚至是 Fruit 对象，编译器都不允许，唯一可以添加的是 null。所以如果做了泛型的向上转型 (List&lt;? extends Fruit&gt;&gt;flist = new ArrayList&lt;Apple&gt;())，那么我们也就失去了向这个 List 添加任何对象的能力，即使是 Object 也不行。 ​ 另一方面，如果调用某个返回 Fruit 的方法，这是安全的。因为我们知道，在这个 List 中，不管它实际的类型到底是什么，但肯定能转型为 Fruit，所以编译器允许返回 Fruit。 ​ 了解了通配符的作用和限制后，好像任何接受参数的方法我们都不能调用了。其实倒也不是，看下面的例子： public class CompilerIntelligence { public static void main(String[] args) { List&lt;? extends Fruit> flist = Arrays.asList(new Apple()); Apple a = (Apple)flist.get(0); // No warning flist.contains(new Apple()); // Argument is ‘Object’ flist.indexOf(new Apple()); // Argument is ‘Object’ //flist.add(new Apple()); 无法编译 } } ​ 在上面的例子中，flist 的类型是 List&lt;? extends Fruit&gt;，泛型参数使用了受限制的通配符，所以我们失去了向其中加入任何类型对象的例子，最后一行代码无法编译。 ​ 但是 flist 却可以调用 contains 和 indexOf 方法，它们都接受了一个 Apple 对象做参数。如果查看 ArrayList 的源代码，可以发现 add() 接受一个泛型类型作为参数，但是 contains 和 indexOf 接受一个 Object 类型的参数，下面是它们的方法签名： public boolean add(E e) public boolean contains(Object o) public int indexOf(Object o) ​ 所以如果我们指定泛型参数为 &lt;? extends Fruit&gt;时，add() 方法的参数变为 ? extends Fruit，编译器无法判断这个参数接受的到底是 Fruit 的哪种类型，所以它不会接受任何类型。 ​ 然而，contains 和 indexOf 的类型是 Object，并没有涉及到通配符，所以编译器允许调用这两个方法。这意味着一切取决于泛型类的编写者来决定那些调用是 “安全” 的，并且用 Object 作为这些安全方法的参数。如果某些方法不允许类型参数是通配符时的调用，这些方法的参数应该用类型参数，比如 add(E e)。 ​ 当我们自己编写泛型类时，上面介绍的就有用了。下面编写一个 Holder 类： public class Holder&lt;T> { private T value; public Holder() {} public Holder(T val) { value = val; } public void set(T val) { value = val; } public T get() { return value; } public boolean equals(Object obj) { return value.equals(obj); } public static void main(String[] args) { Holder&lt;Apple> Apple = new Holder&lt;Apple>(new Apple()); Apple d = Apple.get(); Apple.set(d); // Holder&lt;Fruit> Fruit = Apple; // Cannot upcast Holder&lt;? extends Fruit> fruit = Apple; // OK Fruit p = fruit.get(); d = (Apple)fruit.get(); // Returns ‘Object’ try { Orange c = (Orange)fruit.get(); // No warning } catch(Exception e) { System.out.println(e); } // fruit.set(new Apple()); // Cannot call set() // fruit.set(new Fruit()); // Cannot call set() System.out.println(fruit.equals(d)); // OK } } /* Output: (Sample) java.lang.ClassCastException: Apple cannot be cast to Orange true *///:~ ​ 在 Holer 类中，set() 方法接受类型参数 T 的对象作为参数，get() 返回一个 T 类型，而 equals() 接受一个 Object 作为参数。fruit 的类型是 Holder&lt;? extends Fruit&gt;，所以set()方法不会接受任何对象的添加，但是 equals() 可以正常工作。 下边界限通配符的另一个方向是 “超类型的通配符“: ? super T，T 是类型参数的下界。使用这种形式的通配符，我们就可以 ”传递对象” 了。还是用例子解释： public class SuperTypeWildcards { static void writeTo(List&lt;? super Apple> apples) { apples.add(new Apple()); apples.add(new Jonathan()); // apples.add(new Fruit()); // Error } } riteTo 方法的参数 apples 的类型是 List&lt;? super Apple&gt;，它表示某种类型的 List，这个类型是 Apple 的基类型。也就是说，我们不知道实际类型是什么，但是这个类型肯定是 Apple 的父类型。因此，我们可以知道向这个 List 添加一个 Apple 或者其子类型的对象是安全的，这些对象都可以向上转型为 Apple。但是我们不知道加入 Fruit 对象是否安全，因为那样会使得这个 List 添加跟 Apple 无关的类型。 在了解了子类型边界和超类型边界之后，我们就可以知道如何向泛型类型中 “写入” ( 传递对象给方法参数) 以及如何从泛型类型中 “读取” ( 从方法中返回对象 )。下面是一个例子： public class Collections { public static &lt;T> void copy(List&lt;? super T> dest, List&lt;? extends T> src) { for (int i=0; i&lt;src.size(); i++) dest.set(i,src.get(i)); } } src 是原始数据的 List，因为要从这里面读取数据，所以用了上边界限定通配符：&lt;? extends T&gt;，取出的元素转型为 T。dest 是要写入的目标 List，所以用了下边界限定通配符：&lt;? super T&gt;，可以写入的元素类型是 T 及其子类型。 无边界通配符有一种通配符是无边界通配符，它的使用形式是一个单独的问号：List&lt;?&gt;，也就是没有任何限定。不做任何限制，跟不用类型参数的 List 有什么区别呢？ List&lt;?&gt; list 表示 list 是持有某种特定类型的 List，但是不知道具体是哪种类型。那么我们可以向其中添加对象吗？当然不可以，因为并不知道实际是哪种类型，所以不能添加任何类型，这是不安全的。而单独的 List list ，也就是没有传入泛型参数，表示这个 list 持有的元素的类型是 Object，因此可以添加任何类型的对象，只不过编译器会有警告信息。 总结： 使用 List&lt;? extends C&gt;&gt;list 这种形式，表示 list 可以引用一个 ArrayList ( 或者其它 List 的 子类 ) 的对象，这个对象包含的元素类型是 C 的子类型 ( 包含 C 本身）的一种。 使用 List&lt;? super C&gt; list 这种形式，表示 list 可以引用一个 ArrayList ( 或者其它 List 的 子类 ) 的对象，这个对象包含的元素就类型是 C 的超类型 ( 包含 C 本身 ) 的一种。 《java核心卷》 带有超类型限定的通配符可以向泛型对象写人，super。 带有子类型限定的通配符可以从泛型对象读取，extends。 泛型的继承规则public class Father { public void fatherPrint() { System.out.println("I am father"); } } public class Son extends Father{ public void sonPrint() { System.out.println("I am son"); } } public class FatherSon { public static void main(String[] args) { Pair&lt;Father> fPair=new Pair&lt;Son>(new Son(), new Son()); Pair&lt;Son> fPair2=new Pair&lt;Son>(new Son(), new Son()); } } 报错： Type mismatch: cannot convert from Pair Son to Pair Father 虽然泛型中类型T是继承关系，但是在泛型中这种写法是不允许的 实际上，无论类型变量T和S之间有什么关系，包括继承关系还是实现关系，Pair和Pair之间都不会有什么联系 下面这种继承是可以的 class BasicPair&lt;T> { } class Pair&lt;T> extends BasicPair&lt;T>{ private T first; private T second; public Pair(T first, T second) { super(); this.first = first; this.second = second; } public T getFirst() { return first; } public void setFirst(T first) { this.first = first; } public T getSecond() { return second; } public void setSecond(T second) { this.second = second; } } 引用一句话泛型的继承只是在类这个维度上是可以的，他们的参数类型必须是一致的 参考链接： https://blog.csdn.net/l294265421/article/details/46413975 https://blog.csdn.net/csdn_of_coder/article/details/52563982 泛型的约束与局限性 泛型的一个原则：如果一段代码在编译时没有提出“未经检查的转换”警告，则程序在运行时不会引发ClasscastException异常 不能用基本类型实例化类型参数​ 因为泛型在编译时存在类型擦除，会将类型转换成原始类型，如果是原始类型，就无法转换，但是基本类型是有8种，我们可以使用他们的封装类代替 运行时类型查询只适合原始类型因为泛型的擦除，使代码运行时用的是原始类型，而其他类型无法使用instanceof 上代码 //泛型类 public class OriginTest&lt;T> { private T id; private T name; private T salary; public T getId() { return id; } public void setId(T id) { this.id = id; } public T getName() { return name; } public void setName(T name) { this.name = name; } public T getSalary() { return salary; } public void setSalary(T salary) { this.salary = salary; } public OriginTest(T id, T name, T salary) { super(); this.id = id; this.name = name; this.salary = salary; } public OriginTest() { super(); } } //测试 public class OriginTest1 { public static void main(String[] args) { OriginTest&lt;String> test = new OriginTest&lt;>(); if(test instanceof OriginTest&lt;String>) { System.out.println(true); }else { System.out.println(false); } } } 报错： Cannot perform instanceof check against parameterized type OriginTest. Use the form OriginTest&lt;?&gt; instead since further generic type information will be erased at runtime 无法对参数化类型OriginTest 执行instanceof检查。 请使用OriginTest &lt;？&gt;形式，因为在运行时将删除其他泛型类型信息 不能创建参数化类型的数组同样也是擦除搞得鬼， 个人理解，new的时候实例化的是Object类型的，然而我们使用变量是String类型，我们不能直接用父类类型变量指向子类的对象。需要强制类型转换，所以这里是不允许的 但是在想如果我们用的变量是Object类型的呢，实验的一般发现这样仍然不行，编译器不允许这样的存在。 报错：Cannot create a generic array of OriginTest 上面两个报错一样 那么我们用强制类型转换（其实就是向上转型，向下转型问题）： 声明通配类型的数组，然后后进行类型转换 OriginTest&lt;String>[] test1=(OriginTest&lt;String>[]) new OriginTest&lt;?>[10]; 但是这里存在警告：Type safety: Unchecked cast from OriginTest&lt;?&gt;[] to OriginTest[] 这是不安全的，上截图 对于这类问题，使用集合代替数组，解决不同类型的问题： new ArrayList&lt;OriginTest&lt;String>>(); varargs警告(可变参数警告)补充知识点：可变参数其实就是数组 所以当我们使用可变参数泛型的类时，会出现上面那种问题，这里规则放松，没有报错只是警告。但是在后面赋值的时候还是会出现异常，应该是类型转换异常 不能实例化类型变量我们不知只有new T(…) new T[…]或者T.class这样的类型变量，原因就是编译器不知道T是什么类型。这里我有个疑问，既然T默认在没有指定类型的情况下，是编译成Object类型，这里为什么不行？？？ 当我们想定义未知类型的 对象时，有两种方法： 第二种方法也可以表示为： Pair&lt;String> t=Pair.makePair(String::new) makePair 方法接收一个Supplier， 这是一个函数式接口， 表示一个无参数而且返回类型为T 的函数 不能构造泛型数组数组是可以由父类指向子类实体的 Father[] f= new Son[]; ​ 然而如果可以使用泛型数组，在编译时泛型数组会被擦除为object类型，意味着此时数组中可以存储任意类型的数据，让我们在使用指向该数组的变量类型时就会报错(可以理解为类型转换错误)，出现极大问题，因此，java不允许使用泛型数组。详细代码看参考链接 参考链接： http://www.blogjava.net/sean/archive/2005/08/09/9630.html https://blog.csdn.net/x_iya/article/details/79550667]]></content>
      <categories>
        <category>读书笔记</category>
        <category>java核心卷1</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-算法]]></title>
    <url>%2F2019%2F03%2F12%2Fda-hua-shu-ju-jie-gou-suan-fa%2F</url>
    <content type="text"><![CDATA[敲黑板：时间复杂度计算 算法是解决特定问题求解步骤的描述，在计算中表现为指令的有限序列，并且每天指令表示一个或多个操作 算法特性 输入输出 有穷性 确定性 可行性 算法设计要求： 正确性 可读性 健壮性 高效率和低存储量需求 算法度量方法：事前统计方法（不科学不准确），时后统计方法 函数的渐进增长： 给定两个函数f(n)和g(n)，如果存在一个整数N，使得对于所有的n &gt; N，f(n)总是比g(n)大，那么，我们说f(n)的**渐近**增长快于g(n)。 推到导大O 用常数1取代运行时间中的所有加法常数 在修改后的运行次数函数中，只保留最高阶项 如果最高阶项存在切不唯一，只保留最高阶项]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-绪论]]></title>
    <url>%2F2019%2F03%2F12%2Fda-hua-shu-ju-jie-gou-xu-lun%2F</url>
    <content type="text"><![CDATA[开始撸算法啦 数据结构 数据结构是一门研究非数值计算的程序设计问题中的操作对象，以及他们之间的关系和操作等相关问题的学科 基本概念和术语 数据：是描述客观事物的符号，是计算机中可以操作的对象，是能被计算机识别，并输入给计算机处理的符号集合 数据元素：是组成数据的、有一定意义的基本单位，在计算机中通常作为整体处理，也成为记录 数据项：一个数据元素有很多数据项组成 ，数据项是数据不可分割的最小单位 数据对象：是性质相同的数据元素的集合，是数据的子集 数据结构：是相互之间存在一种或多种特定关系的数据元素的集合 逻辑结构和物理结构 逻辑结构：是指数据对象中数据元素之间的相互关系 集合结构： 线性结构：一对一 树形结构：一对多的层次关系 图形结构：多对多 物理结构：是指数据的逻辑结构在计算机中的存储形式 顺序存储结构：将数据元素存放在地址连续的存储单元中，其数据间的逻辑结构和物理关系是一致的 链式存储结构：是把数据元素存放在任意的存储单元中，这组存储单元可以是连续，也可以是不连续的 基本目的：将数据及其逻辑关系存储到计算机的内存中。 抽象数据类型 数据类型：是指一组性质不同的值的集合及定义在此集合上的一些操作的总称 数据类型（C语言分法） 原子类型：是不可以在分解的基本类型，包括整型、实型、字符型等。 结构类型：有若干个类型组合而成，是可以再分解的。 抽象数据类型：是指一个数学模型及定义在该模型上的一组操作]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构-顺序表]]></title>
    <url>%2F2019%2F03%2F11%2Fda-hua-shu-ju-jie-gou-shun-xu-biao%2F</url>
    <content type="text"><![CDATA[大话数据结构顺序表 源码及主要部分解读 注意函数形参里面L 和L的区别，L指代的是数组本身，不对数组进行更改。\L是指针，会对数组进行更改，L用L.length 而*L用L-&gt;length 解读见代码 完成功能： 结构体定义 线性表的清空 获取指定位置的元素 匹配制定元素 插入操作 删除操作 计算线性表的长度 #include&lt;stdio.h> /*用符号“&lt;”和“>”将要包含的文件的文件名括起来。 这种方法指示预处理程序到预定义的&lt;b>缺省路径下&lt;/b>寻找文件。 预定义的缺省路径通常是在INCLUDE环境变量中指定的*/ /* 用双引号将要包含的文件的文件名括起来。 这种方法指示预处理程序先到当前目录下寻找文件， 再到预定义的缺省路径下寻找文件。 */ #include "stdlib.h" #include "io.h" #include "math.h" #include "time.h" //定义变量 #define OK 1 #define ERROR 0 #define TRUE 1 #define FALSE 0 #define MAXSIZE 20 /*存储空间初始分配量*/ typedef int Status; /*Status是函数的的类型，其值是函数结果状态码*/ typedef int ElemType; /*ElemType类型根据实际情况而定，这里假设为int*/ /*完成增删改查功能*/ Status visit(ElemType c) { printf("%d ",c); return OK; } /*结构体*/ typedef struct { /* data */ ElemType data[MAXSIZE]; /*数组，存储元素*/ int length; /*线性表当前长度*/ }SqlList; /*初始化顺序线性表*/ Status InitList(SqlList *L) { L->length=0; return OK; } /*初始化条件：顺序表L已存在*/ /*判断是否为空表，空表返回true 非空返回false*/ Status ListEmpty(SqlList L) { if (L.length==0) { return TRUE; }else { return FALSE; } } /*初始化条件：顺序表L已存在，操作结果，将L重置为空表*/ Status ClearList(SqlList *L) { L->length=0; return OK; } /*初始条件，顺序表已经存在*/ int ListLength(SqlList L) { return L.length; } /*初始条件，顺序表已经存在*/ /*获取元素 用e返回L中第i个数据元素的值*/ Status GetElem(SqlList L,int i,ElemType *e) { if (L.length==0||i&lt;1||i>L.length) { return ERROR; } *e=L.data[i-1]; return OK; } /*定位元素*/ int LocateElem(SqlList L,ElemType e) { int i; if(L.length==0) { return 0; } for(i = 0; i &lt; L.length; i++) { if(L.data[i]==e){ break; } } if (i>L.length) { return 0; } return i+1; } /*添加操作*/ Status ListInsert(SqlList *L,int i,ElemType e){ int k; if (L->length==MAXSIZE) { //线性表已满 return ERROR; } if(i&lt;1||i>L->length+1){ //输入内容错误 return ERROR; } if (i&lt;=L->length) {/*插入的位置不在末尾*/ for(k=L->length-1; k>=i-1; k--)/*将要插入位置后面的数字向后移动*/ { L->data[k+1]=L->data[k]; } } L->data[i-1]=e; /*新元素插入*/ L->length++; return OK; } /*删除操作*/ Status ListDelete(SqlList *L,int i,ElemType *e){ int k; if (L->length==0) { return ERROR; } if(i&lt;1||i>L->length+1){/*删除位置不正确*/ return ERROR; } if (i&lt;L->length) { for(k=1 ; k &lt; L->length; k++)/*将要删除位置的元素向前移动*/ { L->data[k-1]=L->data[k]; } } L->length--; return OK; } /*对每个元素输出*/ Status ListTraverse(SqlList L){ int i; for( i = 0; i &lt; L.length; i++) { visit(L.data[i]);//输出 } printf("\n"); return OK; } /*两个顺序表合并*/ void unionL(SqlList *La,SqlList Lb){ int La_len,Lb_len,i; ElemType e; La_len=ListLength(*La); Lb_len=ListLength(Lb); for( i = 0; i &lt; Lb_len; i++) { GetElem(Lb,i,&amp;e);/*将列表Lb中的内容拷贝到e中*/ if (!LocateElem(*La,e)) {/*判断是否相等*/ ListInsert(La,++La_len,e); } } } int main(){ SqlList L; SqlList Lb; ElemType e; Status i; int j,k; i=InitList(&amp;L); printf("初始化L后：L.length=%d\n",L.length); for(j=1;j&lt;=5;j++){ i=ListInsert(&amp;L,1,j); } printf("在L的表头依次插入1～5后：L.data="); ListTraverse(L); //原始长度 printf("L.length=%d \n",L.length); //是否为空 i=ListEmpty(L); printf("L是否空：i=%d(1:是 0:否)\n",i); //清空表 i=ClearList(&amp;L); printf("清空L后：L.length=%d\n",L.length); i=ListEmpty(L); printf("L是否空：i=%d(1:是 0:否)\n",i); for(j=1;j&lt;=10;j++) ListInsert(&amp;L,j,j); printf("在L的表尾依次插入1～10后：L.data="); ListTraverse(L); printf("L.length=%d \n",L.length); ListInsert(&amp;L,1,0); printf("在L的表头插入0后：L.data="); ListTraverse(L); printf("L.length=%d \n",L.length); GetElem(L,5,&amp;e); printf("第5个元素的值为：%d\n\n",e); for(j=3;j&lt;=4;j++) { k=LocateElem(L,j); if(k) printf("第%d个元素的值为%d\n",k,j); else printf("没有值为%d的元素\n",j); } k=ListLength(L); /* k为表长 */ for(j=k+1;j>=k;j--) { i=ListDelete(&amp;L,j,&amp;e); /* 删除第j个数据 */ if(i==ERROR) printf("删除第%d个数据失败\n",j); else printf("删除第%d个的元素值为：%d\n",j,e); } printf("依次输出L的元素："); ListTraverse(L); j=5; ListDelete(&amp;L,j,&amp;e); /* 删除第5个数据 */ printf("删除第%d个的元素值为：%d\n",j,e); printf("依次输出L的元素："); ListTraverse(L); //构造一个有10个数的Lb i=InitList(&amp;Lb); for(j=6;j&lt;=15;j++) i=ListInsert(&amp;Lb,1,j); //合并两张表 unionL(&amp;L,Lb); printf("依次输出合并了Lb的L的元素："); ListTraverse(L); getch(); return 0; }]]></content>
      <categories>
        <category>读书笔记</category>
        <category>大话数据结构</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Next配置]]></title>
    <url>%2F2019%2F03%2F10%2Fhexo-next-pei-zhi%2F</url>
    <content type="text"><![CDATA[Hexo Next踩坑 Hexo Next 搭建博客摘要命令title: Hexo Next配置 date: 2019-03-10 15:38:16 update: 2019-03-15 15:38:16 tags: - Hexo - Next categories: - Hexo comment: true images: ![1552203621955](../images/1552203621955.png) top: true博客搭建参考链接http://frieren.me/2017/09/18/Using-Hexo+Github-Pages-to-build-your-own-blog/ https://xuhaoblog.com/hexo-github-pages.html http://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html https://linghucong.js.org/2016/04/15/2016-04-15-hexo-github-pages-blog/ https://mrlichangming.github.io/2018/09/16/hexo-Next%E4%B8%BB%E9%A2%98%E4%BD%BF%E7%94%A8%E9%85%8D%E7%BD%AE/ https://neveryu.github.io/2016/09/03/hexo-next-one/ 官网：https://theme-next.iissnan.com/ github:https://github.com/iissnan/hexo-theme-next]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java核心卷Ⅰ-集合]]></title>
    <url>%2F2019%2F03%2F10%2Fjava-he-xin-juan-i-ji-he%2F</url>
    <content type="text"><![CDATA[本章节主要讲java核心卷1的集合框架 这篇很水，请看链接一只渣渣威 java集合框架集合框架中的接口集合两个基本接口Collection Map Iterable接口&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Iterable接口中只定义了一个方法：iterator，返回集合Iterator对象，所有实现了Iterator接口的集合都可以使用foreach循环进行遍历。 public interface Iterable&lt;T> { Iterator&lt;T> iterator(); } Collection接口&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这是集合类的基本接口，其中声明了很多有用的方法，所有的类都需要实现里面的方法，如果我们实现这些接口无疑增加很多的工作量，所以Java 类库提供了一个类AbstractCollection，它将基础方法size 和iterator 抽象化了。 List接口&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有序集合，加到容器中的特定位置。可以采用两种访问方式，一种是使用一个迭代器访问，这样必须顺序访问；另一种成为随机访问，是使用整数索引访问，这样可以按任意循序访问元素。 Set接口&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set接口相当于Collection接口,set中不允许添加重复内容。 SortSet SortMap接口&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用于提供排序的比较器对象 NavigableSet 和NavigableMap&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接口NavigableSet 和NavigableMap, 其中包含一些用于搜索和遍历有序集和映射的方法。 具体的集合链表List接口 实现接口的类LinkedList java中的链表是双向链表，每个节点及存放着他的前驱结点，也存放着他的后驱节点 链表可以理解为队列，先进先出。当然他也提供了反向遍历链表的方法。 集合类库中提供了子接口ListIterator，其中提供了一些有用的方法，比如反向遍历链表 E previous() boolean hasPrevious() Add方法在迭代器位置之前添加一个新对象 如果迭代器发现它的集合被另一个迭代器修改了， 或是被该集合自身的方法修改了， 就会抛出一个ConcurrentModificationException 异常。这类问题，可以根据需要给容器附加许多迭代器，但是这些迭代器只能读取列表，弄外，在单独设置一个既能读又能写的迭代器。 链表只负责跟踪对列表的结构性修改， 例如， 添加元素、删除元素。set 方法不被视为结构性修改。 不支持快速随机访问，读取效率低，但是修改方便 元素访问方式一种是用迭代器， 另一种是用get 和set 方法随机地访问每个元素。后者不适用于链表，其实get方法还是顺序访问。效率底下 列表迭代器接口可以获取当前位置的索引。nextIndex方法返回下一次调用next方法是返回元素的位置。previousIndex返回下一次调用previous方法是返回元素的索引。理解：比如光标在这里A B | C D 此时读取的位置是B的位置下次调用next 光标变化 A B C | D 读取的位置是C的位置下次调用previous 光标变化 A | B C D 读取的位置是A的位置 代码练习 package jiheTest; import java.util.Iterator; import java.util.LinkedList; import java.util.List; import java.util.ListIterator; public class LinkedListTest { public static void main(String[] args) { List&lt;String> a=new LinkedList&lt;>(); a.add("a"); a.add("b"); a.add("c"); List&lt;String> b=new LinkedList&lt;>(); b.add("A"); b.add("B"); b.add("C"); ListIterator&lt;String> aIter=a.listIterator();//跳过下一个节点，不读取 Iterator&lt;String> bIter=b.listIterator(); /** * 变化过程 * 起始 | a b c 越过第一个元素 * a | b c * a A | b c 添加A元素 越过下一个元素 * a A b | c * a A b B | c * 以下类推 */ while (bIter.hasNext()) { if(aIter.hasNext()) aIter.next();//跳过下一个元素 aIter.add(bIter.next());//添加b元素 } System.out.println(a); bIter=b.iterator(); while (bIter.hasNext()) { bIter.next();//跳过第一个元素 if(bIter.hasNext()) { bIter.next();//跳过下一个元素 bIter.remove();//移除当前元素 } } System.out.println(b); a.removeAll(b);//移除b中与a相同的元素 System.out.println(a); } } 结果[a, A, b, B, c, C][A, C][a, b, B, c] 数组列表ArrayList实现List接口 一般使用get set方法访问内部元素 ArrayList封装了一个动态再分配的对象数组 Vector 类的所有方法都是同步的。可以由两个线程安全地访问一个Vector 对象。但是， 如果由一个线程访问Vector, 代码要在同步操作上耗费大量的时间。这种情况还是很常见的。而ArrayList 方法不是同步的，因此， 建议在不需要同步时使用ArrayList, 而不要使用Vector。 散列集散列表用链表数组表示 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;链表和数组是按照人们的意愿存储的，如果我们想查看某个指定的元素又记位置，我们必须遍历他们，消耗很多时间，而使用散列集我们可以快速查找我们需要的内容。 使用散列集我们无法控制元素出现的位置，他们将按照有利于操作目的的原则组织数据 散列码定义： 散列表示为每一个对象计算一个整数，称为散列码散列码是由对象域产生的一个整数。 具有不同的数据域的对象将产生不同的散列码ep:使用String类的HashCode方法生成的 自定义类，我们需要自己负责实现这个类的HashCode方法。 自己实现的hashcode方法应该和equals方法兼容，即如果e.equals(b)为true，a b对象拥有相同的散列码 散列码的计算只与散列的对象有关，与散列表中的其他对象无关 java中，散列表用链表数组表示。 每个列表称为桶（bucket），要想査找表中对象的位置， 就要先计算它的散列码， 然后与桶的总数取余， 所得到的结果就是保存这个元素的桶的索引。例如， 如果某个对象的散列码为76268, 并且有128 个桶， 对象应该保存在第108 号桶中（ 76268除以128 余108 )。或许会很幸运， 在这个桶中没有其他元素， 此时将元素直接插人到桶中就可以了。当然， 有时候会遇到桶被占满的情况， 这也是不可避免的。这种现象被称为散列冲突（ hashcollision) o 这时， 需要用新对象与桶中的所有对象进行比较， 査看这个对象是否已经存在。如果散列码是合理且随机分布的， 桶的数目也足够大， 需要比较的次数就会很少。 设置桶数：一般设置为预计元素的75%—150%，最好将桶数设置成一个素数，防止键的集聚 。 事先不知道存储多少个元素，如果散列表太满，就要再散列。如果对散列表再散列，就需要创建一个桶数更多的列表。然后将所有元素填入该表中，然后丢弃该表。 填充因子：决定何时对散列表在散列，例如， 如果装填因子为0.75 (默认值)，而表中超过75%的位置已经填人元素， 这个表就会用双倍的桶数自动地进行再散列。对于大多数应用程序来说， 装填因子为0.75 是比较合理的。 散列表实例&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;散列表可以用于实现几个重要的数据结构。其中最简单的是set 类型。set 是没有重复元素的元素集合。set 的add 方法首先在集中查找要添加的对象， 如果不存在，就将这个对象添加进去。 HashSet 类，它实现了基于散列表的集。可以用add 方法添加元素。contains 方法已经被重新定义， 用来快速地查看是否某个元素已经出现在集中。它只在某个桶中査找元素，而不必查看集合中的所有元素（add执行原理）。 散列集迭代器将依次访问所有的桶。由于散列将元素分散在表的各个位置上，所以访问它们的顺序几乎是随机的。只有不关心集合中元素的顺序时才应该使用HashSet。 栗子： public class HashSetTest { public static void main(String[] args) { Set&lt;String&gt; words=new HashSet&lt;&gt;();//HashSet继承set long totalTime=0; try(Scanner in=new Scanner(System.in)){ //输入 while(in.hasNext()) { String word=in.next();//读取文件中的单词 long callTime=System.currentTimeMillis(); words.add(word); callTime=System.currentTimeMillis()-callTime; totalTime+=callTime;//计算总读取时间 } Iterator&lt;String&gt; iter=words.iterator(); for (int i=0;i&lt;=20 &amp;&amp; iter.hasNext();i++) { System.out.println(iter.next());//打印集合中的元素 } } System.out.println(&quot;...&quot;); System.out.println(words.size()+&quot; distinct words.&quot;+totalTime+&quot; milliseconds.&quot;); } } 补充知识点：在命令行调用某个程序输入文件内容是，不能再当级目录下 使用 &gt; 表示输入文件内容 文件一test.txt&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;文件二 test1.txt &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ​ 编译输出结果，可以看出在文件二中，输出的内容顺序打乱了，证明了文章开始的那句话使用散列集我们无法控制元素出现的位置，他们将按照有利于操作目的的原则组织数据参考链接：https://blog.csdn.net/PacosonSWJTU/article/details/50317553 树集TreeSet 树集是一个有序集合（sorted collection）。可以以任意顺序将元素插入到集合中，在对集合进行遍历时，每个值将自动de按照排序后的顺序出现。使用红黑树 SortedSet&lt;String&gt; sorter = new TreeSet&lt;&gt;(); // TreeSet implements SortedSet sorter.add(&quot;bob&quot;); sorter.add(&quot;car&quot;); sorter.add(&quot;amy&quot;); for(String s: sorter) System.println(s);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结果：amy bob car 将元素添加到树中比添加到散列集中慢，但是比将元素添加到数组或链表中要快的多。 迭代器总是以排好序的方式访问每个元素 使用树集必须实现Comparable接口或者构造集的时候提供一个Comparator 树的排序必须是全序的，任意两个元素必须是可比的更详细的内容可以见：https://blog.csdn.net/PacosonSWJTU/article/details/50319649关于对象的比较 package hashSet; import java.util.Objects; public class Item implements Comparable&lt;Item>{//实现Comparable接口 完成compare方法 private String description; private int partNumber; public Item() { super(); } public Item(String description, int partNumber) { super(); this.description = description; this.partNumber = partNumber; } public String getDescription() { return description; } public void setDescription(String description) { this.description = description; } public int getPartNumber() { return partNumber; } public void setPartNumber(int partNumber) { this.partNumber = partNumber; } @Override public String toString() { return "Item [description=" + description + ", partNumber=" + partNumber + "]"; } @Override public int hashCode() {//Hashcode覆写 /*final int prime = 31; int result = 1; result = prime * result + ((description == null) ? 0 : description.hashCode()); result = prime * result + partNumber; return result;*/ return Objects.hash(description,partNumber); } /** * ==比较的是对象的存储地址 * equals没有覆写的情况下也是比较对象的存储地址 */ @Override public boolean equals(Object obj) {//equals覆写 if (this == obj) //如果引用地址相同，返回true return true; if (obj == null) //判断是否为空 return false; if (getClass() != obj.getClass())//判断类型是否相同 return false; Item other = (Item) obj; //强制类型转换 /*if (description == null) { if (other.description != null) return false; } else if (!description.equals(other.description)) return false; if (partNumber != other.partNumber) return false; return true;*/ return Objects.equals(description,other.description)&amp;&amp;partNumber==other.partNumber; } @Override public int compareTo(Item o) { // TODO Auto-generated method stub int diff=Integer.compare(partNumber, o.partNumber); return diff!=0?diff:description.compareTo(o.description); } } 上面注释的内容是自动生成代码，有一定的缺陷 package hashSet; import java.util.Comparator; import java.util.NavigableSet; import java.util.SortedSet; import java.util.TreeSet; public class TreeSetTest { public static void main(String[] args) { SortedSet&lt;Item> parts=new TreeSet&lt;>(); //SortSet比较器 parts.add(new Item("Toaster",1234)); parts.add(new Item("Widget",4562)); parts.add(new Item("Modem",9912)); System.out.println(parts); //便于定位元素以及反向遍历 NavigableSet&lt;Item> sortByDescription =new TreeSet&lt;>(Comparator.comparing(Item::getDescription)); sortByDescription.addAll(parts); System.out.println(sortByDescription); } } 结果： [Item [description=Toaster, partNumber=1234], Item [description=Widget, partNumber=4562], Item [description=Modem, partNumber=9912]] [Item [description=Modem, partNumber=9912], Item [description=Toaster, partNumber=1234], Item [description=Widget, partNumber=4562]] 关于Comparable和Comparator区别见链接：https://blog.csdn.net/pacosonswjtu/article/details/50320775 队列与双端队列&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;队列可以让人们有效地在尾部添加一个元素， 在头部删除一个元素。有两个端头的队列， 即双端队列， 可以让人们有效地在头部和尾部同时添加或删除元素。不支持在队列中间添加元素。在Java SE 6 中引人了Deque 接口， 并由ArrayDeque 和LinkedList 类实现。这两个类都提供了双端队列， 而且在必要时可以增加队列的长度。 优先级队列&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;优先级队列（priority queue) 中的元素可以按照任意的顺序插人，却总是按照排序的顺序进行检索。也就是说，无论何时调用remove 方法， 总会获得当前优先级队列中最小的元素。然而， 优先级队列并没有对所有的元素进行排序。如果用迭代的方式处理这些元素，并不需要对它们进行排序。优先级队列使用了一个优雅且高效的数据结构，称为堆（ heap)。堆是一个可以自我调整的二叉树，对树执行添加（ add) 和删除（ remore) 操作， 可以让最小的元素移动到根，而不必花费时间对元素进行排序。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与TreeSet—样，一个优先级队列既可以保存实现了Comparable 接口的类对象， 也可以保存在构造器中提供的Comparator 对象。 映射映射Map （key-value） 基本映射操作 通用映射：HashMap TreeMap 散列映射对键散列。树映射用键的整体顺序对元素进行排序，并将其组织成搜索树 散列或比较函数只能用于键。值不能散列或比较(只与key有关， 与value 无关) 如果在映射中没有给定与键对应的信息，get将返回null 迭代处理键和值 Map&lt;String,Integer> scores= new HashMap&lt;>(); scores.put("1", 1); scores.put("2", 2); scores.put("3", 3); scores.put("4", 4); scores.put("5", 5); scores.forEach((k,v)->{ k+=1; v++; System.out.println("key="+k+" value="+v); }); 结果： key=11 value=2 key=21 value=3 key=31 value=4 key=41 value=5 key=51 value=6 也可以使用以下方法 for(Map.Entry&lt;String , Employee> entry: staff.entrySet()) { String key = entry.getKey(); Employee e = entry.getValue(); do sth with key } 更新映射项不是很懂这部分内容，下面代码是网上copy下来的，如果在经常更新Map映射项的话，可以使用下面的方法 private Map&lt;String,int> table = new HashMap&lt;String,int>(); public void update(String key, int val) { if( !table.containsKey(key) ) return; Entry&lt;String,int> entry; for( entry : table.entrySet() ) { if( entry.getKey().equals(key) ) { entry.setValue(val); break; } } } 当然也可以使用，get 再put的方法 链接：更新映射项 映射视图 Map映射视图右三种，键集、值集、键值集 获取三种视图的方法 栗子： package mapTest; import java.util.Collection; import java.util.HashMap; import java.util.Map; import java.util.Set; public class MapTest { public static void main(String[] args) { Map&lt;String,String> map=new HashMap&lt;>(); map.put("1", "1"); map.put("2", "2"); map.put("3", "3"); map.put("4", "4"); map.put("5", "5"); //输出键集 System.out.println("输出键集"); Set&lt;String> keys=map.keySet(); for (String string : keys) { System.out.println(string); } System.out.println(); //输出值集 System.out.println("输出值集"); Collection&lt;String> values=map.values(); for (String s : values) { System.out.println(s); } System.out.println(); //输出键值集 System.out.println("输出键值集"); Set&lt;Map.Entry&lt;String, String>> entries=map.entrySet(); for (Map.Entry entry : entries) { System.out.println(entry); System.out.println(entry.getKey()+ " " +entry.getValue()); } System.out.println(map); } } ​ 如果在键集视图上调用迭代器的remove 方法， 实际上会从映射中删除这个键和与它关联的值。不过，不能向键集视图增加元素。另外， 如果增加一个键而没有同时增加值也是没有意义的。如果试图调用add 方法， 它会抛出一个UnsupportedOperationException。条目集视图有同样的限制，尽管理论上增加一个新的键/ 值对好像是有意义的。 专用映射散列集弱散映射引入问题： 如果有一个值，对应的键已经不再使用了， 将会出现什么情况呢？ 假定对某个键的最后一次引用已经消亡，不再有任何途径引用这个值的对象了。但是， 由于在程序中的任何部分没有再出现这个键， 所以， 这个键/ 值对无法从映射中删除。 垃圾回收器无法回收，垃圾回收器跟踪活动的对象。只要映射对象是活动的，其中的所有桶也是活动的， 它们不能被回收(不能被原因) 解决方案： 程序删除长期无用的值 使用WeakHashMap。当对键的唯一引用来自散列条目时， 这一数据结构将与垃圾回收器协同工作一起删除键/ 值对。 WeakHashMap原理 ​ WeakHashMap 使用弱引用（ weak references) 保存键。WeakReference 对象将引用保存到另外一个对象中， 在这里， 就是散列表键。对于这种类型的对象， 垃圾回收器用一种特有的方式进行处理。通常， 如果垃圾回收器发现某个特定的对象已经没有他人引用了， 就将其回收。然而， 如果某个对象只能由WeakReference 引用， 垃圾回收器仍然回收它，但要将引用这个对象的弱引用放人队列中。WeakHashMap 将周期性地检查队列， 以便找出新添加的弱引用。一个弱引用进人队列意味着这个键不再被他人使用， 并且已经被收集起来。于是， WeakHashMap 将删除对应的条目。 链接散列集与映射本章节不是很懂，有待深究 LinkedHashSet和LinkedHashMap，用来记住元素项的插入顺序，避免散列表中的项从表面上看是随机排列的，当条目插入到表中时，就会并入到双向链表中。个人理解就是用了两种存储方式，Hash表（至于是链表还是数组表就不得而至）存储方式和双向链表 链接散列映射将用访问顺序，而不是插入顺序，对映射条目进行迭代，每次调用get或put，收影响的条目将从当前的位置删除，并放到条目链表的 尾部（只有条目在链表中的位置会受影响， 而散列表中的桶不会受影响。一个条目总位于与键散列码对应的桶中，个人理解：其实就是修改了双向链表的存储顺序，有之前的乱序改为顺序，而Hash桶中的位置不变） 实现方法： LinkedHashMap&lt;K, V>(initialCapacity, loadFactor, true) 访问顺序对于实现高速缓存的“ 最近最少使用” 原则十分重要。例如， 可能希望将访问频率高的元素放在内存中， 而访问频率低的元素则从数据库中读取。当在表中找不到元素项且表又已经满时， 可以将迭代器加入到表中， 并将枚举的前几个元素删除掉。这些是近期最少使用的几个元素。 自动化实现该过程，构建LinkedHashMap子类。覆盖以下方法： protected boolean removeEldestEntry(Map.Entry&lt;K， V> eldest) 栗子：每当方法返回true 时， 就添加一个新条目，从而导致删除eldest 条目。例如，下面的高速缓存可以存放100 个元素： Map&lt;K, V> cache = new LinkedHashMapo(128, 0.75F, true) { protected boolean removeEldestEntry(Map.Entry&lt;K, V> eldest) { return size() > 100; } }(); 枚举集和映射此处不是很重要，只是使用方法 EnumSet是一个枚举类型元素集的高效实现。由于枚举类型只有有限个实例，所以EnumSet内部用位序列实现。如果对应的值在集中，则相应的位被置为1。 EnumSet类没有公共的构造器。可以使用静态工厂方法构造这个集： enum Weekday{MonDay,TuesDay,WenesDay,ThursDay,FriDay,SaturDay,SunDay}; EnumSet&lt;Weekday> enumSet=EnumSet.allOf(Weekday.class);// 创建一个包含指定元素类型的所有元素的枚举 set EnumSet&lt;Weekday> never=EnumSet.noneOf(Weekday.class);// 创建一个具有指定元素类型的空枚举 set EnumSet&lt;Weekday> workday=EnumSet.range(Weekday.MonDay, Weekday.FriDay);//创建一个最初包含由两个指定端点所定义范围内的所有元素的枚举 set EnumSet&lt;Weekday> mwf=EnumSet.of(Weekday.MonDay, Weekday.FriDay,Weekday.SunDay,Weekday.SaturDay);//创建一个最初包含指定元素的枚举 set 栗子： import java.util.EnumSet; public class Test { public Test() { // TODO Auto-generated constructor stub } enum Weekday{MonDay,TuesDay,WenesDay,ThursDay,FriDay,SaturDay,SunDay}; public static void main(String[] args) { // TODO Auto-generated method stub EnumSet&lt;Weekday> enumSet=EnumSet.allOf(Weekday.class);// 创建一个包含指定元素类型的所有元素的枚举 set enumSet.remove(Weekday.MonDay);//创建的枚举元素，可以被删除 System.out.println(enumSet); EnumSet&lt;Weekday> never=EnumSet.noneOf(Weekday.class);// 创建一个具有指定元素类型的空枚举 set never.add(Weekday.FriDay); never.add(Weekday.SunDay); never.add(Weekday.MonDay);//会自动排序 System.out.println(never); EnumSet&lt;Weekday> workday=EnumSet.range(Weekday.MonDay, Weekday.FriDay);//创建一个最初包含由两个指定端点所定义范围内的所有元素的枚举 set System.out.println(workday);//输出MonDay~FriDay之间的枚举变量 EnumSet&lt;Weekday> mwf=EnumSet.of(Weekday.MonDay, Weekday.FriDay,Weekday.SunDay,Weekday.SaturDay);//创建一个最初包含指定元素的枚举 set System.out.println(mwf); mwf.add(Weekday.WenesDay);//添加元素 System.out.println(mwf); } } 结果： [TuesDay, WenesDay, ThursDay, FriDay, SaturDay, SunDay] [MonDay, FriDay, SunDay] [MonDay, TuesDay, WenesDay, ThursDay, FriDay] [MonDay, FriDay, SaturDay, SunDay] [MonDay, WenesDay, FriDay, SaturDay, SunDay] 可以修改 Set接口的常用方法来修改 EnumSet EnumMap 是一个键类型为 枚举类型的映射表。 它可以直接且高效地用一个值数组实现， 在使用时， 需要再构造器中指定键类型： EnumMap&lt;Weekday, Employee> map = new EnumMap&lt;>(Weekday.class); 个人理解：其实EnumSet、EnumMap用法类推Set、Map，只是增加了Enum枚举定义 参考链接： https://blog.csdn.net/PacosonSWJTU/article/details/50331019 https://blog.csdn.net/u014322541/article/details/45677283 标识散列映射不是很重要 ​ 类IdentityHashMap有特殊的作用。在这个类中，键的散列值不是用hashCode函数计算的，而是用System.identityHashCode方法计算的。这是Object.hashCode方法根据对象的内存地址类计算散列码所使用的方式。而且，在对两个对象进行比较时，IdentityHashMap类使用==，而不是用equals。 视图和包装器视图理解： 摘取理解 java中的视图，可以说其实就是一个具有限制的集合对象，只不过这里的不是集合对象，而是一个视图对象。 集合视图就是把集合里面的东西给你展示出来。然后功能没有原始集合多。 是查看集合中部分或者全部数据的窗口。 对原集合的一层包装 ，不同的集合视图有不同的用途，有的是只读有的是同步的。针对视图的操作会影响到集合的数据。 链接：https://blog.csdn.net/weixin_38201813/article/details/70665574 原文： 使用视图可以获得其他的实现了集合接口Collection和映射表Map接口的对象 栗子：映射表类的keySet方法，看起来好像它创建了一个新集(Set),并将映射表中的所有键都填进去，然后返回这个集。事实是该方法返回一个实现Set接口的类对象，这个类方法对原映射表进行操作。这种集合就称为视图。 个人理解： ​ 视图获得其他实现集合接口Collection、Map接口的对象；可以通过这些访问他们的方法以及他们的子类、实现接口的方法，但是有的方法是无法使用的，因为数据类型的原因，可以在轻量级集合包装器中看到。 写在前面的话： ​ 视图以下部分大多是在讲视图的适应范围，不同的情况不同使用，应该在结合项目写代码的时候有更深入的理解。视图可以设置子范围，试图有只能修改或者只能读的，或者转化异常的。。。大概就是下面的内容，个人理解的不是很深，以后还得深究。 轻量级集合包装器 Arrays 类的静态方法asList 将返回一个包装了普通Java 数组的List 包装器。这个方法可以将数组传递给一个期望得到列表或集合参数的方法。 返回的对象不是ArrayList。它是一个视图对象， 带有访问底层数组的get 和set 方法。改变数组大小的所有方法（例如， 与迭代器相关的add 和remove 方法）都会抛出一个Unsupported OperationException 异常 public class Test { public static void main(String[] args) { Map&lt;String,String> a=new HashMap&lt;>(); String[] s=new String[10]; /*自动补全变量快捷键Ctrl+Alt+v*/ List&lt;String> list = Arrays.asList(s); list.set(2,"a"); //list.add("10");//此处报错remove方法同样报错 System.out.println(list.get(2)); System.out.println(list.size()); //将返回一个实现了List 接口的不可修改的对象， 并给人一种包含》个元素， 每个元素都像是一个anObject 的错觉。 创建了100个default，但是对象只存储一次，字符串值存储一次，存储代价小 List&lt;String> set= Collections.nCopies(100,"default"); System.out.println(set.get(0)==set.get(10)); } } 结果： a 10 true asList方法可以接收可变数目的参数。源码： /** * Returns a fixed-size list backed by the specified array. (Changes to * the returned list "write through" to the array.) This method acts * as bridge between array-based and collection-based APIs, in * combination with {@link Collection#toArray}. The returned list is * serializable and implements {@link RandomAccess}. * * &lt;p>This method also provides a convenient way to create a fixed-size * list initialized to contain several elements: * &lt;pre> * List&amp;lt;String&amp;gt; stooges = Arrays.asList("Larry", "Moe", "Curly"); * &lt;/pre> * * @param &lt;T> the class of the objects in the array * @param a the array by which the list will be backed * @return a list view of the specified array */ @SafeVarargs @SuppressWarnings("varargs") public static &lt;T> List&lt;T> asList(T... a) { return new ArrayList&lt;>(a); } *区分Collection和Collections * java.util.Collection 是一个集合接口。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式。 Collection├List│├LinkedList│├ArrayList│└Vector│ └Stack└Set 继承接口见开始的那张图 关于Collection接口官方解释： * The root interface in the &lt;i>collection hierarchy&lt;/i>. A collection * represents a group of objects, known as its &lt;i>elements&lt;/i>. Some * collections allow duplicate elements and others do not. Some are ordered * and others unordered. The JDK does not provide any &lt;i>direct&lt;/i> * implementations of this interface: it provides implementations of more * specific subinterfaces like &lt;tt>Set&lt;/tt> and &lt;tt>List&lt;/tt>. This interface * is typically used to pass collections around and manipulate them where * maximum generality is desired. ​ Collection 层次结构 中的根接口。Collection 表示一组对象，这些对象也称为 collection 的元素。一些 collection 允许有重复的元素，而另一些则不允许。一些 collection 是有序的，而另一些则是无序的。JDK 不提供此接口的任何直接 实现：它提供更具体的子接口（如 Set 和 List）实现。此接口通常用来传递 collection，并在需要最大普遍性的地方操作这些 collection。 java.util.Collections 是一个包装类。它包含有各种有关集合操作的静态多态方法。此类不能实例化，就像一个工具类，服务于Java的Collection框架。 关于Colections： * This class consists exclusively of static methods that operate on or return * collections. It contains polymorphic algorithms that operate on * collections, "wrappers", which return a new collection backed by a * specified collection, and a few other odds and ends. ​ 此类完全由在 collection 上进行操作或返回 collection 的静态方法组成。它包含在 collection 上操作的多态算法，即“包装器”，包装器返回由指定 collection 支持的新 collection，以及少数其他内。 调用以下代码： Collections.singleton(anObject); 则返回一个视图对象。 这个对象实现了Set 接口。 返回的对象实现了一个不可修改的单元素集， 而不需要付出建立数据结构的 开销。 singletonList 和 singletonMap 方法类似； 子范围试图接下来内容看不懂了，很是模糊，原文摘要参看以下链接 可以为很多集合建立子范围视图； 如， List g2 = staff.subList(10,20); 从列表staff 中取出 第10个~第19个元素；（第一个 索引包含在内，第二个索引不包含在内） 可以将任何操作应用到子范围， 并且能够自动地反应整个列表的情况； 对于有序集合映射表， 可以使用 排序顺序而不是元素位置建立子范围。 SortedSet 接口说明了3个方法 返回 大于等于from 小于to的所有元素子集 SortedSet&lt;E> subSet(E from ,E to) SortedSet&lt;E> headSet(E to) SortedSet&lt;E> tailSet(E from) ​ * 有序映射表有类似方法 返回映射表视图， 该映射表包含键落在指定范围内的所有元素 摘自：https://blog.csdn.net/PacosonSWJTU/article/details/50333509 视图部分不是很理解，有需求的请参照该链接 不可修改的视图 Collections 还有几个方法， 用于产生集合的不可修改视图。 这些视图对现有集合增加了一个运行时的检查。 如果发现试图对集合进行修改， 就抛出一个异常， 同时这个集合将保持未修改状态 一下方法获取不可修改视图 Collections.unmodifiableCollection Collections.unmodifiableList Collections.unmodifiableSet Collections.unmodifiableSortedSet Collections.unmodifiableMap Collections.unmodifiableSortedMap ​ 关于这六中方法，可以使用时查看源码注释 ​ 这里放一个： * Returns an unmodifiable view of the specified list. This method allows * modules to provide users with "read-only" access to internal * lists. Query operations on the returned list "read through" to the * specified list, and attempts to modify the returned list, whether * direct or via its iterator, result in an 不可修改视图并不是 集合本身不可修改（只是无法通过其投影出的视图修改原始集合）。仍然可以通过集合的原始引用对集合进行修改。并且仍然可以让集合的元素调用更改方法； 由于视图只是包装了 接口而不是 实际的集合对象， 所以只能访问 接口中定义的方法； 如， LinkedList 类有一些非常方便的方法， addFirst 和 addLast ， 它们都不是 List接口的方法，不能通过修改视图进行访问； waning： ​ unmodifiableCollection 方法 ，它的equals 方法不调用底层集合的equals 方法。相反， 它继承了Object 类的equals 方法， 这个方法只是检测两个对象是否是同一个对象。如果将集或列表转换成集合， 就再也无法检测其内容是否相同了。• 视图就是以这种方式运行的， 因为内容是否相等的检测在分层结构的这一层上没有定义妥当。视图将以同样的方式处理hashCode 方法。 ​ unmodifiableSet 类和unmodifiableList 类却使用底层集合的equals 方法和hashCode 方法。 同步视图多线程问题，锁机制？ 其实就是不能同步修改内容，有个锁机制 问题： ​ 如果由多个线程访问集合，就必须确保集不会被意外地破坏。例如， 如果一个线程试图将元素添加到散列表中，同时另一个线程正在对散列表进行再散列，其结果将是灾难性的。 解决办法： 类库的设计者使用视图机制来确保常规集合的线程安全， 而不是实现线程安全的集合类 栗子： Map&lt;String, Employee〉map = Collections.synchronizedMap(new HashMap&lt;String, Employee>0)； 现在， 就可以由多线程访问map 对象了。像get 和put 这类方法都是同步操作的， 即在另一个线程调用另一个方法之前，刚才的方法调用必须彻底完成 受查视图提出问题： ArrayList&lt;String> strings = new ArrayListo()； ArrayList rawList = strings; // warning only, not an error, for compatibility with legacy code rawList.add(new DateO) ; // now strings contains a Date object! 解决办法： List&lt;String> safestrings = Collections.checkedList(strings，String,class); 视图的add 方法将检测插人的对象是否属于给定的类。如果不属于给定的类， 就立即抛出一个ClassCastException。这样做的好处是错误可以在正确的位置得以报告： ArrayList rawList = safestrings; rawList.add(new DateO)；// checked list throws a ClassCastException 受查视图受限于虚拟机可以运行的运行时检查。例如， 对于ArrayList &lt;Pair&gt;, 由于虚拟机有一个单独的“ 原始” Pair 类， 所以，无法阻止插入Pair 。 算法排序与混排 Collections 类中的sort 方法可以对实现了List 接口的集合进行排序 Collections.sort(xxx); 如果想采用其他方式对列表进行排序，可以使用List 接口的sort 方法并传入一个Comparator 对象。可以如下按工资对一个员工列表排序： staff.sort(Comparator.comparingDouble(Employee::getSalary)); 注意上面的写法，注意！！！很值得学习使用 如果想按照降序对列表进行排序， 可以使用一种非常方便的静态方法Collections.reverseOrder()。 这个方法将返回一个比较器， 比较器则返回b.compareTo(a)。例如: staff.sort(Comparator.reverseOrder()) java的排序实现 直接将所有元素转人一个数组， 对数组进行排序，然后，再将排序后的序列复制回列表。 shuffle方法随机混排列表中元素的顺序。 二分查询 Collections的binarySearch方法实现该方法 要想查找某个元素， 必须提供集合以及要查找的元素。如果集合没有采用Comparable 接口的compareTo 方法进行排序， 就还要提供一个比较器对象。 i = Collections.binarySearch(c, element) ; i = Collections.binarySearch(c, element, comparator); 如果binarySearch 方法返回的数值大于等于0, 则表示匹配对象的索引。也就是说,c.get(i) 等于在这个比较顺序下的element。如果返回负值， 则表示没有匹配的兀素。但是，可以利用返回值计算应该将element 插人到集合的哪个位置， 以保持集合的有序性。插人的位置是 insertionPoint = -i - 1; if (i &lt; 0) c.add(-i - 1, element) ; 使用技巧 简单算法看源码去，用到算法时候，先baidu ，看源码说明！。主要是我太懒了，懒得将这些东西弄上去 批操作 成批删除 colll.removeAll (coll2); 将从coll1 中删除coll2中出现的所有元素。 colli.retainAll(coll2); 会从coll1 中删除所有未在coll2 中出现的元素 找出两个集合的交集 技巧！ 建立一个新集来存放结果 Set&lt;String> result = new HashSeto(a); retainAll() result.retainAll(b); 一个很有技巧的例子：假设有一个映射， 将员工ID映射到员工对象， 而且建立了一个将不再聘用的所有员工的ID。 Map&lt;String, Employee> staffMap = . . .; Set&lt;String> terainatedlDs = . . .; 直接建立一个键集，并删除终止聘用关系的所有员工的ID。 staffMap.keySet().removeAll (terminatedIDs); 集合和数组的转换 数组转换成集合 String[] value=... HashSet&lt;String> staff=new HashSet&lt;>(Arrays.adList(values));//注意Arrays.adList(values)返回的是一个视图，前面有说 集合转换成数组 Object[] values=staff.toArray();//注意返回类型为Object，而不是我们需要的类型，不能强制类型转换 解决办法： String[] values=staff.toArray(new String[0]); 或者这种指定长度数组 staff.toArray(new String[staff.size()]) ; 遗留的集合挂个图，用的不多，暂时不深究，以后又需要在学 写在尾巴这里的话​ 耗时1周将集合这部分内容看完了，可以说是很慢了，确实有很多东西不是很了解，以前看视频、看李兴华的那本书也是摸棱两可，很多概念不是很了解，看完了这一部分，对集合视图有了大致的了解，但是还需要深入学习，每种方法的实现，以及集合接口，集合类之间的关系，以及他们的适用范围，这将会是我看完核心卷在深入java学习的新章节。 附带集合类相关链接。 https://blog.csdn.net/sunhuaqiang1/article/details/52142873 ​ 上述类图中，实线边框的是实现类，比如ArrayList，LinkedList，HashMap等，折线边框的是抽象类，比如AbstractCollection，AbstractList，AbstractMap等，而点线边框的是接口，比如Collection，Iterator，List等。 ​ 我们可以看到Collection是List、Set、Queue接口的父接口，故该接口中定义的方法可用于操作List、Set、Queue集合。 ​ 发现一个特点，上述所有的集合类，都实现了Iterator接口，这是一个用于遍历集合中元素的接口，主要包含hashNext(),next(),remove()三种方法。它的一个子接口LinkedIterator在它的基础上又添加了三种方法，分别是add(),previous(),hasPrevious()。也就是说如果是先Iterator接口，那么在遍历集合中元素的时候，只能往后遍历，被遍历后的元素不会在遍历到，通常无序集合实现的都是这个接口，比如HashSet，HashMap；而那些元素有序的集合，实现的一般都是LinkedIterator接口，实现这个接口的集合可以双向遍历，既可以通过next()访问下一个元素，又可以通过previous()访问前一个元素，比如ArrayList。 ​ 还有一个特点就是抽象类的使用。如果要自己实现一个集合类，去实现那些抽象的接口会非常麻烦，工作量很大。这个时候就可以使用抽象类，这些抽象类中给我们提供了许多现成的实现，我们只需要根据自己的需求重写一些方法或者添加一些方法就可以实现自己需要的集合类，工作流昂大大降低。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>java核心卷1</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
</search>
